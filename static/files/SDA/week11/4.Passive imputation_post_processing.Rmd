---
title: "`mice`: Passive imputation and Post-processing"
author: "Gerko Vink and Stef van Buuren"
date: "Multiple Imputation in Practice"
output: 
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: false
---
<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 18px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 18px;
}
h2 { /* Header 2 */
    font-size: 18px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

---


This is the fourth exercise in the series. 

Exact replication of the imputations and figures in this exercise depends on `mice version > 3.2.1`. The latest version of `mice` can be obtained from:
```{r eval=FALSE}
devtools::install_github("stefvanbuuren/mice")
```
If you have an earlier `mice` version, the imputations and resulting plots may slightly differ. The overall train of thought for this document for all `mice` versions is equivalent.

In this exercise we will walk you through the more advanced features of `mice`, such as *post-processing* of imputations and *passive imputation*.

All the best, 

[Gerko](https://www.gerkovink.com) and [Stef](http://www.stefvanbuuren.name)

---

**1. Open `R` and load the packages `mice` and `dplyr`.**
```{r message=FALSE, warning=FALSE}
library(mice) # Data imputation
library(dplyr) # Data manipulation
library(lattice) # Plotting device
set.seed(123)
```
We choose seed value `123`. This is an arbitrary value; any value would be an equally good seed value. Fixing the random seed enables you (and others) to exactly replicate anything that involves random number generators. If you set the seed in your `R` instance to `123`, you will get the exact same results and plots as we present in this document if you follow the order and code of the exercises precisely. 

---

# Passive Imputation

There is often a need for transformed, combined or recoded versions of the data. In the case of incomplete data, one could impute the original, and transform the completed original afterwards, or transform the incomplete original and impute the transformed version. If, however, both the original and the transformed version are needed within the imputation algorithm, neither of these approaches work: One cannot be sure that the transformation holds between the imputed values of the original and transformed versions. `mice` has a built-in approach, called *passive imputation*, to deal with situations as described above. The goal of passive imputation is to maintain the consistency among different transformations of the same data. As an example, consider the following deterministic function in the `boys` data
\[\text{BMI} = \frac{\text{Weight (kg)}}{\text{Height}^2 \text{(m)}}\]
or the compositional relation in the mammalsleep data:
\[\text{ts} = \text{ps}+\text{sws}\]

---

**2. Use passive imputation to impute the deterministic sleep relation in the `mammalsleep` data. Name the new multiply imputed dataset `pas.imp`.**

First, we create a `method` vector:
```{r cache = FALSE}
meth <- make.method(mammalsleep)
meth
```
and a `predictorMatrix`:
```{r}
pred <- make.predictorMatrix(mammalsleep)
pred
```

We add the call for passive imputation to the `ts` element in the `meth` object 
```{r}
meth["ts"]<- "~ I(sws + ps)"
meth
```

and set the predictor relations for `ts` with `sws` and `ps` to `0`. Also, we have to exclude `Species` as a predictor
```{r}
pred[c("sws", "ps"), "ts"] <- 0
pred[, "species"] <- 0
pred
```
This avoids circularity problems where `ts` would *feed back into* `sws` and `ps`, from which it is calculated:

We can then run the imputations as
```{r}
pas.imp <- mice(mammalsleep, 
                meth = meth, 
                pred = pred, 
                maxit = 10, 
                seed = 123, 
                print = F)
```

We used a custom predictor matrix and method vector to tailor our imputation approach to the passive imputation problem. We made sure to exclude `ts` as a predictor for the imputation of `sws` and `ps` to avoid circularity. 

We also gave the imputation algorithm 10 iterations to converge and fixed the seed to `123` for this `mice` instance. This means that even when people do not fix the overall `R` seed for a session, exact replication of results can be obtained by simply fixing the `seed` for the random number generator within `mice`. Naturally, the same input (data) is each time required to yield the same output (`mids`-object). 

---

**3. Inspect the trace lines for `pas.imp`.**
```{r cache = FALSE}
plot(pas.imp)
```

We can see that the pathological nonconvergence we experienced before has been properly dealt with. The trace lines for the sleep variable look okay now and convergence can be inferred by studying the trace lines.

---

# Post-processing of the imputations

Remember that we imputed the `boys` data previously with `pmm` and with `norm`, where we saw that `pmm` preserves the observed data range and `norm` allows us to extend outside of the range of the observed data. If we were to impute e.g. `tv` with `norm` the problem arises that there may be negative values among the imputations. Somehow we should be able to 

1. Use a method that extrapolates beyond the range of the observed data, while
2. Laying a constraint on the imputed values of `tv`. 

The `mice()` function has an argument called `post` that takes a vector of strings of `R` commands. These commands are parsed and evaluated after the univariate imputation function returns, and thus provides a way of post-processing the imputed values while using the processed version in the imputation algorithm. In other words; the post-processing allows us to manipulate the imputations for a particular variable that are generated within each iteration. Such manipulations directly affect the imputated values of that variable and the imputations for other variables. Naturally, such a procedure should be handled with care. 

---

**4. Post-process the values to constrain them between 1 and 25, use `norm` as the imputation method for `tv`.**
```{r cache = FALSE}
meth <- make.method(boys)
meth["tv"] <- "norm"
post <- make.post(boys)
post["tv"] <- "imp[[j]][, i] <- squeeze(imp[[j]][, i], c(1, 25))"
imp <- mice(boys, 
            meth = meth, 
            post = post, 
            print = FALSE)
```
In this way the imputed values of `tv` are constrained (squeezed by function `squeeze()`) between 1 and 25.

---

**5. Compare the imputed values and histograms of `tv` for the solution obtained by `pmm` to the constrained solution (created with `norm`, constrained between 1 and 25).**

First, we recreate the default `pmm` solution
```{r}
imp.pmm <- mice(boys, print=FALSE)
```
and we inspect the imputed values for the `norm` solution
```{r}
table(complete(imp)$tv)
```
and for the `pmm` solution
```{r}
table(complete(imp.pmm)$tv)
```
It is clear that the norm solution - as expected - does not give us integer data as imputations. Next, we inspect and compare the density of the incomplete and imputed data for the constrained solution.
```{r}
densityplot(imp, ~tv)
```

---

A nice way of plotting the histograms of both datasets simultaneously is by creating first the dataframe (here we named it `tvm`) that contains the data in one column and the imputation method in another column.
```{r}
tv <- c(complete(imp.pmm)$tv, complete(imp)$tv)
used.method <- rep(c("pmm", "norm"), each = nrow(boys))
tvm <- data.frame(tv = tv, method = used.method)
```
and then plotting a histogram of `tv` conditional on method.
```{r}
histogram( ~tv | method, data = tvm, nint = 25)
```

Is there still a difference in distribution between the two different imputation methods? Which imputations are more plausible do you think?

---

**6. Make a missing data indicator (name it `miss`) for `bmi` and check the relation of `bmi`, `wgt` and `hgt` for the boys in the imputed data. To do so, plot the imputed values against their respective calculated values.**
```{r}
miss <- is.na(imp$data$bmi)
xyplot(imp, bmi ~ I (wgt / (hgt / 100)^2),
       na.groups = miss, cex = c(0.8, 1.2), pch = c(1, 20),
       ylab = "BMI (kg/m2) Imputed", xlab = "BMI (kg/m2) Calculated")
```

With this plot we show that the relation between `hgt`, `wgt` and `bmi` is not preserved in the imputed values. In order to preserve this relation, we should use passive imputation.

---

**7. Use passive imputation to preserve the relation between imputed `bmi`, `wgt` and `hgt` by setting the imputation method for `bmi` to:** 

- `meth["bmi"]<- "~ I(wgt / (hgt / 100)^2)"`

**but do not solve for circularity.**
```{r cache = FALSE}
meth <- make.method(boys)
meth["bmi"] <- "~ I(wgt / (hgt / 100)^2)"
imp <- mice(boys, 
            meth = meth, 
            print=FALSE)
```

---

**8. Again, plot the imputed values of `bmi` versus the calculated values and check whether there is convergence for `bmi`.**

To inspect the relation:
```{r}
xyplot(imp, bmi ~ I(wgt / (hgt / 100)^2), na.groups = miss,
       cex = c(1, 1), pch = c(1, 20),
       ylab = "BMI (kg/m2) Imputed", xlab = "BMI (kg/m2) Calculated")
```

To study convergence for `bmi` alone:
```{r}
plot(imp, c("bmi"))
```

Although the relation of `bmi` is preserved now in the imputations we get absurd imputations and on top of that we clearly see there are some problems with the convergence of `bmi`. The problem is that we have circularity in the imputations. We used passive imputation for `bmi` but `bmi` is also automatically used as predictor for `wgt` and `hgt`. This can be solved by adjusting the predictor matrix.

---

**9. Solve the problem of circularity (if you did not already do so) and plot once again the imputed values of bmi versus the calculated values.**

First, we remove `bmi` as a predictor for `hgt` and `wgt` to remove circularity.
```{r}
pred <- make.predictorMatrix(boys)
pred[c("hgt", "wgt"), "bmi"] <- 0
pred
```
and we run the `mice` algorithm again with the new predictor matrix (we still 'borrow' the imputation methods object `meth` from before)
```{r cache = FALSE}
imp <-mice(boys, 
           meth = meth, 
           pred = pred, 
           print = FALSE)
```
Second, we recreate the plots from **Assignment 8**. We start with the plot to inspect the relations in the observed and imputed data
```{r}
xyplot(imp, bmi ~ I(wgt / (hgt / 100)^2), na.groups = miss,
       cex=c(1, 1), pch=c(1, 20),
       ylab="BMI (kg/m2) Imputed", xlab="BMI (kg/m2) Calculated")
```

and continue with the trace plot to study convergence
```{r}
plot(imp, c("bmi"))
```

All is well now!

---

# Conclusion

We have seen that the practical execution of multiple imputation and pooling is straightforward with the `R` package `mice`. The package is designed to allow you to assess and control the imputations themselves, the convergence of the algorithm and the distributions and multivariate relations of the observed and imputed data.

It is important to ‘gain’ this control as a user. After all, we are imputing values and taking their uncertainty properly into account. Being also uncertain about the process that generated those values is therefor not a valid option.

---

# For fun 

---

## What you shouldn’t do with passive imputation

Never set all relations fixed. You will remain with the starting values and waste your computer’s energy (and your own).
```{r cache = FALSE}
meth<- make.method(boys)
pred <- make.predictorMatrix(boys)
meth["bmi"]<- "~ I(wgt / (hgt / 100)^2)"
meth["wgt"]<- "~ I(bmi * (hgt / 100)^2)"
meth["hgt"]<- "~ I(sqrt(wgt / bmi) * 100)"
pred[c("bmi", "wgt", "hgt"), ] <- 0
imp.path <- mice(boys, 
                 meth=meth, 
                 pred=pred, 
                 seed=123)
plot(imp.path, c("hgt", "wgt", "bmi"))
```

We named the `mids` object `imp.path`, because the nonconvergence is pathological in this example!

---

**- End of exercise**

---
