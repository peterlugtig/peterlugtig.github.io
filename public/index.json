[{"authors":["peterlugtig"],"categories":null,"content":"Peter Lugtig is an associate professor at the deparment of Methodology and Statistics at Utrecht University, where he specializes in survey methodology, which includes inferences using a mix of survey data and big data and the modelling of survey errors, and the use of sensor technology in smartphones.\nNext to his research, he has a passion for teaching and thus is involved in several Bachelor\u0026rsquo;s, Master\u0026rsquo;s and post-graduate courses about statistics and survey methodology.\n","date":1530004560,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1530004560,"objectID":"ab06ed9daf6288d8dab5aaa744c95fb5","permalink":"https://peterlugtig.com/authors/peterlugtig/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/peterlugtig/","section":"authors","summary":"Peter Lugtig is an associate professor at the deparment of Methodology and Statistics at Utrecht University, where he specializes in survey methodology, which includes inferences using a mix of survey data and big data and the modelling of survey errors, and the use of sensor technology in smartphones.\nNext to his research, he has a passion for teaching and thus is involved in several Bachelor\u0026rsquo;s, Master\u0026rsquo;s and post-graduate courses about statistics and survey methodology.","tags":null,"title":"Peter Lugtig","type":"authors"},{"authors":["peter_detailed"],"categories":null,"content":"\nWelcome! I (Peter Lugtig) am a survey methodologist working at the department of methods and statistics of Utrecht University. I teach and do research on the methodology of doing longitudinal research in the social sciences. You can find my full CV by clicking on the link at the left.\nThis personal webpage is about my research. I have the tendency to get distracted into too many side-projects (all fun and important), but my main research interests are:\n  Inference using a mix of survey data and big data. I am mainly interested to find out how mobile phone sensor data can complement survey data, and study the data quality of \u0026lsquo;sensor\u0026rsquo; data (see below), like GPS and accelerometer data to infer human behavior. Topics are data fusion of survey and sensor data, nonresponse pattrens in sensor data, correlates of nonresponse, and what to do about these.\n  Panel Survey Methods: panel surveys follow people over time to document change, and I believe that this requires specific methodologies to make sure the resulting data are of high quality. For example, selective drop-out from the panel should be prevented. And specific types of survey questions that take into account the fact that respondents have been interviewed before, can also increase the quality of change estimates. My dissertation was about this topic.\n  Modeling survey errors: Errors is what methodologists worry about. The only problem is that errors are rarely directly observable. We only have one dataset, and we cannot directly evaluate whether the individual answers are \u0026lsquo;true\u0026rsquo; or \u0026lsquo;wrong\u0026rsquo; Similarly, we would like to know whether the answers of the people we observe generalize to all the people we would like to know something about. For this, we need statistical models. I mainly work with Structural Equation Models and use within-subjects designs, to disentangle all kinds of survey errors, and compare the size of each error source. From 2012-2015 I have worked on an ESRC-funded project studying common causes (i.e. trade-offs) in survey errors. Currently, my interest is more in the use of both sensor data, survey data and big data in mobile data collection, particularly with data on movement (GPS and accelerometers).\n  Longitudinal data analysis. This comprises all my side projects. I work on diverse projects that involve the analysis of longitudinal survey data, mainly using Structural Equation Models.\n  If you have questions about any of these topics, or posts on my blog, do not be afraid to e-mail me at p.lugtig@uu.nl. I regularly teach short courses or give lectures on SEM and survey methods, as well as consultations to researchers on these topics. If you are interested to hear me speak on my research or give a specific training, do e-mail me as well.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"78d9be37983243cfa9c721eee826c741","permalink":"https://peterlugtig.com/authors/peter_detailed/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/peter_detailed/","section":"authors","summary":"Welcome! I (Peter Lugtig) am a survey methodologist working at the department of methods and statistics of Utrecht University. I teach and do research on the methodology of doing longitudinal research in the social sciences. You can find my full CV by clicking on the link at the left.\nThis personal webpage is about my research. I have the tendency to get distracted into too many side-projects (all fun and important), but my main research interests are:","tags":null,"title":"Peter Lugtig","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://peterlugtig.com/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://peterlugtig.com/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://peterlugtig.com/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes .  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://peterlugtig.com/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"Dear all,\nNine years ago I started blogging. I have been quiet the last few years when it comes to blogging. Perhaps I will pick this up again, perhaps not. What changed quite a bit is how I work as a scientist. I am using R now as my default software for analysis, and have also started to use GitHub for version control, as the cool kids nowadays do. Anyways, my website was long due an overhaul. Here it is. Thanks to Thom Volker for helping me out with this. The website should be relatively easy to maintain, so, who knows, I may pick up blogging again. These are interesting times for a survey methods person. We are in the middle of the COVID-19 outbreak - as I write this I have been at home for over 2 weeks now. As much as I agree with people saying that it really is up to the experts - virologists and epidemiologists - I feel there is a role for sampling theory in making sure that we get as accurate statistics on the proportion of the total population get is infected with SarsCov2. The rather far-reaching public measures to battle Covid-19 should be maintained as long as necessary, but not longer than that. The point when to relax or re-instate measures like social distancing depend very much on what proportion of the total population is infected. I believe one can only really estimate this proportion by taking random samples from the general population, and testing everyone in that sample. However, that should not necessarily be a simple random sample, as seems to be current opinion. It will be much better to stratify on geographic area (as Covid-19 spreads locally) and risk factors such as age. More on that later perhaps.\nPeter\n","date":1585526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585526400,"objectID":"b3fb408822edb78c0deba4f34901e618","permalink":"https://peterlugtig.com/post/new-website/","publishdate":"2020-03-30T00:00:00Z","relpermalink":"/post/new-website/","section":"post","summary":"Dear all,\nNine years ago I started blogging. I have been quiet the last few years when it comes to blogging. Perhaps I will pick this up again, perhaps not. What changed quite a bit is how I work as a scientist. I am using R now as my default software for analysis, and have also started to use GitHub for version control, as the cool kids nowadays do. Anyways, my website was long due an overhaul.","tags":["website","data quality","sampling"],"title":"new website","type":"post"},{"authors":["Kolenkov","S.","West","B.T.","and Lugtig","P."],"categories":[],"content":"","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"dd0d9ba517c4d21effa08238ca2d19ef","permalink":"https://peterlugtig.com/publication/2020_kolenikov/","publishdate":"2020-04-03T00:00:00Z","relpermalink":"/publication/2020_kolenikov/","section":"publication","summary":"We  document  our  understanding  of,  and  recommendations  for,  appropriate  best  practices  in documenting the complex sampling design settings for statistical software that enables design-based analyses of survey data. We discuss features of complex sample survey data such as stratification, clustering, unequal probabilities of selection, and calibration, and outline their impact on estimation procedures. We provide assessment guidelines and a checklist that will aid complex sample survey data  providers  in  aligning  their  level  of  documentation  with  best practices  andshow  how  existing surveys and their documentation score based on these guidelines.","tags":[],"title":"A checklist for assessing the analysis documentation for public-use complex sample survey data sets","type":"publication"},{"authors":["Smeets","L.M.S.","Lugtig","P.","and Schouten","J.G."],"categories":[],"content":"","date":1575154800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575154800,"objectID":"8f8402bec09b494aababa6da4752eb38","permalink":"https://peterlugtig.com/publication/2019_smeets_automatic/","publishdate":"2019-12-01T00:00:00+01:00","relpermalink":"/publication/2019_smeets_automatic/","section":"publication","summary":"Goal: Showing the feasibility of automatic travel mode prediction using smartphone location data in a national travel survey. Data collection: In the fall of 2018, 1,902 respondents were randomly sampled from the Dutch population to participate in a smartphone-based travel study. A purpose-built app that collected location data and generated a diary of stops and trips was used. For the trips, respondents could label which travel mode they used. Of the respondents, 517 completed data collection for at least 7 days and a total 18,414 trips were collected, of which 5,641 were labelled. Method: Every trip consists of a string of chronological ordered GPS points. From these points, trip-level features were engineered, such as average speed. Context-location data, such as the location of public transport stops, was then added and extra features such as how many train stations were passed during a trip were calculated. In addition, the data was enriched with respondent-level characteristics, available through Dutch registries. In total 127 features were engineered. A Random Forest Algorithm was then used to predict travel modes from these features. The transport modes distinguished are: Walking, Bike, E-bike, Car, Bus, Metro, Tram, Scooter, Train, and erroneously recorded trips. This last one is unique to this research, but inherent to app-based studies. Results: For 62% of trips the correct transport mode is predicted, when treating trips as independent events. Taking into account how often respondents used a certain transport mode increases the accuracy to 70%. Collapsing similar transport modes, such as bikes and E-bikes, also positively affects the accuracy. However, not all modes of transport can be as accurately classified.","tags":[],"title":"Automatic Travel Mode Prediction in a National Travel Survey","type":"publication"},{"authors":["Elevelt","A.","Toepoel","V.","Lugtig","P.","Bernasco","W.","and Ruiter","S. de"],"categories":[],"content":"","date":1569456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569456000,"objectID":"2ce11feaef91acff54193156e1ee4edb","permalink":"https://peterlugtig.com/publication/2019_elevelt_where_you/","publishdate":"2019-09-26T00:00:00Z","relpermalink":"/publication/2019_elevelt_where_you/","section":"publication","summary":"Smartphones enable passive collection of sensor data alongside survey participation. Location data add context to people’s reports about their time use. In addition, linking global positioning system data to self-reported time use surveys (TUSs) can be valuable for understanding how people spend their time. This article investigates whether and how passive collection of geographical locations (coordinates) proves useful for deriving respondents’ functional locations. Participants of the ongoing Children of Immigrants Longitudinal Survey in the Netherlands were invited to participate in a TUS administered with a smartphone app that also unobtrusively tracked respondents’ locations. Respondents reported their activities per 10-min interval in a smartphone diary app (n = 1,339) and shared their geographical location data (n = 1,264). The correspondence between the functional locations derived from the time use data and those derived from the geographical location data was assessed by calculating the percentage of intervals in which both measures are similar. Overall, results show that home locations can be automatically assigned reliably but that respondent information is required to reliably assign work or school locations. In addition, location tracking data contain many measurement errors, making it difficult to record valid locations. Multilevel models show that the variability in correct classifications is intrapersonal and largely predicted by phone type, which determines location measurement frequency.","tags":[],"title":"Where you at? Using GPS location in an electronic Time Use diary study to derive functional locations","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides , also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Did you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"a60f48c8ba9369973af492ec5d1ec15e","permalink":"https://peterlugtig.com/teaching/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/teaching/writing-technical-content/","section":"teaching","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.","tags":null,"title":"Writing technical content in Academic","type":"teaching"},{"authors":["Lugtig","P.","Toepoel","V.","Haan","M.","Zandvliet","R.","and Klein Kranenburg","L."],"categories":[],"content":"","date":1561935600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561935600,"objectID":"bd51b5206c6823c5fb1963e8aa101f5d","permalink":"https://peterlugtig.com/publication/2019_lugtig_recruiting_smartphone/","publishdate":"2019-07-01T00:00:00+01:00","relpermalink":"/publication/2019_lugtig_recruiting_smartphone/","section":"publication","summary":"A sizable minority of all web surveys are nowadays completed on smartphones. People who choose a smartphone for Internet-related tasks are different from people who mainly use a PC or tablet. Smartphone use is particularly high among the young and urban. We have to make web surveys attractive for smartphone completion in order not to lose these groups of smartphone users. In this paper we study how to encourage people to complete surveys on smartphones in order to attract hard-to-reach subgroups of the population. We experimentally test new features of a survey-friendly design: we test two versions of an invitation letter to a survey, a new questionnaire lay-out, and autoforwarding. The goal of the experiment is to evaluate whether the new survey design attracts more smartphone users, leads to a better survey experience on smartphones and results in more respondents signing up to become a member of a probability-based online panel. Our results show that the invitation letter that emphasizes the possibility for smartphone completion does not yield a higher response rate than the control condition, nor do we find differences in the socio-demographic background of respondents. We do find that slightly more respondents choose a smartphone for survey completion. The changes in the layout of the questionnaire do lead to a change in survey experience on the smartphone. Smartphone respondents need 20% less time to complete the survey when the questionnaire includes autoforwarding. However, we do not find that respondents evaluate the survey better, nor are they more likely to become a member of the panel when asked at the end of the survey. We conclude with a discussion of autoforwarding in web surveys and methods to attract smartphone users to web surveys.","tags":[],"title":"Recruiting young and urban groups into a probability-based online panel by promoting smartphone use","type":"publication"},{"authors":["Uitdehaag","M.J.","Stellato","R.K.","Lugtig","P.","Olden","T.","and Teunissen","S.C."],"categories":[],"content":"","date":1559430000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559430000,"objectID":"51c79df1bb4072ac648d09b5c8be93e8","permalink":"https://peterlugtig.com/publication/2019_uitdehaag_barriers/","publishdate":"2019-06-02T00:00:00+01:00","relpermalink":"/publication/2019_uitdehaag_barriers/","section":"publication","summary":"Background:\nNurses and certified nursing assistants (CNA) have a crucial role in 24/7 continuity of palliative care for many vulnerable patients and families, however, their perspective has been largely omitted in reported barriers to palliative care. Aim:\nTo describe barriers to ideal palliative care that are specific to nurses and CNAs working in all care settings. Methods:\nA cross-sectional, online survey was distributed to members of the Dutch Nurses' Association. Findings:\nAlmost 50% of the participating 2377 nurses and CNAs experienced more than five barriers to ideal palliative care in their work situation; nurses and CNAs employed in regional hospitals, mental healthcare and nursing home settings encountered more barriers than those working in other settings. Conclusion:\nThe three most common barriers were: lack of proactive care planning, lack of internal consultation possibilities and lack of assessment of care recipients' preferences and needs for a seamless transition to another setting.","tags":[],"title":"Barriers to ideal palliative care in multiple care settings: The nurses' point of view","type":"publication"},{"authors":["Bais","F.","Schouten","J.G.","Lugtig","P.","Toepoel","V.","Arends-Toth","J.","Douhou","S.","Kieruj","N.","Morren","M.","and Vis","C."],"categories":[],"content":"","date":1556665200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556665200,"objectID":"c4c628c997c98159f336bd3d5adb31b9","permalink":"https://peterlugtig.com/publication/2019_bais_can_survey_item_characteristics/","publishdate":"2019-05-01T00:00:00+01:00","relpermalink":"/publication/2019_bais_can_survey_item_characteristics/","section":"publication","summary":"Item characteristics can have a significant effect on survey data quality and may be associated with measurement error. Literature on data quality and measurement error is often inconclusive. This could be because item characteristics used for detecting measurement error are not coded unambiguously. In our study, we use a systematic coding procedure with multiple coders to investigate the extent to which the coding of item characteristics could be done reliably. For this purpose, we constructed an item characteristics scheme that is based on typologies of characteristics. High intercoder reliability indicates a clear relation between item characteristic, item content, and measurement error. Our results show that intercoder reliability is often low, especially for item characteristics that are hard to code due to subjectivity. Low intercoder reliability complicates comparisons between studies about item characteristics and measurement error. We give suggestions for coping with low intercoder reliability.","tags":[],"title":"Can survey item characteristics relevant to mode-specific measurement error be coded reliably","type":"publication"},{"authors":["Haan","M.","Toepoel","V.","and Lugtig","P."],"categories":[],"content":"","date":1553468400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553468400,"objectID":"694824198d30f71b1e2b42f4b676e460","permalink":"https://peterlugtig.com/publication/2019_haan_predict_device_use/","publishdate":"2019-03-25T00:00:00+01:00","relpermalink":"/publication/2019_haan_predict_device_use/","section":"publication","summary":"In this study, we investigate whether mobile device use in surveys can be predicted. We aim to identify possible motives for device use and build a model by drawing on theory from technology acceptance research and survey research. We then test this model with a Structural Equation Modeling approach using data of seven waves of the GESIS panel. We test whether our theoretical model fits the data by focusing on measures of fit, and by studying the standardized effects of the model. Results reveal that intention to use a particular device can predict actual use quite well. Ease of smartphone use is the most meaningful variable: if people use a smartphone for specific tasks, their intention to use a smartphone for survey completion is also more likely. In conclusion, investing in ease of use of mobile survey completion could encourage respondents to use mobile devices. This can foremost be established by building well-designed surveys for mobile devices.","tags":[],"title":"Can we predict device use? An investigation into mobile device use in surveys","type":"publication"},{"authors":["admin"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter ).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image , place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic .\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"0328133065e3febbdf24de36973d6882","permalink":"https://peterlugtig.com/teaching/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/teaching/jupyter/","section":"teaching","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"teaching"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation  Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export : E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask  Documentation ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://peterlugtig.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Schouten","R.M.","Lugtig","P.","and Vink","G."],"categories":[],"content":"","date":1530486000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530486000,"objectID":"786a0fe4570cec1d67f0b7d2e6eb0031","permalink":"https://peterlugtig.com/publication/2018_schouten_generating_missing/","publishdate":"2018-07-02T00:00:00+01:00","relpermalink":"/publication/2018_schouten_generating_missing/","section":"publication","summary":"Missing data form a ubiquitous problem in scientific research, especially since most statistical analyses require complete data. To evaluate the performance of methods dealing with missing data, researchers perform simulation studies. An important aspect of these studies is the generation of missing values in a simulated, complete data set: the amputation procedure. We investigated the methodological validity and statistical nature of both the current amputation practice and a newly developed and implemented multivariate amputation procedure. We found that the current way of practice may not be appropriate for the generation of intuitive and reliable missing data problems. The multivariate amputation procedure, on the other hand, generates reliable amputations and allows for a proper regulation of missing data problems. The procedure has additional features to generate any missing data scenario precisely as intended. Hence, the multivariate amputation procedure is an efficient method to accurately evaluate missing data methodology.","tags":[],"title":"Generating missing values for simulation purposes: A multivariate amputation procedure","type":"publication"},{"authors":["Toepoel","V.","and Lugtig","P."],"categories":[],"content":"","date":1530399600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530399600,"objectID":"53fcf13f0d8a3fcbf6c12baca96620eb","permalink":"https://peterlugtig.com/publication/2018_toepoel_modularization/","publishdate":"2018-07-01T00:00:00+01:00","relpermalink":"/publication/2018_toepoel_modularization/","section":"publication","summary":"With the rise of mobile surveys comes the need for shorter questionnaires. We investigate the modularization of an existing questionnaire in the Longitudinal Internet Study for the Social Sciences (LISS) Panel in the Netherlands. We randomly divided respondents into a normal length survey condition, a condition where the same survey was split into 3 parts, and a condition where the survey was split into 10 parts. Respondents received the parts consecutively at regular intervals over a 1-month period. We discuss response rates, data quality measures, and respondents’ evaluation of the questionnaire. Our results indicate higher start rates when the survey is cut into smaller parts but also higher dropout rates. However, the fraction of missing information is lower in the 3- and 10-part conditions. More respondents use their mobile phone for survey completion when the survey is shorter. We find fewer item missings and satisficing in shorter surveys. We find no effect on neutral and extreme responding nor on estimates of the validity of answers. People with low and high education and young and old evaluate shorter surveys better than the normal length survey.","tags":[],"title":"Modularization in an era of mobile web: Investigating the effects of cutting a survey into smaller pieces on data quality","type":"publication"},{"authors":["Peter Lugtig"],"categories":null,"content":"As a survey methodologist I get paid to develop survey methods that generaly minimize survey errors, and advise people on how to field surveys in a specific setting. A question that has been bugging me for a long time is what survey error we should worry about most. The Total Survey Error (TSE) framework is very helpful for thinking which type of survey error may impact survey estimates\nBut which error source is generally larger? Nonresponse or measurement errors?\nThankfully, no one has ever asked me this question yet, because I would find it impossible to answer anything then \u0026ldquo;well, that depends\u0026rdquo;.\nThe reason why we don\u0026rsquo;t know what error source is larger is that we can usually assess observational errors only for the people we have actually observed. There are several ways to do this. Sometimes we know the truth, and so we can compare survey answers (\u0026ldquo;do you have a valid driver\u0026rsquo;s license?\u0026quot;) to data that we know from administrative records. If we are interested in attitudes, we can use psychometric models. The people behind the computer programme SQP have summarised a huge number of question experiments and MTMM models to predict the quality of a specific survey questions. By asking different forms of the same question (e.g. how interested are you in politics?\u0026quot;) we can gauge the reliability and validity of this question under different question wordings and answer scales.\nThe problem of course is that if we are indeed interested in the concept \u0026ldquo;interest in politics\u0026rdquo;, we would ideally also like to know what people who we have not observed would have answered. In order to estimate errors of non-observation (nonresponse), we would need to actually observe these people!\nThere are of course some situations where we actually do know something about nonrespondents. Cannell and Fowler (1963) are an early example: they knew something about nonrespondents (hospital visits) and could compare different respondent and nonrespondent groups. A more recent great example is by Kreuter, Muller and Trappmann (2010) . They did a survey among people for whom they already knew their employment status. They showed that nonresponse and measurement error in employment status were about of equal size, and go in different directions.\nThere are several other studies, among students or in the context of mixed-mode studies that have looked at factual questions, and estimated both measurement and nonresponse error in the same study. So, what do we learn? From my reading of the literature, there is no clear pattern in findings. Sometimes measurement errors are larger, sometimes nonresponse is larger. And sometimes these survey errors go in the same direction, and sometimes in different directions. A further problem is that these validation studies use factual questions, not attitudinal questions, which surveys are more often interested in. In conclusion, that means that:\n1. For factual questions, is is not clear whether nonresponse or measurement errors are the larger problem. There is large variation across studies.\n2. Because the measurement quality of attitudinal questions is generally lower than that of factual questions, measurement errors may pose a relatively larger problem than nonresponse in attitudinal questions.\n3. BUT, we then have to assume that nonresponse bias is generally the same for attitudinal and factual questions, which may not be true. Stoop (2005) and others have shown that if you are interested in measuring in \u0026quot; interest in politics\u0026rdquo;, late and hard-to-reach respondents are very different from early and easy respondents.\nSo, what to do? How do we make progress so that I can at some point give an answer to the question which error sourcewe should worry about most?\n1. We could find studies with a very high response rate (100% ideally) and study the differences between the easy and late respondents, like Stoop did.\n2. We should do more validation studies for factual questions, which should become more feasible, as more and more register data are available.\n3. And, we should try to link MTMM studies and other psychometric models to nonresponse models. I recently did a study that did this for a panel study, but what is really needed is work in cross-sectional studies.\n","date":1530004560,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530004560,"objectID":"03086fcd1fdcc63f2f4028601dc0894f","permalink":"https://peterlugtig.com/post/which-survey-error-source-is-larger/","publishdate":"2018-06-26T11:16:00+02:00","relpermalink":"/post/which-survey-error-source-is-larger/","section":"post","summary":"As a survey methodologist I get paid to develop survey methods that generaly minimize survey errors, and advise people on how to field surveys in a specific setting. A question that has been bugging me for a long time is what survey error we should worry about most. The Total Survey Error (TSE) framework is very helpful for thinking which type of survey error may impact survey estimates\nBut which error source is generally larger?","tags":["measurement error","MTMM","nonresponse error","validation","common causes of survey error","data quality"],"title":"Which survey error source is larger: measurement or nonresponse?","type":"post"},{"authors":["Lugtig","P."],"categories":[],"content":"","date":1513119600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513119600,"objectID":"8108c09c3c44905f8f693a81bc3448f4","permalink":"https://peterlugtig.com/publication/2017_lugtig_the_relative_size_of_measurement_error/","publishdate":"2017-12-13T00:00:00+01:00","relpermalink":"/publication/2017_lugtig_the_relative_size_of_measurement_error/","section":"publication","summary":"This paper proposes a method to simultaneously estimate both measurement and nonresponse errors for attitudinal and behavioural questions. The method uses a Multi-Trait Multi-Method (MTMM) approach, which is commonly used to estimate the reliability and validity of survey questions. The classic MTMM model is in this paper extended to include the effects of measurement bias and longitudinal nonresponse. Measurement and nonresponse errors are expressed on a common metric in this model, so that their relative sizes can be assessed over the course of a panel study. Using an example about political trust from the Dutch LISS panel, we show that measurement problems lead to both small errors and small biases, that dropout in the panel study does not lead to errors or bias, and that therefore, measurement is a more important source of both error and bias than nonresponse.","tags":[],"title":"The relative size of measurement error and attrition error in a panel survey. Comparing them using a new Multi-Trait Multi-Method model","type":"publication"},{"authors":["Lugtig","P.","Toepoel","V.","Haan","M.","and Schouten","B."],"categories":[],"content":"","date":1509663600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509663600,"objectID":"a32a25cc75f380e4c59b4feb03705a6b","permalink":"https://peterlugtig.com/publication/dutch_2017_lugtig_het_waarneem/","publishdate":"2017-11-03T00:00:00+01:00","relpermalink":"/publication/dutch_2017_lugtig_het_waarneem/","section":"publication","summary":"In oktober 2016 zijn het Centraal Bureau voor de Statistiek en de afdeling Methodologie \u0026 Statistiek van de Universiteit Utrecht een intensieve samenwerking begonnen. In de komende jaren werken zij samen aan het integreren van smartphones binnen dataverzamelingsmethoden, zowel voor de interactie met respondenten als voor metingen via de sensoren in de smartphones van respondenten. Smartphones zijn wijd verspreid (Figuur 1) en de mogelijkheden van sensoren zijn eindeloos, maar hoe en onder welke condities zorg je ervoor dat nieuwe vormen van data ofﬁciële statistieken kunnen verbeteren of aanvullen?","tags":[],"title":"In Dutch: Het waarneem innovatie netwerk","type":"publication"},{"authors":null,"categories":null,"content":"My breaks between posts are getting longer and longer. Sorry my dear readers. Today, I am writing about research done over a year ago that I did with Vera Toepoel and Alerk Amin. Our study was about a group of respondents we can no longer ignore: Mobile-only web survey respondents. These are people, who do no longer use a laptop or desktop PC and use their smartphone for most or any of their Internet browsing, but instead use a smartphone. If we as survey methodologists want these people to answer our surveys, we have to design our surveys for smartphones as well.\nWho are these mobile-only web survey respondents? This population may of course differ across countries. We used data from the American Life Panel, run by RAND, to investigate what this group looked like in the United States, using data from 2014 (so the situation today may be a bit different). The full paper can be found here We find that of all people participating in 7 surveys conducted in the panel, 7% is mobile-only in practice. This is not a huge proportion, but it may matter a lot if these 7% of respondents are very different from other types of respondents. We find that they are.\nIn order to study how different these respondents are, we define 5 groups based on the device the use for responding to surveys:\n1. Respondents who always use a PC for completing surveys. This the largest group (68%) and therefore serves as the reference group)\n2. Respondents who always use a tablet (5%)\n3. Respondents who always use a smartphone ( 7% - our group of interest)\n4. Respondents who mix tablets and Pcs (7%)\n5. Respondents who mix phones and Pcs (10%)\nA further 1% uses all devices, but we ignore these respondents here.\n  Click Figure to enlarge. The effects shown are always in comparison to the reference group, which is the ‘always PC’ group.\nThe 5 groups serve as our dependent variable in a multinomial logit regression. The average marginal effects shown in the Figure above respresent the change in the likelihood of being in the \u0026lsquo;always PC\u0026rsquo; group as compared to one of the other groups. The negative age coefficient of -.03 for the always phone group means that with every decade respondents get younger (a negative effect), they have a .03 higher probability to be be in the always phone group as referred to the always Pc group. These effects seem small, but they are not. An imaginary respondent aged 60 has a predicted probability of 92 percent of being in the always PC group as opposed to the always phone group, but this probability is about 80 percent for someone aged 20, controlling for the effects of other covariates.\nOur take-away? Apart from age, \u0026lsquo;Always phone’ respondents are also less likely to have a higher education (Bachelor degree or higher), are more likely to be married, and more likely to be of Hispanic or African American ethnicity. These characteristics coincide with some of the most important characteristics of hard-to-recruit respondents. While designing your surveys for smartphones will not get these hard-to-recruit respondents into your panel, you can easily lose them by not designing your surveys for smartphones.\n","date":1493315520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493315520,"objectID":"3dc8105270a3b95987beb1548ab7fd89","permalink":"https://peterlugtig.com/post/mobile-only-web-survey-respondents/","publishdate":"2017-04-27T19:52:00+02:00","relpermalink":"/post/mobile-only-web-survey-respondents/","section":"post","summary":"My breaks between posts are getting longer and longer. Sorry my dear readers. Today, I am writing about research done over a year ago that I did with Vera Toepoel and Alerk Amin. Our study was about a group of respondents we can no longer ignore: Mobile-only web survey respondents. These are people, who do no longer use a laptop or desktop PC and use their smartphone for most or any of their Internet browsing, but instead use a smartphone.","tags":["nonresponse","mixed-device","market research","questionnaire design","mobile survey","smartphone","panel survey"],"title":"Mobile-only web survey respondents","type":"post"},{"authors":["Lynn","P.","and Lugtig","P."],"categories":[],"content":"","date":1486335600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486335600,"objectID":"5042d3339b9d85874f608e16e85b9f2e","permalink":"https://peterlugtig.com/publication/2017_lynn_total_survey_error_for_longitudinal/","publishdate":"2017-02-06T00:00:00+01:00","relpermalink":"/publication/2017_lynn_total_survey_error_for_longitudinal/","section":"publication","summary":"","tags":[],"title":"Total survey error for longitudinal surveys","type":"publication"},{"authors":["Defoe","I.N.","Dubas","J.S.","Somerville","L.","Lugtig","P.","and Van Aken","M.A.G."],"categories":[],"content":"","date":1480546800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480546800,"objectID":"b9d6e47e7d91efa15b1fcd8a82eafb2b","permalink":"https://peterlugtig.com/publication/2016_defoe_the_unique_role_of_cognitive/","publishdate":"2016-12-01T00:00:00+01:00","relpermalink":"/publication/2016_defoe_the_unique_role_of_cognitive/","section":"publication","summary":"Adolescence is a vulnerable period for the initiation and peak of many harmful risk-taking behaviors such as smoking, which is among the most addictive and deadliest behaviors. Generic metatheories like the theory of triadic influence (TTI) suggest that interrelated risk factors across multiple domains (i.e., intrapersonal and social/environmental) jointly contribute to adolescent smoking behavior. Yet, studies are lacking that investigate risk factors across different domains in the same study, which obscures whether each makes a unique contribution to the increase in smoking throughout adolescence or whether there is overlap across the domains. Hence, to fill this gap using a latent growth approach, the current accelerated longitudinal study investigated the collective contribution of multiple intrapersonal and social risk factors in the development of smoking behavior from ages 12 to 17 in 574 ethnically diverse Dutch adolescents. Results from the latent growth model showed that whereas the contribution of motivational-intrapersonal factors like sensation-seeking was no longer significant in the stringent multivariate model, higher levels of impulsivity (cognitive-intrapersonal) and overt peer pressure (social) at age 12 proved to be robust and unique predictors of linear increases in adolescent smoking up until age 17. Consistent with the TTI, adolescent smoking progression does not occur in isolation and the determinants are wide-ranging as they stem from both intrapersonal and social domains. Thus focusing on such confluence of intrapersonal and social risk factors via prevention programs from as young as age 12 might halt the deadly increase in smoking behavior throughout adolescence.","tags":[],"title":"The unique roles of intrapersonal and social factors in adolescent smoking development","type":"publication"},{"authors":["Van Ditzhuijzen","J. van","ten Have","M.","de Graaf","R.","Lugtig","P","Nijnatten","C.H.C.J. van","and Vollebergh","W.A.M."],"categories":[],"content":"","date":1476140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476140400,"objectID":"859c2b32afefc89f6fdb7fbaf89a4c50","permalink":"https://peterlugtig.com/publication/2017_van_ditzhuijzen_incidence_and_recurrence/","publishdate":"2016-10-11T00:00:00+01:00","relpermalink":"/publication/2017_van_ditzhuijzen_incidence_and_recurrence/","section":"publication","summary":"Research in the field of mental health consequences of abortion is characterized by methodological limitations. We used exact matching on carefully selected confounders in a prospective cohort study of 325 women who had an abortion of an unwanted pregnancy and compared them 1-to-1 to controls who did not have this experience. Outcome measures were incidence and recurrence of common DSM-IV mental disorders (mood, anxiety, substance use disorders, and the aggregate measure ‘any mental disorder’) as measured with the Composite International Diagnostic Interview (CIDI) version 3.0, in the 2.5–3 years after the abortion. Although non-matched data suggested otherwise, women in the abortion group did not show significantly higher odds for incidence of ‘any mental disorder’, or mood, anxiety and substance use disorders, compared to matched controls who were similar in background variables but did not have an this experience. Having an abortion did not increase the odds for recurrence of the three disorder categories, but for any mental disorder the higher odds in the abortion group remained significant after matching. It is unlikely that termination of an unwanted pregnancy increases the risk on incidence of common mental disorders in women without a psychiatric history. However, it might increase the risk of recurrence among women with a history of mental disorders.","tags":[],"title":"Incidence and recurrence of common mental disorders after abortion: Results from a prospective cohort study","type":"publication"},{"authors":["Padilla","J.L.","and Lugtig","P."],"categories":[],"content":"","date":1475622000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475622000,"objectID":"90039d4143f4de58b951811edc6d60ef","permalink":"https://peterlugtig.com/publication/2016_padilla_trends_and_challenges_for_methodology/","publishdate":"2016-10-05T00:00:00+01:00","relpermalink":"/publication/2016_padilla_trends_and_challenges_for_methodology/","section":"publication","summary":"","tags":[],"title":"Trends and challenges for Methodology","type":"publication"},{"authors":["Lugtig","P.","Toepoel","V.","and Amin","A."],"categories":[],"content":"","date":1475276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475276400,"objectID":"1377bb2a4858150b3769ee9432577c7e","permalink":"https://peterlugtig.com/publication/2016_lugtig_mobile_only_web_respondents/","publishdate":"2016-10-01T00:00:00+01:00","relpermalink":"/publication/2016_lugtig_mobile_only_web_respondents/","section":"publication","summary":"Web surveys are no longer completed on just a desktop or laptop computer. Respondents increasingly use mobile devices, such as tablets and smartphones to complete web surveys. In this article, we study how respondents in the American Life Panel complete surveys using varying devices. We show that about 30 percent of respondents sometimes complete surveys on a mobile device, and about 12 percent always use a mobile device. We study the characteristics of these “mobile-only” web survey respondents, and find that they share many characteristics of typically hard-to-recruit survey respondents. They are more likely to be non-white, young, and not have a higher education. In terms of voting behavior we find no differences between the groups of survey respondents who use different devices. This suggests that biases in political polls conducted through web-surveys are unlikely to occur when mobile-only respondents are underrepresented.","tags":[],"title":"Mobile-only web respondents","type":"publication"},{"authors":["Lynn","P.","and Lugtig","P."],"categories":[],"content":"","date":1473202800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473202800,"objectID":"6ca1ccc1b64c262d85010ce898248274","permalink":"https://peterlugtig.com/publication/2016_lynn_total_survey_error/","publishdate":"2016-09-07T00:00:00+01:00","relpermalink":"/publication/2016_lynn_total_survey_error/","section":"publication","summary":"This article describes the application of the total survey error paradigm to longitudinal surveys. Several aspects of survey error, and of the interactions between different types of  error, are distinct in the longitudinal survey context. Furthermore, error trade-off decisions in survey design and implementation are subject to some unique considerations. Previous literature on total survey error mostly fails to explicitly consider uniquely longitudinal issues. We aim to show how uniquely longitudinal sources of error in surveys should be understood within the Total Survey Error framework and we provide examples of studies of some of the unique interactions between errors.","tags":[],"title":"Total Survey Error for longitudinal surveys","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://peterlugtig.com/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://peterlugtig.com/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["admin"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started  📚 View the documentation  💬 Ask a question on the forum  👥 Chat with the community  🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic  💡 Request a feature or report a bug  ⬆️ Updating? View the Update Guide and Release Notes  ❤ Support development of Academic:  ☕️ Donate a coffee  💵 Become a backer on Patreon  🖼️ Decorate your laptop or journal with an Academic sticker  👕 Wear the T-shirt  👩‍💻 Contribute        Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements  Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown , Jupyter , or RStudio  Plugin System - Fully customizable color and font themes  Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics , Disqus commenting , Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable .\nEcosystem   Academic Admin : An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts : Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)   install on your computer using Git with the Command Prompt/Terminal app   install on your computer by downloading the ZIP files   install on your computer with RStudio   Then personalize and deploy your new site .\nUpdating  View the Update Guide .\nFeel free to star the project on Github to help keep track of updates .\nLicense Copyright 2016-present George Cushen .\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"59ebcbd1972b28e20a326a0e113ad994","permalink":"https://peterlugtig.com/teaching/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/teaching/getting-started/","section":"teaching","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"teaching"},{"authors":null,"categories":null,"content":"Why we should throw out most of what we know on how to visually design web surveys\nIn 2000, web surveys looked like postal surveys stuck onto a screen. Survey researchers needed time to get used to the idea that web surveys should perhaps look differently from mail surveys. When I got into survey methodology in 2006, everyone was for example still figuring out whether to use drop down menus (no), how many questions to put on one screen (a few at most), let alone whether to use slider bars (it\u0026rsquo;s not going to reduce breakoffs).\nWe now know that good web surveys don\u0026rsquo;t look like mail surveys. Proponents of \u0026lsquo;gamification\u0026rsquo; in surveys argue that survey researchers are still underusing the potential of web surveys. Perhaps they are right. So, while web surveys are ubiquitous, and have been around for almost 20 years, we still don\u0026rsquo;t exactly know to to visually design them.\nThe next challenge is already upon us. How are we going to deal with the fact that so many surveys are now being completed on different devices than computers? Touch screens are getting more popular, and screens for smartphones can be as small as 4 inches. People are nowadays using all kinds of devices to complete surveys . The rules for how a questionnaire should look like on a 21 inch desktop monitor are in my view not the same however as for a 5 inch Iphone.\nJust take the following picture as an example. It was taken from the Dutch LISS panel in 2013, before they came up with a new and much better design for mobile surveys. Yes this is still what many people still see when they answer a survey question on a smartphone. Is this the way to do it? Probably not. Why should there be a \u0026lsquo;next\u0026rsquo; (verder) button at the bottom of the page? Can\u0026rsquo;t we redesign the answer scale so that we use more space on the screen?\nSmall touchscreens ask for a different design. Take the picture below. Tiles are used instead of small buttons, so that the entire screen is used. There is no next button; once you press a tile the next questions shows up. To me this looks better, but is it really? Only proper (experimental) research can tell.\nI also still see lots of problems with adapting our visual design to smartphones. Where to put the survey question in the example below? On a separate page? What if respondents tick a wrong answer? And, what if some respondents get this question on a PC? Should the questions look the same to minimize measurement differences, or be optimized for each device separately? Web surveys are dead. Mixed-device surveys are here to stay.\n  I think there are lots of opportunities for exciting research on how to design surveys for the new era of mixed-device surveys. For anyone interested, I recently edited an open-access special issue on mixed-device surveys together with Vera Toepoel, where different authors for example study:\n - why using slider bars is a bad idea for (mobile) surveys - the effects of device switching within longitudinal surveys ( study 1 and study 2 ) on data quality\n- different possible visual designs for implementing mixed-device surveys , and their effects on data quality\nThese studies are just the beginning. Much more is necessary, and it will take trial, error and probably another 15 years before we have figured out how to design surveys for mixed-device surveys properly.\n","date":1455140520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1455140520,"objectID":"74503472c74ac292893a9dd7ffd933a9","permalink":"https://peterlugtig.com/post/the-old-web-survey-is-dead/","publishdate":"2016-02-10T22:42:00+01:00","relpermalink":"/post/the-old-web-survey-is-dead/","section":"post","summary":"Why we should throw out most of what we know on how to visually design web surveys\nIn 2000, web surveys looked like postal surveys stuck onto a screen. Survey researchers needed time to get used to the idea that web surveys should perhaps look differently from mail surveys. When I got into survey methodology in 2006, everyone was for example still figuring out whether to use drop down menus (no), how many questions to put on one screen (a few at most), let alone whether to use slider bars (it\u0026rsquo;s not going to reduce breakoffs).","tags":["measurement error","mixed-device","mode effect","smartphone","mixed mode"],"title":"The traditional web survey is dead","type":"post"},{"authors":["De Leeuw","E.D.","and Lugtig","P."],"categories":[],"content":"","date":1450393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450393200,"objectID":"2af4c585f2c1fd64f70d22cb5195aa9c","permalink":"https://peterlugtig.com/publication/2015_de_leeuw_dropouts_in_longitudinal_data/","publishdate":"2015-12-18T00:00:00+01:00","relpermalink":"/publication/2015_de_leeuw_dropouts_in_longitudinal_data/","section":"publication","summary":"Different types of nonresponse threaten the validity of longitudinal studies: first,initial nonresponse during the recruitment in the baseline survey and second, successivedropout at each time point. Dropout in longitudinal surveys has three separate sources:failure to locate research participants, failure to contact participants, and failure to achievecooperation. In this entry, specific attention is given to existing knowledge on the corre-lates of dropout and strategies to limit the problem. To limit nonresponse, a total designapproach is advocated with specific attention to each source. That is to limit both noncon-tact (i.e., failure to locate and subsequent failure to contact a located research participant)and noncooperation.","tags":[],"title":"Dropouts in longitudinal surveys","type":"publication"},{"authors":null,"categories":null,"content":"Back after a long pause. Panel surveys traditionally interview respondents at regular intervals, for example monthly or yearly. This interval is mostly chosen for practical reasons: interviewing people more frequently would lead to a large respondent burden, and a burden on data processing and dissemination. For these practical reasons, panel surveys often space their interviews one year apart. Many of the changes (e.g. changes in household composition) we as researchers are interested in occur slowly, and annual interviews suffice to capture these changes.\nSometimes we want to get reports at a more detailed level, however. For example, we would like to know how often a respondents visits a doctor (general practitioner) in one year, or when a respondent went on holidays. In order to get at such an estimate, survey researchers can do one of several things:\n1. we can ask a respondent to remember all doctor visits in the past year, and rely on retrospective recall. We know that doesn\u0026rsquo;t work very well, because respondents cannot remember all visits. Instead, respondents will rely on rounding, guessing and estimation to come to an estimate.\n2. we can ask respondents for visits in say the past month, and rely on extrapolation to get to an annual estimate. This strategy works well if doctor visits are stable throughout the year (which they are not).\n3. We can try to break down the year into months, and instead of asking for doctor visits in the last year, ask for doctor visits in each month, reducing the reference period. We can stimulate the retrieval of the correct information further by using a timeline or by the use of landmarks.\n4. We can interview respondents more often. So, we conduct 12 monthly interviews instead of one annual interview, thereby reducing both the reference and recall period.\nWith Tina Glasner and Anja Boeve , I recently published a paper that compared methods 1, 3 and 4 within the same study to estimate the total number of doctor (family physician) visits. This study is unique in the sense that we used all three methods within the same respondents, so for each respondents we can see how reporting is different when we rely on annual recall, monthly recall, and on whether we use an annual or monthly reference period. Our study also included an experiment to see whether timelines and landmarks improved recall.\nYou can find the full paper here .\nWe find that respondents give different answers about their doctor visits depending on how we ask them. The estimates for annual visits are;\n- annual estimate (1 question): 1.96 visits\n- monthly estimate with 12-month recall: 2.62 visits\n- monthly estimate with 1-month recall: 3.90 visits\nThe average number of doctor visits in population registers is 4.66, so the monthly estimate with 1 month-recall periods comes closest to our population estimate.\nAs a final step, we were interested in understanding which respondents give different answers depending on the question format. For this, we studied the within-person absolute difference between the monthly estimates with a 12-month and 1-month recall period. The table below shows that the more frequent doctor visits are, the larger the differences between the 1 month and 12-month recall periods. This implies that respondents with more visits tend to underreport them more often when the recall period is long. The same holds for people in moderate and good health. People in bad health often go to the doctor regularly, and remember these visits. More infrequent visits are more easily forgotten. Finally, we find that the results of our experiment are non-significant. Offering respondents personal landmarks, and putting these next to the timeline to improve recall, does not lead to smaller differences.\n  In practice, these findings may be useful when one is interested in estimating frequencies of behavior over an annual period. Breaking up the \u0026lsquo;annual-estimate\u0026rsquo; question into twelve monthly questions helps to improve data quality. Asking about such frequencies at 12 separate occasions further helps, but this is unlikely to be feasible due to the large increased costs of more frequent data collection. In self-administered web-surveys this might however be feasible. Splitting up questionnaires into multiple shorter ones may not only reduce burden, but can increase data quality for specific survey questions as well.\n","date":1448974260,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448974260,"objectID":"61a5a304908e4d355432fa24a25c7748","permalink":"https://peterlugtig.com/post/retrospective-reporting/","publishdate":"2015-12-01T13:51:00+01:00","relpermalink":"/post/retrospective-reporting/","section":"post","summary":"Back after a long pause. Panel surveys traditionally interview respondents at regular intervals, for example monthly or yearly. This interval is mostly chosen for practical reasons: interviewing people more frequently would lead to a large respondent burden, and a burden on data processing and dissemination. For these practical reasons, panel surveys often space their interviews one year apart. Many of the changes (e.g. changes in household composition) we as researchers are interested in occur slowly, and annual interviews suffice to capture these changes.","tags":["measurement error","recall","survey error","data quality","measurement","panel survey"],"title":"Retrospective reporting","type":"post"},{"authors":["Toepoel","V.","and Lugtig","P."],"categories":[],"content":"","date":1448924400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448924400,"objectID":"5b667f93fa1e5c14c1a9ebd626545a38","permalink":"https://peterlugtig.com/publication/2015_toepoel_online_surveys_are_mixed_device/","publishdate":"2015-12-01T00:00:00+01:00","relpermalink":"/publication/2015_toepoel_online_surveys_are_mixed_device/","section":"publication","summary":"Survey research is changing in a more rapid pace than ever before, and the continuous and exponential growth in technological developments is not likely to slow down. Online surveys are now being completed on a range of different devices: PC, laptops, tablets, mobile phones or hybrids between these devices. Each device varies in screen sizes, modes of operationalization and technological possibilities. We define online surveys that are in practice being completed on different devices as mixed-device surveys. This special issue discusses issues in the design and implementation of mixed-device surveys, with the aim to bring survey research to the next level: in our view all web surveys should from now be thought of as mixed-device surveys. Theory and best practices for mixed-device surveys are still in its infancy. The current state of knowledge about the dynamics of taking surveys on mobile devices is not as advanced as necessary in times of rapid change. While current technology opens great possibilities to collect data via text, apps, and visuals, there is little scientific research published about the actual uses and best practices of these applications to increase data quality. Researchers and survey methodologists in particular need to find ways to keep up with fast changing technologies.","tags":[],"title":"Online surveys are Mixed-Device surveys. Issues associated with the use of different mobile devices in web surveys","type":"publication"},{"authors":["Lugtig","P.","and Balluerka","N."],"categories":[],"content":"","date":1443481200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443481200,"objectID":"e81cdf5077a50ccc755a22c329d11354","permalink":"https://peterlugtig.com/publication/2015_lugtig_methodology_turns_10/","publishdate":"2015-09-29T00:00:00+01:00","relpermalink":"/publication/2015_lugtig_methodology_turns_10/","section":"publication","summary":"Since its inception in February 2005, Methodology, the official journal of the European Association of Methodology, has been an online journal with a strong European vocation and dedication ‘‘to promote research and the development of empirical research methods in the fields of behavioral, social, educational, health and economic sciences, as well as in the field of evaluation research’’ (Ato \u0026 Eid, 2005; Ato \u0026 Hox, 2009). In 2009, the then editors of Methodology, Manuel Ato and Joop Hox, wrote an editorial in which they looked back at the first 4 years of Methodology (Ato \u0026 Hox, 2009). Now, 6 years later, two different editors, Peter Lugtig of Utrecht University and Nekane Balluerka of the University of the Basque Country, have taken over the editorship of Methodology. As Methodology celebrates its 10th birthday, it is time to look back and forward.","tags":[],"title":"Methodology turns 10","type":"publication"},{"authors":["Fikkers","K.M.","Piotrowski","J.T.","Lugtig","P.","and Valkenburg","P.M."],"categories":[],"content":"","date":1441926000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441926000,"objectID":"d972c60769b0f102029a1313a3ce5dcc","permalink":"https://peterlugtig.com/publication/2016_fikkers_the_role_of_perceived/","publishdate":"2015-09-11T00:00:00+01:00","relpermalink":"/publication/2016_fikkers_the_role_of_perceived/","section":"publication","summary":"This study investigates the role of a social context variable, perceived peer norms, in the relationship between media violence exposure and adolescents' aggressive behavior. This was informed by a need to better understand whether, how, and for whom, media violence exposure may affect aggression. Three hypotheses were tested with peer norms as moderator, as mediator, and as both moderator and mediator in the relationship between media violence and aggression. A two-wave longitudinal survey measured media violence exposure, perceived descriptive and injunctive norms, and aggressive behavior among 943 adolescents (aged 10–14, 50.4% girls). Results provided support only for the moderated-mediation model. The indirect effect of media violence on aggression via perceived peer approval of aggression (i.e., injunctive norms) was moderated by perceived prevalence of peer aggression (i.e., descriptive norms). Specifically, media violence indirectly increased aggressive behavior for adolescents who perceived more peer aggression, but decreased aggression for adolescents who perceived less peer aggression. Implications for future research into media violence effects are discussed.","tags":[],"title":"The role of perceived peer norms in the relationship between media violence exposure and adolescents’ aggression","type":"publication"},{"authors":["Lugtig","P.","Glasner","T.","and Boevé","A."],"categories":[],"content":"","date":1441407600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441407600,"objectID":"d29bc858b5401cc2cf8c4bf21f1b2e71","permalink":"https://peterlugtig.com/publication/2015_lugtig_reducing_underreports_of_behaviors/","publishdate":"2015-09-05T00:00:00+01:00","relpermalink":"/publication/2015_lugtig_reducing_underreports_of_behaviors/","section":"publication","summary":"","tags":[],"title":"Reducing underreports of behaviors in retrospective surveys: The effects of three different strategies","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"7704f97801627807cc0e343cfd0736c4","permalink":"https://peterlugtig.com/teaching/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/teaching/2015-07-23-r-rmarkdown/","section":"teaching","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"teaching"},{"authors":null,"categories":null,"content":"This is a follow-up on why I think panel surveys need to adapt their data collection strategies to target individual respondents . Let me first note that apart from limiting nonresponse error, there are other reasons why we would want to do this. We can limit survey costs by using expensive survey resources only for people who need them.\nA focus on nonresponse alone can be too limited. For example: imagine we want to measure our respondents\u0026rsquo; health. We can maybe do this cheaply by using web interviews, and then try to limit nonresponse error by using interviewers to convert initial nonrespondents. But what about measurement? If we use web surveys we largely have to rely on self-reports on the respondents\u0026rsquo; health. But if we use interviewers for everyone and do a Face-to-Face survey among all our respondents, we can use the interviewers to obtain objective health measures for respondents. These objective measurements could be much better than the self-reports. So face-to-face interviews may not be \u0026lsquo;worth\u0026rsquo; the cost if we look at nonresponse alone, but if we also include the effects on measurement, it may be a viable interview option, if we reduce the sampling size.\nI think a focus just on any one type of survey error can have adverse effects, and it is Total Survey Error as well as costs we need to keep in mind. Having said this, I really believe nonresponse errors in panel surveys are a huge problem. What could we do (and have others done)?\n1. Targeted mode. Some respondents are easy to reach in all modes, and some are difficult in all modes. There is also a \u0026lsquo;middle\u0026rsquo; group, who may participate in some modes, but not others. I, for example dislike web surveys (because I get so many), but appreciate mail surveys (because I never get them). In a panel survey, we can ask respondents about mode preferences. Some studies\n( here , here ) have found that stated mode preferences are not very predictive of response in that mode in the next wave, as people indicate to prefer the mode they are interviewed in. This means we probably need a better model than just \u0026lsquo;mode preference\u0026rsquo; to make this work.\n  Probably wants a different survey mode next time.\n 2. Targeted incentives. We know some respondents are \u0026lsquo;in it\u0026rsquo; for the money, or at least are sensitive to offers of incentives. In panel surveys, we can learn quickly about this by experimenting with amounts both between and/or within persons. For example, does it help to offer higher incentives to hard-to-reach respondents? Does that help just once, or is there a persistent effect? It may be unethical to offer higher incentives to just hard-to-reach respondents, as we then put a premium on bad respondent behavior. We could however use different metrics for deciding whom to offer the incentive. Nonresponse bias is a much better indicator for example. There is not too much we know about how to do this, although there is a nice example here. 3. Targeted advance letters. We know quite a lot about the effects different types of advance letters have on subsequent response. Young people can for example be targeted with a letter with a flashy lay-out and short bites of information of the study, while older people may prefer a more \u0026lsquo;classic\u0026rsquo; letter with more extensive information about the study setup and results.\nThe effects of targeted letters on response in panel surveys are often small, and only present for specific subgroups. See here , and here for two examples. Still, this type of targeting costs little, perhaps we can find bigger effects if we know what groups to target with what message. As with other targeting methods, we need a combination of data mining and experimentation to develop knowledge about this.\n4. Targeted tracking. I am not aware of any survey doing targeted tracking. Tracking is done during fieldwork. Respondents who are not located by an interviewer (or advance letter which bounce), are sent back to the study coordinating team, after which tracking methods are used to locate the respondent at an alternative address. From the literature we know that it is mainly people who move house who need tracking. If we can successfully predict the likelihood to move, we could potentially save time (and money) in fieldwork, by putting cases into preventive tracking. We could also potentially use a targeted order of tracking procedures, as James Wagner has done.   -\n","date":1432126800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432126800,"objectID":"719d19a4f6761162eeab476cd75ecc4c","permalink":"https://peterlugtig.com/post/adaptive-designs-4-ways-to-improve/","publishdate":"2015-05-20T15:00:00.002+02:00","relpermalink":"/post/adaptive-designs-4-ways-to-improve/","section":"post","summary":"This is a follow-up on why I think panel surveys need to adapt their data collection strategies to target individual respondents . Let me first note that apart from limiting nonresponse error, there are other reasons why we would want to do this. We can limit survey costs by using expensive survey resources only for people who need them.\nA focus on nonresponse alone can be too limited. For example: imagine we want to measure our respondents\u0026rsquo; health.","tags":["measurement error","nonresponse error","adaptive design","panel survey"],"title":"Adaptive designs: 4 ways to improve panel surveys","type":"post"},{"authors":["Lugtig","P.","and Toepoel","V."],"categories":[],"content":"","date":1424905200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424905200,"objectID":"624a98ac4c75289cc90b141abc056780","permalink":"https://peterlugtig.com/publication/2016_lugtig_the_use_of_pcs_smartphones/","publishdate":"2015-02-26T00:00:00+01:00","relpermalink":"/publication/2016_lugtig_the_use_of_pcs_smartphones/","section":"publication","summary":"Respondents in an Internet panel survey can often choose which device they use to complete questionnaires: a traditional PC, laptop, tablet computer, or a smartphone. Because all these devices have different screen sizes and modes of data entry, measurement errors may differ between devices. Using data from the Dutch Longitudinal Internet Study for the Social sciences panel, we evaluate which devices respondents use over time. We study the measurement error associated with each device and show that measurement errors are larger on tablets and smartphone than on PCs. To gain insight into the causes of these differences, we study changes in measurement error over time, associated with a switch of devices over two consecutive waves of the panel. We show that within individuals, measurement errors do not change with a switch in device. Therefore, we conclude that the higher measurement error in tablets and smartphones is associated with self-selection of the sample into using a particular device.","tags":[],"title":"The use of PCs, smartphones and tablets in a probability-based panel survey. Effects on survey measurement error","type":"publication"},{"authors":null,"categories":null,"content":"Last week, I gave a talk at Statistics Netherlands (slides here ) about panel attrition. Initial and nonresponse and dropout from panel surveys have always been a problem. A famous study by Groves and Peytcheva ( here ) showed that in cross-sectional studies, nonresponse rates and nonresponse bias are only weakly correlated. In panel surveys however, all the signs are there that dropout in a panel study is often related to change. Those respondents undergoing most change, are also most likely to drop out. This is probably partly because of respondents (e.g. a move of house could be a good reason to change other things as well, like survey participation), but it is also because of how surveys deal with such moves. Movers are much harder to contact (if we don\u0026rsquo;t have accurate contact details anymore). Movers are often assigned to a different interviewer. This will all lead to an underestimate of the number of people who move house in panel studies. Moving house is associated with lots of other life events (change in household composition, change in work, income etc.). In short dropout is a serious problem in longitudinal studies.\nThe figure below shows the cumulative response rates for some large-scale panel studies. The selection of panel studies is a bit selective. I have tried to focus on large panel studies (so excluding cohort studies), which are still existing today, with a focus on Western Europe.   Cumulative nonresponse rates in large panel surveys (click to enlarge)\nThe oldest study in the figure (PSID) has the highest initial response rate, followed by studies which were started in the 1980s (GSOEP), 1990s (BHPS), and early 2000s (HILDA). The more recent studies all have higher initial nonresponse rates. But not only that. They also have higher dropout rates (the lines go down much faster). This is problematic.\nI think these differences are not due to the fact that we, as survey methodologists, are doing a worse job now as compared to 20 years ago. If anything, we have been trying use more resources, professionalize tracking, offer higher incentives, and be more persistent. In my view, the increasing dropout rates are due to changes in society (the survey climate). A further increase of our efforts (e.g. higher incentives) could perhaps help somewhat to reduce future dropout. I think this is however not the way to go, especially as budgets for data collection face pressures everywhere.\nThe way to reduce panel dropout is to collect data in a smarter way. First, we need to understand why people drop out. This is something we know quite well (but more can be done). For example, we know that likely movers are at risk. So, what we need are tailored strategies that focus on specific groups of people (e.g. likely movers). For example, we could send extra mailings in between waves only to them. We could use preventive tracking methods. We could put these into the field earlier.\nI am not the first to suggest such strategies. We have been tailoring our surveys for ages to specific groups, but have mostly done so at an ad-hoc basis, never systematically. Responsive or adaptive designs try to use tailoring systematically , for those groups that most benefit from tailoring. Because we know so much about our respondents after wave 1, panel studies offer lots of opportunities to implement responsive designs.\n","date":1421850060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1421850060,"objectID":"45d9df1e33bc95ba41e654017544ecc7","permalink":"https://peterlugtig.com/post/why-panel-surveys-need-to-go-adaptive/","publishdate":"2015-01-21T15:21:00.002+01:00","relpermalink":"/post/why-panel-surveys-need-to-go-adaptive/","section":"post","summary":"Last week, I gave a talk at Statistics Netherlands (slides here ) about panel attrition. Initial and nonresponse and dropout from panel surveys have always been a problem. A famous study by Groves and Peytcheva ( here ) showed that in cross-sectional studies, nonresponse rates and nonresponse bias are only weakly correlated. In panel surveys however, all the signs are there that dropout in a panel study is often related to change.","tags":["attrition","Don Dillman","responsive design","adaptive design","panel survey"],"title":"why panel surveys need to go 'adaptive'","type":"post"},{"authors":null,"categories":null,"content":"Last week, I wrote about the fact that respondents in panel surveys are now using tablets and smartphones to complete web surveys . We found that in the LISS panel, respondents who use tablets and smartphones are much more likely to switch devices over time and not participate in some months.\nThe question we actually wanted to answer was a different one: do respondents who complete surveys on their smartphone or mobile give worse answers?\nTo do this, we used 6 months of data from the LISS panel, and in each month, coded the User Agent String. We then coded types of satisficing behavior that occur in surveys: the percentage of item missings, whether respondents complete (non-mandatory) open questions, how long their answers were, whether respondents straightline, whether they go for the first answers in a check-all-that-apply questions, and how many answers they click in a check-all-that apply question. We also looked at interview duration, and how much respondents liked the survey.\nWe found that respondents on a smartphone seem to do much worse. They take longer to complete the survey, are more negative about the survey, have more item missings, and have a much higher tendency to pick the first answer. On the other questions, differences were small, sometimes in favor of the smartphone user.\n  Click to enlarge: indicators of satisficing per device in LISS survey\nIs this effect due to the fact that the smartphone and tablet are not made to complete surveys, and is satisficing higher because of a device-effect? Or is it a person effect, and are worse respondents more inclined to do a survey on a tablet or smartphone?\nIn order to answer this final question, we looked at device-transitions that respondents take within the LISS panel. In the 6 months of the LISS, respondents can make 5 transitions from using 1 device in the one month, to another (or the same) device in the next. For 7 out of 9 transitions (we have too few observations to analyze the tablet -\u0026gt; phone and phone -\u0026gt; tablet transitions), we can then look at the difference in measurement error that is associated with a change in device.\n  Click to enlarge. Changes in data quality (positive is better) associated with change in device.\nThe red bars indicate that there is no significant change in measurement error associated with a device change. Our conclusion is that device changes do not lead to more measurement error, with 2 exceptions:\n1. A transition from tablet -\u0026gt; PC or phone -\u0026gt; PC in two consecutive months, leads to a better evaluation of the questionnaire. This implies that the user experience of completing web surveys on a mobile device should be improved.\n2. We find that people check more answers in a check-all-that-apply question when they move from a tablet -\u0026gt; PC, or phone -\u0026gt; PC\nSo, in short. Satisficing seems to be more problematic when surveys are completed on tablets and phones. But this can almost fully be explained by a selection effect. Those respondents who are worse completing surveys, choose to complete surveys more on tablets and smartphones.\nThe full paper can be found here ","date":1418068020,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1418068020,"objectID":"1aa510c59bd8dc7d1f9af130202d8f56","permalink":"https://peterlugtig.com/post/blog-post/","publishdate":"2014-12-08T20:47:00.002+01:00","relpermalink":"/post/blog-post/","section":"post","summary":"Last week, I wrote about the fact that respondents in panel surveys are now using tablets and smartphones to complete web surveys . We found that in the LISS panel, respondents who use tablets and smartphones are much more likely to switch devices over time and not participate in some months.\nThe question we actually wanted to answer was a different one: do respondents who complete surveys on their smartphone or mobile give worse answers?","tags":["User agent strings","measurement error","mobile survey","common causes of survey error","data quality","mixed mode","panel survey"],"title":"Satisficing in mobile web surveys. Device-effect or selection effect?","type":"post"},{"authors":null,"categories":null,"content":" Vera Toepoel and I have been writing a few articles over the last two years about how survey respondents are taking up tablet computers and smartphones. We were interested in studying whether people in a probability-based web panel ( the LISS panel ) use different devices over time, and whether siwtches in devices for completing surveys are associated with more or less measurement error.\nIn order to answer this question, we have coded the User Agent Strings of the devices used by more than 6.000 respondents over a six month period. (see the publication tab for a syntax on how to do this using R).\nWe find, as others have done, that in every wave about 10% of respondents either use a tablet or smartphone. What is new in our analyses is that we focus on the question whether respondents persistently use the same device.\nThe table below shows that PC users largely stick to their PC in all waves. For example, we see that 77.4% of PC-respondents in April, again use a PC in May. Only 1.5% of April’s PC respondents switch to either a tablet or smartphone to complete a questionnaire in May.\nTable. Devices used between April and September 2013 by LISS panel respondents.\n  N = 6,226. Click to enlarge\nThe proportion of respondents switching a PC for either a tablet or smartphone is similarly low in the other months, and is never more than 5%. This stability in device use for PCs is, however, not found for tablets and smartphones. Once people are using a smartphone in particular, they are not very likely to use a smartphone in the next waves of LISS. Only 29 per cent of smartphone users in July 2013, again uses a smartphone in August for example. The consistency of tablet usage increases over the course of the panel; 24% of respondent is a consistent tablet user in April-May, but this increases to 64% in July-August.\nFinally, it is worth to note that the use of either a smartphone or a tablet is more likely to lead to non-participation in the next wave of the survey. This may however be a sample selection effect. More loyal panel members may favor the PC to complete the questionnaires.\nMore in a next post on the differences between respondents answer behavior over time, when they switch devices. Do respondents become worse when they answer a survey on a smartphone or tablet?\nYou can download the full paper here ","date":1417531440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417531440,"objectID":"4311ea6878813e815c054372f1b0f906","permalink":"https://peterlugtig.com/post/what-devices-do-respondents-use-over/","publishdate":"2014-12-02T15:44:00+01:00","relpermalink":"/post/what-devices-do-respondents-use-over/","section":"post","summary":"Vera Toepoel and I have been writing a few articles over the last two years about how survey respondents are taking up tablet computers and smartphones. We were interested in studying whether people in a probability-based web panel ( the LISS panel ) use different devices over time, and whether siwtches in devices for completing surveys are associated with more or less measurement error.\nIn order to answer this question, we have coded the User Agent Strings of the devices used by more than 6.","tags":["User agent strings","measurement error","mobile survey","R","mixed mode","panel survey"],"title":"Which devices do respondents use over the course of a panel study?","type":"post"},{"authors":["Cernat","A.","Lugtig","P.","Uhrig","S.C.N.","and Watson","N."],"categories":[],"content":"","date":1409526000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409526000,"objectID":"0dd91b4bd97187b61e552df0ea4c109b","permalink":"https://peterlugtig.com/publication/2014_cernat_assessing_and_relaxing_assumptions/","publishdate":"2014-09-01T00:00:00+01:00","relpermalink":"/publication/2014_cernat_assessing_and_relaxing_assumptions/","section":"publication","summary":"The quasi-simplex model  makes use of at least three  repeated  measures of the same variable to estimate  its  reliability. The  model has  rather strict  assumptions  about how  various  parameters  in the model are related to each other. Previous studies have outlined how several of the assumptions of the quasi-simplex model may be relaxed using more than 3 waves of data. It is unclear however whether the assumptions of the quasi-simplex model are overlystrict. In other words, it is not known whether relaxing  the assumptions  results  in  better  models  or different substantive  conclusions  with regard  to the  reliability  of  survey  measures.  Using  data  from  theBritish  Household  Panel  Surveythis  paper shows how the assumptions of the quasi-simplex model can be relaxed. We conclude that relaxing the assumptions  in  practice  seldom  leads  to  a  better  model  or  different  conclusions  than  the  traditional quasi-simplex model.","tags":[],"title":"Assessing and relaxing assumptions in quasi-simplex models","type":"publication"},{"authors":null,"categories":null,"content":"I am back from some great holidays, and am revisiting some of the research I did over the last 2 years. Back then, I would have not expected that I would become so interested in doing survey research on mobile phones. I do think that a little change of research topic does one good.\nI have written two papers with Vera Toepoel on how to do surveys on mobile phones. The first question we had was whether people were actually likely to do a survey on a mobile phone. Last year, Marketresponse, a probability-based web panel in the Netherlands, had changed their survey software so that questionnaires would be dynamically adapted to mobile phone screen settings, and navigation methods. They then informed their respondents about it, and encouraged them to try a short survey on shopping behavior on their smartphone (if respondents had one).\nWe found that of those respondents who owned a smartphone, 59% chose to use it when encouraged and were positively surprised by this finding. Even with quite little encouragement, survey respondents are willing to try completing the survey on their mobile phone. Also, we found little reason to be worried about side-effects of encouraging mobile survey response.\n- We found little differences in terms of demographics between those who did the survey on a mobile phone, or a desktop (including tablets).\n- We found no differences in terms of response behavior.\n- We found no difference in how mobile and desktop respondents evaluated the questionnaire.\n- We found no difference in the time it took them to complete the survey (see the figure below). In fact, the timings were so similar, we could scarcely believe the differences were so small.\n  The full paper can be found here . There are a few potential caveats in our study: we use a sample of experienced survey respondents and did not use experimental assignments, so self-selection into device could be selective beyond the variables we studied. So far however, it really seems that web surveys on a mobile phone are not very different for respondents than traditional web surveys.\n","date":1407949560,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1407949560,"objectID":"8b0d3d3ec1274abe26cf50db27ae81b2","permalink":"https://peterlugtig.com/post/can-you-push-web-survey-respondents-to/","publishdate":"2014-08-13T19:06:00+02:00","relpermalink":"/post/can-you-push-web-survey-respondents-to/","section":"post","summary":"I am back from some great holidays, and am revisiting some of the research I did over the last 2 years. Back then, I would have not expected that I would become so interested in doing survey research on mobile phones. I do think that a little change of research topic does one good.\nI have written two papers with Vera Toepoel on how to do surveys on mobile phones. The first question we had was whether people were actually likely to do a survey on a mobile phone.","tags":["mobile survey"],"title":"Can you push web survey respondents to complete questionnaires on their mobile phones?","type":"post"},{"authors":["Mulder","B.","Poortvliet","M.","Lugtig","P.","and Bruin","M. de"],"categories":[],"content":"","date":1402527600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1402527600,"objectID":"c9f8fb5215422f6515138310d703fc2f","permalink":"https://peterlugtig.com/publication/2014_mulder_explaining_consumer_intentions/","publishdate":"2014-06-12T00:00:00+01:00","relpermalink":"/publication/2014_mulder_explaining_consumer_intentions/","section":"publication","summary":"Low public acceptance hinders the successful introduction of biotechnological innovations, such as genetically modified foods or vaccinations against infectious diseases. Earlier studies indicated that a lack of knowledge is not a key barrier to acceptance. This was confirmed in the current study, which examined an integrated theoretical model tested among 579 participants from the Dutch public. The results suggest that communication strategies should instead target attitudes, social norms, and risk perceptions, and appeal to people's tendency (or lack thereof) to be innovative.","tags":[],"title":"Explaining consumer intentions to use innovative medical and food applications: Test of an extended model of reasoned action in a survey study","type":"publication"},{"authors":null,"categories":null,"content":"Big data and new technologies to do survey research. These were in my view the two themes of the 2014 AAPOR conference . The conference organisation tried to push the theme ‘Measurement and the role of pubic opinion in a democracy’, but I don\u0026rsquo;t think the theme was really reflected in the talks at the conference. Or perhaps I have missed those talks, the conference was huge as always (\u0026gt; 1000 participants).\nThe profession of survey research is surely changing. Mick Couper last year argued that the ‘sky wasn’t falling’ on survey research, but it is evolving. Big data may potentially replace parts of survey research, especially if we don\u0026rsquo;t adapt to new technologies (mobile), and learn to use some of the data that are now found everywhere. Big data and survey research in fact have the same basic goal. To extract meaningful information out of datasets (big data) or people (survey research), and use that to inform policy making.\nBig data can certainly be useful for policy-making. Out of the 10 or so presentations that I have seen at AAPOR, most were however just talking about potential possibilities over using big data to inform policy makers.\nWhat was in my opinion missing at AAPOR were good case studies that showed how big data can replace survey research and provide valid inferences. I have seen many good earlier examples when it comes to predictions at the level of an individual using big data. When Amazon tries to recommend me books that relate to a book I have previously bought, I find these useful and accurate predictions of what I really like. In politics, voter registration records data can help politicians target likely voters for their party, as the 2012 Obama campaign showed .\nBut when it comes to aggregating big data to the level of the population, big data is often in trouble (the Obama election campaign is an outlier here, as they collect data on the whole population). Survey research has relied on the principle of random sampling from the population to draw inferences, but for big data, coverage and nonresponse errors are often unknown and unestimatible for the convenience samples that big data ususally are. Paul Biemer made this point in an excellent talk .\nMost of the other big data presentations at AAPOR to me were either in the category ‘bar talk’ - anecdotes without a scientific empirical strategy - or just talked about the potential of big data. And don’t get me wrong: I do think that big data are very useful, especially if they cover a late proportion of the population (e.g. voter records), or if the goals is prediction at the level of an individual.\nThe other conference theme seemed to be mobile surveys. With Vera Toepoel, I gave a presentation on this topic, which may be the topic of a next blogpost. Here, I think survey researchers are much better equipped to deal with the challenge mobile devices pose. I saw many excellent presentations on questionnaire design for mobile surveys, and selection bias.\nFinally, this is just my conference take-away. Some other bloggers ( here here ) seem to have a slightly different view on the conference. Probably this is due to the fact I have only seen 1 out of the 8 presentations given at any time. So be sure to check their posts out if you want to know more about the conference.\n","date":1401116700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401116700,"objectID":"5b414114c2da86bf727047273d4a89b5","permalink":"https://peterlugtig.com/post/aapor-2014/","publishdate":"2014-05-26T17:05:00+02:00","relpermalink":"/post/aapor-2014/","section":"post","summary":"Big data and new technologies to do survey research. These were in my view the two themes of the 2014 AAPOR conference . The conference organisation tried to push the theme ‘Measurement and the role of pubic opinion in a democracy’, but I don\u0026rsquo;t think the theme was really reflected in the talks at the conference. Or perhaps I have missed those talks, the conference was huge as always (\u0026gt; 1000 participants).","tags":["conference","AAPOR","big data","mobile survey"],"title":"AAPOR 2014","type":"post"},{"authors":null,"categories":null,"content":"A follow up on last month\u0026rsquo;s post . Respondents do seem to be less compliant in the waves before they drop out from a panel survey. This may however not neccesarily lead to worse data. So, what else do we see before attrition takes place? Let have a look at missing data:\nFirst, we look at missing data in a sensitive question on income amounts. Earlier studies ( here , here, here ) have already found that item nonresponse on sensitive questions predicts later attrition. I find that item nonresponse does increase before attrition, but only because of the fact that respondents are more likely to refuse to give an answer. And that increase is largely due to respondents who will later refuse to participate in the study as a whole. So, item refusals are a good predictor of later study refusals. The proportion of \u0026ldquo;Don\u0026rsquo;t know\u0026rdquo; respondents does not increase over time.\n  Missing income data in BHPS in 5 waves before attrition (click to enlarge)\nDoes this finding for a sensitive question extend to all survey questions? No. Over all questions combined, I find that refusals increase before attrition takes place, but from a very low base (see the Y-axis scale in the figure below). Moreover, there is no difference between the groups, meaning that those who drop out of the survey do not have more item-missings than those respondents who are \u0026ldquo;always interviewed\u0026rdquo;. It may seem odd that item missings increase for respondents who always happily participate. I suspect however that this may be related to the fact that both interviewers and respondents may have known in the last wave(s) that the BHPS was coming to an end after 18 years of interviewing.     Missing data for all survey questions in BHPS in waves before attrition (click to enlarge)\nWhat to do with this information? It seems that later study refusals can be identified using a combination of item nonresponses and survey compliance indicators. Once these respondents are identified, the next step would be to target them with survey design features that try to prevent attrition. These survey design features should target some of the concerns and motivations such respondents have that cause them to drop out from the survey.\n","date":1398773280,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398773280,"objectID":"032d486b39a1f449929c8c12cea3c17f","permalink":"https://peterlugtig.com/post/are-item-missings-related-to-later/","publishdate":"2014-04-29T14:08:00+02:00","relpermalink":"/post/are-item-missings-related-to-later/","section":"post","summary":"A follow up on last month\u0026rsquo;s post . Respondents do seem to be less compliant in the waves before they drop out from a panel survey. This may however not neccesarily lead to worse data. So, what else do we see before attrition takes place? Let have a look at missing data:\nFirst, we look at missing data in a sensitive question on income amounts. Earlier studies ( here , here, here ) have already found that item nonresponse on sensitive questions predicts later attrition.","tags":["missing data","measurement error","trade-off between survey errors","British Household Panel Study","attrition","responsive design","common causes of survey error","panel survey"],"title":"Are item-missings related to later attrition?","type":"post"},{"authors":["Lugtig","P.","Das","M.","and Scherpenzeel","A."],"categories":[],"content":"","date":1397170800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397170800,"objectID":"7c3030f4ef41ceb67358e70590243927","permalink":"https://peterlugtig.com/publication/2014_lugtig_nonresponse_and_attrition_in_a_probability/","publishdate":"2014-04-11T00:00:00+01:00","relpermalink":"/publication/2014_lugtig_nonresponse_and_attrition_in_a_probability/","section":"publication","summary":"Since the mid 2000s, several research organizations have set up large probability‐based online panel surveys. In these panels, individuals or households are followed over time to study change. When the respondents also represent the general population well, these panel studies can also be used to study change at the population level, or do cross‐sectional surveys of the general population.\nTo make sure that these online panels can be used to generalize study findings to the population, they start out with a probability‐based sample. After recruiting people offline, those without Internet access are then given access and a computer at home. In this way, the panel surveys will be representative of people with‐ and without Internet access.\nBoth initial nonresponse in the panel recruitment phase, and attrition over time threaten the external validity of probability‐based online surveys however. This paper uses the Dutch LISS panel as an example to investigate the extent of nonresponse and attrition bias in the panel. To do so, we separate 9 groups of respondents, who each follow a distinct pattern of dropout. Then, within each group we look at the correlates of attrition, and compare these to the correlates of initial nonresponse bias. We show that initial nonresponse and attrition are two very different processes in a probability‐based panel survey. The correlates of early attrition in the panel survey are very different from the correlates of initial nonresponse. We also find large differences between the correlates of different types of attrition, implying that attrition at various stages of the panel survey is selective.\nIn terms of the contribution to nonresponse bias, we find initial nonresponse bias to contribute more to overall nonresponse bias than attrition. The chapter concludes with a discussion of our findings and implications for survey practice.","tags":[],"title":"Nonresponse and attrition in a probability based Internet Panel for the general population","type":"publication"},{"authors":["Toepoel","V.","and Lugtig","P."],"categories":[],"content":"","date":1396393200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396393200,"objectID":"3be8ee52baa32f4a65b39d988a7d61cc","permalink":"https://peterlugtig.com/publication/2014_toepoel_what_happens_if_you_offer/","publishdate":"2014-04-02T00:00:00+01:00","relpermalink":"/publication/2014_toepoel_what_happens_if_you_offer/","section":"publication","summary":"This article reports from a pilot study that was conducted in a probability-based online panel in the Netherlands. Two parallel surveys were conducted: one in the traditional questionnaire layout of the panel and the other optimized for mobile completion with new software that uses a responsive design (optimizes the layout for the device chosen). The latter questionnaire was optimized for mobile completion, and respondents could choose whether they wanted to complete the survey on their mobile phone or on a regular desktop. Results show that a substantive number of respondents (57%) used their mobile phone for survey completion. No differences were found between mobile and desktop users with regard to break offs, item nonresponse, time to complete the survey, or response effects such as length of answers to an open-ended question and the number of responses in a check-all-that-apply question. A considerable number of respondents gave permission to record their GPS coordinates, which are helpful in defining where the survey was taken. Income, household size, and household composition were found to predict mobile completion. In addition, younger respondents, who typically form a hard-to-reach group, show higher mobile completion rates.","tags":[],"title":"What happens if you offer a mobile option to your web panel? Evidence from a probability-based panel of internet users","type":"publication"},{"authors":["Koning","I.M.","Lugtig","P.","and Vollebergh","W.A.M."],"categories":[],"content":"","date":1396306800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396306800,"objectID":"1b4aaab92071bf1e00967c71558b0312","permalink":"https://peterlugtig.com/publication/2014_koning_differential_effects_of_baseline_drinking/","publishdate":"2014-04-01T00:00:00+01:00","relpermalink":"/publication/2014_koning_differential_effects_of_baseline_drinking/","section":"publication","summary":"The effects of an intervention designed to prevent onset of weekly drinking in non drinking students (PAS) were investigated in the group of students that was already drinking at baseline. A cluster randomized trial was used including 3,490 Dutch early adolescents (M age = 12.66, SD = 0.49) randomized over four conditions; 1) parent intervention, 2) student intervention, 3) combined intervention and 4) control group. Outcome measures were amount and growth of weekly alcohol drinking measured 10, 22 and 34 months after baseline. The combined intervention significantly curbed the growth of drinking among both non-drinkers (the target group of the intervention) and drinkers at baseline. Overall, less strong increases of drinking over time are found among non-drinkers compared to drinkers at baseline. Thus, the combined PAS intervention is also effective in curbing adolescents' drinking behaviour in those who already were drinking at baseline. Broad implementation of the combined parent–student intervention is recommended.","tags":[],"title":"Differential effects of baseline drinking status: Effects of an alcohol prevention program targeting students and/or parents (PAS) among weekly drinking students","type":"publication"},{"authors":null,"categories":null,"content":"I am working on a paper that aims to link measurement errors to attrition error in a panel survey. For this, I am using the British Household Panel Survey. In an earlier post I already argued that attrition can occur for many reasons, which I summarized in 5 categories.\n1. Noncontact\n2. Refusal\n3. Inability (due to old age, infirmity) as judged by the interviewer, also called \u0026lsquo;other non-interview\u0026rsquo;.\n4. Ineligibibility (due to death, or move into institution or abroad).\n5. people who were always interviewed\nIn the paper, I study whether attrition due to any of the reasons above can be linked to increased measurement errors in the last waves before attrition. For example, earlier studies have found that item nonresponse to sensitive questions (income) predicts unit nonresponse in the next waves.\nFor every respondent in the BHPS, I coded different indicators measurement error in every of the last five waves before attrition takes place. My working hypothesis is that measurement errors should increase in the last few waves before attrition takes place, due to decreasing respondent willingness and/or capability to participate.\nIn the figure below, you find one set of indicators I used. Compliance to the survey does not count as an indicator of measurement error, but I found it interesting to look into nonetheless. I find that respondents are far less keen to do \u0026ldquo;extra\u0026rdquo; tasks in the waves before attrition. As measures, of compliance to these extra tasks, I looked at:\n1. the respondent cooperation as judged by the interviewer.\n2 the proportion of respondents who completes the tracking schedule at the end of the interview, and\n3. the proportion of respondents returning a self-completion questionnaire, left after the interview.\nIn order to be able to interpret the results in a good way, I contrasted the 4 attrition groups with the 5th group of respondents who do not drop out, and are always interviewed.\n  Compliance with survey task by respondents in last 5 waves before attrition (click to enlarge)\nUnsuprisingly, I find that compliance decreases before attrition. Even at 5 waves before attrition, I find differences between the groups, with the \u0026ldquo;always interviewed\u0026rdquo; being most compliant, and the later to \u0026ldquo;refuse\u0026rdquo; group least compliant. The differences between the groups increase, the closer they get to attrition. Of the groups that attrite, the \u0026ldquo;noncontacts\u0026rdquo; and later \u0026ldquo;ineligibles\u0026rdquo; do only a little worse than the \u0026ldquo;always interviewed\u0026rdquo;. The \u0026ldquo;refusers\u0026rdquo; and \u0026ldquo;inables\u0026rdquo; have sharply decreasing cooperation ratings, and rates of completing the tracking schedule and returning the self-completion questionnaire. The differences between the groups are not large enough to predict exactly who is going to refuse or become unable to participate, but they can help to identify respondents being at risk.\nThe next question would be what to do with this knowledge. If a respondent really is unable to participate, there is not so much we as survey practitioners can do about this. Likely refusers may also be hard to target effectively. The rate of noncontacts is to a large degree under the control of survey practitioners, and for that reason, many nonresponse researchers are trying to limit noncontacts. Although refusers may be harder to target than noncontacts, it may be easier to identify potential refusers, and take pre-emptive action, rather than use refusal conversion techniques after a respondent has refused.\n","date":1396017180,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396017180,"objectID":"af407a96ec58f782554c15557f088097","permalink":"https://peterlugtig.com/post/do-respondents-become-sloppy-before/","publishdate":"2014-03-28T15:33:00+01:00","relpermalink":"/post/do-respondents-become-sloppy-before/","section":"post","summary":"I am working on a paper that aims to link measurement errors to attrition error in a panel survey. For this, I am using the British Household Panel Survey. In an earlier post I already argued that attrition can occur for many reasons, which I summarized in 5 categories.\n1. Noncontact\n2. Refusal\n3. Inability (due to old age, infirmity) as judged by the interviewer, also called \u0026lsquo;other non-interview\u0026rsquo;.\n4. Ineligibibility (due to death, or move into institution or abroad).","tags":["measurement error","trade-off between survey errors","British Household Panel Study","compliance","attrition","responsive design","common causes of survey error","panel survey"],"title":"Do respondents become sloppy before attrition?","type":"post"},{"authors":["Scherphof","C.S.","Eijnden","R.J.J.M. van den","Lugtig","P.","Engels","R.C.M.E.","and Vollebergh","A.M."],"categories":[],"content":"","date":1393974000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1393974000,"objectID":"e825938be2d9a6ad2d55a258b302d8f3","permalink":"https://peterlugtig.com/publication/2014_scherphof_adolescents_use_of_nicotine/","publishdate":"2014-03-05T00:00:00+01:00","relpermalink":"/publication/2014_scherphof_adolescents_use_of_nicotine/","section":"publication","summary":"*Rationale* Previous research has shown limited efficacy of nicotine replacement therapy (NRT) among adolescents and generally low compliance rates. As higher compliance rates are associated with improved abstinence rates, the present study examined predictors of NRT compliance.\n*Objectives* This study aims to test whether different NRT compliance trajectories can be distinguished among adolescents, to test whether these trajectories can be predicted by demographic, smoking-related, and personality factors, and to examine abstinence rates for each trajectory.\n*Methods* Data were used from a randomized controlled trial that tested the efficacy of nicotine patches versus placebo patches among 265 Dutch adolescents. During NRT treatment, adolescents filled out six online questionnaires in which they reported on the number of days they used the patches. Predictors (i.e., demographic and smoking-related factors and personality characteristics) and end-of-treatment abstinence were also administered through these self-reports. Latent class growth analysis (LCGA) was used to analyze compliance data by classifying individuals into similar growth trajectories.\n*Results* Three compliance trajectories were found (i.e.,“compliers”(n=89),“moderate decreasers”(n=41), and “strong decreasers”(n=127)). The compliers can be characterized by higher levels of conscientiousness and agreeableness and lower levels of extraversion compared with the strong decreasers, and by higher levels of conscientiousness and education compared with the moderate decreasers. Amongthe compliers, a substantially higher percentage of adolescents achieved abstinence at end-of-treatment (10 %) compared with the moderate decreasers (3 %) and the strong decreasers(6 %).\n*Conclusions* These findings could be the starting point for person-tailored interventions that aim to enhance NRT compliance rates among adolescents.","tags":[],"title":"Adolescents’ use of nicotine replacement therapy for smoking cessation: Predictors of compliance trajectories","type":"publication"},{"authors":["Lugtig","P.","and Jäckle","A."],"categories":[],"content":"","date":1392332400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1392332400,"objectID":"db81c9569f1efd43ee9c2a307ea47085","permalink":"https://peterlugtig.com/publication/2014_lugtig_in_interview_edit_checks/","publishdate":"2014-02-14T00:00:00+01:00","relpermalink":"/publication/2014_lugtig_in_interview_edit_checks/","section":"publication","summary":"Household income is difficult to measure, since it requires the collection of information about all potential income sources for each member of a household.Weassess the effects of two types of edit check questions on measurement error and survey estimates: within-wave edit checks use responses to questions earlier in the same interview to query apparent inconsistencies in responses; dependent interviewing uses responses from prior interviews to query apparent inconsistencies over time.Weuse data from three waves of the British Household Panel Survey (BHPS) to assess the effects of edit checks on estimates, and data from an experimental study carried out in the context of the BHPS, where survey responses were linked to individual administrative records, to assess the effects on measurement error. The findings suggest that interviewing methods without edit checks underestimate non-labour household income in the lower tail of the income distribution. The effects on estimates derived from total household income, such as poverty rates or transition rates into and out of poverty, are small.","tags":[],"title":"Can I just check...? Effects of edit check questions on measurement error and survey estimates","type":"publication"},{"authors":null,"categories":null,"content":"Studies into the correlates of nonresponse often have to rely on socio-demographic variables to study whether respondents and nonrespondents in surveys differ. Often there is no other information available on sampling frames that researchers can use.\nThat is unfortunate, for two reasons. First, the variables we are currently using to predict nonrespons, usually explain a very limited amount of variance of survey nonresponse. Therefore, these variables are also not effective correctors for nonresponse. So, socio-demographic variables are not that interesting to have as sampling frame data. See my earlier posts here and here .\nIt is also unfortunate, because theoretically, we can come up with other respondent characteristics that should explain nonresponse much better. For example, whether respondents believe surveys to be important, whether they enjoy thinking (need for cognition) and whether they have a conscientious personality.\nI published a new paper today in Sociological Methods and Research, that links these variables in particular to different patterns of attrition in a longitudinal survey. See the full paper here Among the 2007 sample members of the Dutch LISS Panel , I tested for different drop out patterns, and classified respondents according to their attrition process. Some respondents are continuous respondents (stayers - on top), while others start enthusiastically, but drop out at various stages of the survey (lines going down), or never really enthusiastically participate (lurkers - erratic lines in the middle).\n  Figure 1: attrition patterns among original LISS sample members (click to enlarge)\nAs a next step, I linked the attrition classes to a set of predictors. Among them socio-demographic variables, but also psychological, and survey related ones.\nThe 3 strongest predictors of the differences between the attrition patterns (latent classes) are:\n- Personality. Conscientious and less extravert people drop out less often\n- Survey enjoyment. If people enjoy completing surveys, they are not likely to drop out.\n- Having received a PC. The LISS panel gave respondents without Internet access a computer and broadband Internet to enable them to participate. Almost none of the people who received such a computer dropped out from the study.\n In an earlier post about an upcoming book chapter, I already noted that the correlates of attrition and initial nonresponse are very different in the LISS, so personality may not explain initial nonresponse in other panel surveys or nonresponse in cross-sectional surveys.\nIt would be very hard to test my hypothesis that personality is a strong predictor of all types of nonresponse. Unless you would do a survey among employees, and have simultaneous access all personality data from tests that every job applicant at that company took. If you sit on top such data and want me to analyse them, do e-mail me.\n","date":1391789520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391789520,"objectID":"183490a1ca9adc679e7eef1d6faa64bb","permalink":"https://peterlugtig.com/post/personality-predicts-likelihood-and/","publishdate":"2014-02-07T17:12:00+01:00","relpermalink":"/post/personality-predicts-likelihood-and/","section":"post","summary":"Studies into the correlates of nonresponse often have to rely on socio-demographic variables to study whether respondents and nonrespondents in surveys differ. Often there is no other information available on sampling frames that researchers can use.\nThat is unfortunate, for two reasons. First, the variables we are currently using to predict nonrespons, usually explain a very limited amount of variance of survey nonresponse. Therefore, these variables are also not effective correctors for nonresponse.","tags":["nonresponse","attrition","nonresponse error","panel survey"],"title":"Personality predicts the likelihood and process of attrition in a panel survey","type":"post"},{"authors":["Lugtig","P."],"categories":[],"content":"","date":1391641200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391641200,"objectID":"cef480218e1e248d48dfb84b5db7f6ac","permalink":"https://peterlugtig.com/publication/2014_lugtig_panel_attrition_separating_stayers/","publishdate":"2014-02-06T00:00:00+01:00","relpermalink":"/publication/2014_lugtig_panel_attrition_separating_stayers/","section":"publication","summary":"Attrition is the process of dropout from a panel study. Earlier studies into the determinants of attrition study respondents still in the survey and those who attrited at any given wave of data collection. In many panel surveys, the process of attrition is more subtle than being either in or out of the study. Respondents often miss out on one or more waves, but might return after that. They start off responding infrequently, but more often later in the course of the study. Using current analytical models, it is difficult to incorporate such response patterns in analyses of attrition. This article shows how to study attrition in a latent class framework. This allows the separation of different groups of respondents, that each follow a different and distinct process of attrition. Classifying attriting respondents enables us to formally test substantive theories of attrition and its effects on data accuracy more effectively.","tags":[],"title":"Panel attrition: Separating stayers, fast attriters, gradual attriters and lurkers","type":"publication"},{"authors":null,"categories":null,"content":"Frauke Kreuter once commented on a presentation I gave that I should really be looking at sequence analysis for studying attrition in panel surveys. She had written an article on the topic with Ulrich Kohler ( here ) in 2009, and as of late there are more people exploring the technique (e.g. Mark Hanly at Bristol, and Gabi Durrant at Southampton ).\nI am working on a project on attrition in the British Household Panel, and linking attrition errors to measurement errors. Attrition data can be messy. Below, you see the response outcome sequences of every initial panel member in the British Household Panel Survey. This figure obscures the fact individual respondents may frequently switch states (e.g. interview - noncontact - interview - refusal - not issued).\n  Figure 1: relative sizes of final interview outcomes at 18 waves of BHPS of wave 1 respondents\nAlthough descriptive visualizations like these are informative, sequence analysis becomes analytically interesting when you try to \u0026ldquo;do\u0026rdquo; something with the sequences of information. In my case, I want to group all sequence chains into \u0026ldquo;clusters\u0026rdquo; or \u0026ldquo;classes\u0026rdquo; of people who have a similar process of attrition. Stata and R TraMineR offer possibilities for doing this. Both packages enable you to match sequences by optimal matching , so that for every sequence from every person you get a distance measure to every other sequence (person). In turn, this (huge) dustance matrix can then be used to classify all the sequences of all respondents into clusters. R offers a nice way to handle huge data matrices, by using aggregation and weighting by the way. See the WeightedCluster library.\nBelow, you find the results of the sequence analysis. The nice thing is that I end up with 6 clusters that look the same as the Classes that I got out of a Latent Class Analysis over summer. So now I feel much more confident using this classification.\n  Figure 2: 6-cluster solution for sequence analysis on BHPS attrition patterns\nThe differences between sequence analysis and LCA are really minimal, and probably result from the fact that the Optimal Matching algorithm used in sequence analysis is more flexible (in that it would allow deletion, additions, substitutions etc to match), than Latent Class Analysis. But in practice, for my analyses, it doesn\u0026rsquo;t matter what technique I use. My results are equivalent. Personally, I like Latent Class analysis more, because it offers the option of linking the Latent Classes of attrition to substantive research data in one model.\nAttrition data bear a resemblence to contact data recorded in a telephone or face-to-face survey. Interviewers make call or interview attempts, that bear a lot of information about the survey proecess, and could improve fieldwork, and reduce nonresponse and costs. I am imagining a paper where one links contact data at every wave, and combines that with attrition analyses, in a series of linked-sequence data analysis. That way, you can learn how specific sequences of call and contact data, lead to specific sequences of interview outcomes at later stages of the panel survey. It can be done if you have a lot of time.\n","date":1383578520,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1383578520,"objectID":"4086f39b7f2e61cee1a8029d62bd1539","permalink":"https://peterlugtig.com/post/longitudinal-interview-outcome-data/","publishdate":"2013-11-04T16:22:00.001+01:00","relpermalink":"/post/longitudinal-interview-outcome-data/","section":"post","summary":"Frauke Kreuter once commented on a presentation I gave that I should really be looking at sequence analysis for studying attrition in panel surveys. She had written an article on the topic with Ulrich Kohler ( here ) in 2009, and as of late there are more people exploring the technique (e.g. Mark Hanly at Bristol, and Gabi Durrant at Southampton ).\nI am working on a project on attrition in the British Household Panel, and linking attrition errors to measurement errors.","tags":["statistical modeling","attrition","survey error","R","sequence analysis"],"title":"Longitudinal interview outcome data reduction: Latent Class and Sequence analyses","type":"post"},{"authors":["Schoot","A.G.J. van de","Kluytmans","A.","Tummers","L.","Lugtig","P.","Hox","J.","and Muthen","B."],"categories":[],"content":"","date":1382482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382482800,"objectID":"9b677f3a0e74c9f3a7575f08a56b87f4","permalink":"https://peterlugtig.com/publication/2013_schoot_facing_off_with_choosing/","publishdate":"2013-10-23T00:00:00+01:00","relpermalink":"/publication/2013_schoot_facing_off_with_choosing/","section":"publication","summary":"Measurement invariance (MI) is a pre-requisite for comparing latent variable scores across groups. The current paper introduces the concept of approximate MI building on the work of Muthén and Asparouhov and their application of Bayesian Structural Equation Modeling (BSEM) in the software Mplus. They showed that with BSEM exact zeros constraints can be replaced with approximate zeros to allow for minimal steps away from strict MI, still yielding a well-fitting model. This new opportunity enables researchers to make explicit trade-offs between the degree of MI on the one hand, and the degree of model fit on the other. Throughout the paper we discuss the topic of approximate MI, followed by an empirical illustration where the test for MI fails, but where allowing for approximate MI results in a well-fitting model. Using simulated data, we investigate in which situations approximate MI can be applied and when it leads to unbiased results. Both our empirical illustration and the simulation study show approximate MI outperforms full or partial MI In detecting/recovering the true latent mean difference when there are (many) small differences in the intercepts and factor loadings across groups. In the discussion we provide a step-by-step guide in which situation what type of MI is preferred. Our paper provides a first step in the new research area of (partial) approximate MI and shows that it can be a good alternative when strict MI leads to a badly fitting model and when partial MI cannot be applied.","tags":[],"title":"Facing off with Scylla and Charybdis: A comparison of scalar, partial, and the novel possibility of approximate measurement invariance","type":"publication"},{"authors":null,"categories":null,"content":"I love watching videos from Richard Feynman on Youtube. Apart from being entertaining, Feynman in the video below does explain quite subtly about what constitutes a good scientific theory, and what doesn\u0026rsquo;t. He is right about the fact that good theories are precise theories.\nRichard Feynman: fragment from a class on the Philosophy of science (source: Youtube)\nThe video also makes me jealous of natural scientists. In the social sciences, almost all processes and causal relationships are contextual, as opposed to the natural sciences. For example: in survey methods, nonresponse is one of the phenomena that is contextual . Nonresponse always occurs, but the predictors of nonresponse differ across countries, survey topics, time, survey mode, and subpopulations. In other words, that is what makes building a theory about nonresponse so difficult. ","date":1382365440,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1382365440,"objectID":"05dd6941ba32c8fef5096ead75639854","permalink":"https://peterlugtig.com/post/a-great-lecturer-and-contextuality-of/","publishdate":"2013-10-21T16:24:00.002+02:00","relpermalink":"/post/a-great-lecturer-and-contextuality-of/","section":"post","summary":"I love watching videos from Richard Feynman on Youtube. Apart from being entertaining, Feynman in the video below does explain quite subtly about what constitutes a good scientific theory, and what doesn\u0026rsquo;t. He is right about the fact that good theories are precise theories.\nRichard Feynman: fragment from a class on the Philosophy of science (source: Youtube)\nThe video also makes me jealous of natural scientists. In the social sciences, almost all processes and causal relationships are contextual, as opposed to the natural sciences.","tags":["teaching","nonresponse error","Richard Feynman"],"title":"A great lecturer, and the contextuality of nonresponse","type":"post"},{"authors":null,"categories":null,"content":"Three weeks ago, I wrote about the fact that I think that it would be great if we could have a journal on peer-reviewed datasets (along with data being accessible).\nIt seems I am not alone thinking this. Jelte Wicherts, a psychologist/statistician atTilburg University has just started the Journal of Open Psychology data .\nJelte writes:\n\u0026ldquo;The Journal of Open Psychology Data (JOPD) features peer reviewed data papers describing psychology datasets with high reuse potential. Data papers may describe data from unpublished work, including replication research, or from papers published previously in a traditional journal. We are working with a number of specialist and institutional data repositories to ensure that the associated data are professionally archived, preserved, and openly available. Equally importantly, the data and the papers are citable, and reuse is tracked.\n","date":1381997340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381997340,"objectID":"3db44aa72cd2c2bb17e76a40fb2eb057","permalink":"https://peterlugtig.com/post/my-prayers-on-peer-reviewed-datasets/","publishdate":"2013-10-17T10:09:00.002+02:00","relpermalink":"/post/my-prayers-on-peer-reviewed-datasets/","section":"post","summary":"Three weeks ago, I wrote about the fact that I think that it would be great if we could have a journal on peer-reviewed datasets (along with data being accessible).\nIt seems I am not alone thinking this. Jelte Wicherts, a psychologist/statistician atTilburg University has just started the Journal of Open Psychology data .\nJelte writes:\n\u0026ldquo;The Journal of Open Psychology Data (JOPD) features peer reviewed data papers describing psychology datasets with high reuse potential.","tags":["open access","replication","publishing"],"title":"My prayers on peer-reviewed datasets are instantly answered","type":"post"},{"authors":null,"categories":null,"content":"I am continuing on the recent article and commentaries on weighting to correct for unit nonresponse by Michael Brick, as published in the recent issue of the Journal of Official Statistics ( here ).\nThe article by no means is all about whether one should impute or weight. I am just picking out one issue that got me thinking. Michael Brick rightly says that in order to correct succesfully for unit nonresponse using covariates, we want the covariates to do two things:\n1. They should explain missingness.\n2. They should highly correlate with our variable of interest.\nIn other words, these are the two assumptions for a Missing At Random process of missing data.\nThe variables (covariates) we currently use for nonresponse adjustments do neither. Gender, age, ethnicity, region, (and if we\u0026rsquo;re lucky) education, household composition and house characterics do not explain missingness, nor our variable of interest. Would it ever be conceivable to obtain covariates that do this? What are the candidates?\n1. covariates (X) that explain missingness (R):\nParadata are currently our best bet. Those may be interviewer observations or call data during fieldwork (note the absence of sample level paradata for self-administered surveys - here lies a task for us). Paradata don\u0026rsquo;t explain missingness very well at the moment, but I think everyone in survey research agrees we can try to collect more.\nAnother set of candidates are variables that we obtain by enriching sampling frames. We can use marketing data, social networks, or census data to get more information on our sampling units.\n2. covariates (X) that explain our variable of interest (Y):\nEven if we find covariates that explain missingness, we also want those covariates to be highly correlated to our variable of interest. It is very unlikely that a fixed set of for example paradata variables can ever achieve that. Enriched frame data may be more promising, but is unlikely that this will generally work. I think it is a huge problem that our nonresponse adjustment variables (X) are not related to Y, and one that is not likely to ever be resolved for cross-sectional surveys.\nBut. In longitudinal surveys, this is an entirely different matter. Because we usually ask the same variables over time, we can use variables from earlier occasions to predict values that are missing at later waves. So, there, we have great covariates that explain our variable of interest. We can use those as long as MAR holds. If change in the dependent variable is associated with attrition, MAR does not hold. Strangely, I know very few studies that study whether attrition is related to change in the dependent variable. Usually, attrition studies focus on covariates measured before attrition, to then explain attrition. They do not focus on change in the dependent variable.\n  Covariate adjustment for nonresponse in cross-sectional and longitudinal surveys\n(follow-up 28 October 2013): When adjustment variables are strongly linked to dependent variables, but not to nonresponse, variances tend to be increased (See Little and Vartivarian). So, in longitudinal surveys, the weak link between X and R should really be of medium strength as well, if adjustment is to be successful.\nI once thought that because we have so much more information in longitudinal surveys, we could use the lessons that we learn from attrition analyses to improve nonresponse adjustments in cross-sectional surveys. In a forthcoming book chapter , I found that the correlates of attrition are however very different from the correlates of nonresponse in wave 1. So in my view, the best we can do in cross-sectional surveys is to focus on explaining missingness, and then hope for the best for the prediction of our variables of interest.\n","date":1381740060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381740060,"objectID":"551b68b6e3f5af2873e56ff4f53a55f3","permalink":"https://peterlugtig.com/post/imagine-we-have-great-covariates-for/","publishdate":"2013-10-14T10:41:00.001+02:00","relpermalink":"/post/imagine-we-have-great-covariates-for/","section":"post","summary":"I am continuing on the recent article and commentaries on weighting to correct for unit nonresponse by Michael Brick, as published in the recent issue of the Journal of Official Statistics ( here ).\nThe article by no means is all about whether one should impute or weight. I am just picking out one issue that got me thinking. Michael Brick rightly says that in order to correct succesfully for unit nonresponse using covariates, we want the covariates to do two things:","tags":["missing data","weighting","attrition","nonresponse error","imputation","panel survey"],"title":"Imagine we have great covariates for correcting for unit nonresponse...","type":"post"},{"authors":null,"categories":null,"content":"This week, I have been reading the most recent issue of the Journal of Official Statistics , a journal that has been open access since the 1980s. In this issue is a critical review article of weighting procedures authored by Michael Brick with commentaries by Olena Kaminska ( here ), Philipp Kott ( here ), Roderick Little ( here ), Geert Loosveldt ( here ), and a rejoinder ( here ).\nI found this article a great read, and to be full of ideas related to unit nonresponse. The article reviews approaches to weighting: either to the sample or the population, by poststratification and with different statistical techniques. But it discusses much more, and I recommend reading it.\nOne of the issues that is discussed in the article, but much more extensively in a commentary by Roderick Little, is the question whether we should use weighting or imputations to adjust for unit nonresponse in surveys. Over the years, I have switched allegiances to favouring weighting or imputations in certain missing data situations many times, and I am still not always certain on what is best to do. Weighting is generally favoured for cross-sectional surveys, because we understand how it works. Imputations are generally favoured when we have strong correlates for missingness and our variable(s) of interest, such as in longitudinal surveys. Here are some plusses and minuses for both weighting and imputations.\nWeighting is design based. Based on information that is available for the population or whole sample (including nonrespondents), respondent data are weighted in such a way that the survey data reflect the sample/population again.\n+ The statistical properties of all design-based weighting procedures are well-known.\n+ Weighting works with complex sampling designs (at least theoretically).\n+ We need relatively little information on nonrespondents to be able to use weighting procedures. There is however a big BUT\u0026hellip;\n- Weighting models mainly use socio-demographic data, because that is the kind of information we can add to our sampling frame. These variables are never highly correlated with our variable of interest, nor missingness due to nonresponse, so weighting is not very effective. That is, weighting theoretically works nicely, but in practice, it doesn\u0026rsquo;t ameliorate the missing data problem we have because of unit nonresponse much.\nImputations are model based. Based on available information for respondents and nonrespondents, a prediction model is built for a variable which has missing information. The model can take an infinite number of shapes, depending on whether imputation is stochastic, how variables are related within the model, and what variables are being used. Based on this model, one or multiple values are imputed for every missing value on every variable for every case. The crucial difference is that weighting uses the same variables for correcting the entire dataset, whereas imputation models differ for every variable that is to be imputed.\n+ Imputation models are flexible. This means that the imputation model can be optimized in such a way that it strongly predicts both the dependent variable to be imputed, and the missingness process.\n- In the case of unit nonresponse, we often have limited data on nonrespondents. So, although a model-based approach may have advantages over design-based aproaches in terms of its ability to predict our variable(s) of interest, this depends on the quality of the covariates we use.\nThis then brings me, and the authors of the various papers in JoS back to the basic problem: we don\u0026rsquo;t understand the process on nonresponse in surveys . Next time, more on imputations and weighting for longitudinal surveys. And more on design vs. model based approaches in survey research.\np.s. This all assumes simple random sampling. If complex sampling designs are used, weighting is until now I think the best way to start dealing with nonresponse. I am unaware of imputation methods that can deal with complex sampling (other than straightforward multilevel structures).\n","date":1381088940,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1381088940,"objectID":"adbae020da279bc61fe226c9aa8f75d7","permalink":"https://peterlugtig.com/post/to-weight-or-to-impute-for-unit/","publishdate":"2013-10-06T21:49:00.003+02:00","relpermalink":"/post/to-weight-or-to-impute-for-unit/","section":"post","summary":"This week, I have been reading the most recent issue of the Journal of Official Statistics , a journal that has been open access since the 1980s. In this issue is a critical review article of weighting procedures authored by Michael Brick with commentaries by Olena Kaminska ( here ), Philipp Kott ( here ), Roderick Little ( here ), Geert Loosveldt ( here ), and a rejoinder ( here ).","tags":["weighting","nonresponse error","imputation","coverage error","data quality"],"title":"To weight or to impute for unit nonresponse?","type":"post"},{"authors":null,"categories":null,"content":"This morning, an official enquiry into the scientific conduct of professor Mart Bax concluded that he had committed large-scale scientific fraud over a period of 15 years. Mart Bax is a now-retired professor of political anthropology at the Free University Amsterdam. In 2012 a journalist first accused him of fraud, and this spring, the Volkskrant, one of the big newspapers in the Netherlands reported they were not able to find any of the informants Mart Bax had used in his studies.\nAn official enquiry followed. You can can the report here (in Dutch) . In summary, Mart Bax most likely made up at least 64, mostly peer-reviewed articles and recycled his own articles using different titles in different journals. Although the investigation could not rule out that some studies were just done sloppily the overall picture from the report is one of overall scientific misconduct.\nSo, what to do about this? I have a clear opinion on this: Make your data available, and replicate other people\u0026rsquo;s studies What strikes me, is that it seems normal to some social scientists not to store interviews (whether on tape or anonymized in scripts) or publish datasets. It may be a little more difficult for qualitative researchers than quantitative researchers to do this. Back in the 1990s, when Mart Bax committed this fraud, it may have been really complicated to publish such transcripts online. Nowadays, it is dead easy however, and some, although not many journals offer this service. See for some good examples in the social sciences:\n- The review of economical studies : will only publish articles that provide data, and where analyses can be replicated. This is the only example that I could find of a journal policy that really makes it easy to replicate research findings.\n- All Springer journals provide the opportunity for supplementary materials (among them data). Is just an option.\n- The journal of Personality and Social Psychology encourages providing data and analysis scripts in general (The American Psychological Association as w hole does this).\n If you know of any other journals with good replicability policies, please send a comment or e-mail (p.lugtig AT uu.nl), so I can compile a more comprehensive list.\nIn the natural sciences, there are journals where datasets are peer-reviewed and publishe d. As social scientists, we have a long way to go to tackle fraud, and generally become much more open about our data and analysis methods. Journals, professional associations, and individualresearchers should all be stricter on data accessibility, and replicability of studies.\n","date":1379932020,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379932020,"objectID":"4be4be0408154b03336681cd81b562a8","permalink":"https://peterlugtig.com/post/publish-your-data/","publishdate":"2013-09-23T12:27:00+02:00","relpermalink":"/post/publish-your-data/","section":"post","summary":"This morning, an official enquiry into the scientific conduct of professor Mart Bax concluded that he had committed large-scale scientific fraud over a period of 15 years. Mart Bax is a now-retired professor of political anthropology at the Free University Amsterdam. In 2012 a journalist first accused him of fraud, and this spring, the Volkskrant, one of the big newspapers in the Netherlands reported they were not able to find any of the informants Mart Bax had used in his studies.","tags":["open access","replication","publishing","data quality","fraud"],"title":"Publish your data","type":"post"},{"authors":null,"categories":null,"content":"Social scientists (and psychology in particular) have in recent years had somethings of a bad press, both in- and outside academia. To give some examples:\n- There is a sense among some people that social science provides little societal or economical value. - Controversy over research findings within social science: for example the findings of Bem et al. about the existence of precognition , or the estimation of the number of casualties in Iraq war (2003-2007).\n- Scientific fraud: in the Netherlands alone, we have had about five affairs of scientific fraud in the past few years. The biggest one being the Stapel-affair: a professor who dreamed up the data of about 50 high-profile scientific articles.\nNow, I disagree with the fact that the social sciences do not contribute enough to society, but is hard to argue about this issue if people can argue that social scientists commit fraud, or are secretive about their methods and results. Also, I dislike the defensive attitude many social scientists take on fraud, opnness, and replicability. Instead of just being defensive, try do some something constructive with critique we receive as a field.\nAt this year\u0026rsquo;s GESIS summer school, I gave a talk about the topic of survey errors and how to improve social science as a whole. I think it is really time to change the way we as social scientists do our work. We have to be more open about what we do and how we do it. Not only so we can strenghthen the position of the social sciences in general, but more importantly to make progress as a field. Many theories in the social sciences are founded on empirical research findings, that can either not be replicated, are based on wrong statistical analyses, or are based on fraudulated data. Dreaming up data is the worst example of fraud, but I count as fraud also selectively deleting those cases that don\u0026rsquo;t support your theory, or presenting exploratory analyses as confirmatory. This last point especially is common throughout the social sciences (and in other disciplines as well).\n  _Summaries of a survey on scientific fraud in medical faculties in the Flanders region of Belgium _\n_(source: http://blogs.scientificamerican.com/talking-back/2013/05/02/spring-and-scientific-fraud-is-busting-out-all-over/)_\nHere is my idea of how to start making things better:\n1. Publish your data. Unless you work with medical or otherwise privacy-sensitive data, I see no reason why not all data should be published online at some point. Of course, data need to be cleaned after data collection, and researchers may keep data for themselves for a limited amount of time, if they fear others may steal their good research ideas. But once a paper is published, the data should become available. No excuses\n2. Document your analyses. If you publish your data, why not publish your analyses scripts and logs of your analyses as well, so everyone can easily replicate your analyses? We need more replication in the social sciences, and should make it more attractive for researchers to do this. Yes, that means that data analysis errors may be exposed by other researchers. But in my view, this is the only way we can progress as social sciences.\nAnd as I believe in practice what you preach, I am putting all my data and analysis-scripts at this webpage (see publications ). As I do not own all the data, I am still working out how to do this with some of my co-authors, but my goal is to really have all my data and scripts/syntaxes there, so everyone can replicate my analyses given they use the same software.\nThe slides for my presentation at GESIS are found here . There is also a video-recording of the lecture, that can be found here ","date":1379165820,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1379165820,"objectID":"b15885d2d62c92c5976904f69452cf48","permalink":"https://peterlugtig.com/post/how-to-improve-social-sciences/","publishdate":"2013-09-14T15:37:00.002+02:00","relpermalink":"/post/how-to-improve-social-sciences/","section":"post","summary":"Social scientists (and psychology in particular) have in recent years had somethings of a bad press, both in- and outside academia. To give some examples:\n- There is a sense among some people that social science provides little societal or economical value. - Controversy over research findings within social science: for example the findings of Bem et al. about the existence of precognition , or the estimation of the number of casualties in Iraq war (2003-2007).","tags":["GESIS","open access","replication","publishing","data quality","fraud"],"title":"How to improve the social sciences","type":"post"},{"authors":null,"categories":null,"content":"One of the greatest challenges in survey research are declining response rates. Around the globe, it appears to become harder and harder to convince people to participate in surveys. As to why response rates are declining, researchers are unsure. A general worsening of the \u0026lsquo;survey climate\u0026rsquo;, due to increased time pressures on people in general, and direct marketing are usually blamed.\nThis year\u0026rsquo;s Nonresponse workshop was held in London last week. This was the 24th edition, and all we talk about at the workshop is how to predict, prevent or adjust for nonreponse in panel surveys.\nEven though we are all concerned about declining nonresponse rates, presenters at the nonresponse workshop have found throughout the years that nonresponse cannot be predicted using respondent characteristics. The explained variance of any model rarely exceeds 0.20. Because of this, we don\u0026rsquo;t really know how to predict or adjust for nonresponse either. We fortunately also find that generally, the link between nonresponse rates and nonresponse bias is wea k. In other words, high nonresponse rates are not per se biasing our substantive research findings.\nAt this year\u0026rsquo;s nonresponse workshop presentations focused on two topics. At other survey methods conferences ( ESRA , AAPOR ) I see a similar trend:\n1. Noncontacts: where refusals can usually be not predicted at all (explained variances lower than 0.10), noncontacts can to some extent. So, presentations focused on:\n- increasing contact rates among \u0026lsquo;difficult\u0026rsquo; groups\n- Using paradata, and call record data to improve the prediction of contact times, and succesful contacts.\n- Using responsive designs, where the contact strategies is changed, based on pre-defined (and often experimental) strategies for subgroups in your populations ( adaptive designs ), and paradata during fieldwork using decision-rules ( responsive designs) .\n   2. Efficiency: Responsive designs can be used to increase response rates or limit nonresponse bias. However, they can also be used to limit survey costs. If respondents can be contacted with fewer contact attempts, this saves money. Similarly, we can limit the amount of effort we put into groups of cases for which we already have a high response rate, and devote our resources to hard-to-get cases.\nThere are many interesting studies than can be done into both these areas. With time, I think we will see that succesful stratgies will be developed that limit noncontact rates, nonresponse and even nonresponse bias to some extent. Also, survey might become cheaper using responsive designs, especially if the surveys use Face-to-Face or telephone interviewing. At this year\u0026rsquo;s workshop, there were no presentations on using a responsive design approach for converting soft refusals. But I can see the field moving in that direction too eventually.\nJust one note of general disappointment with myself and our field remains after attending the workshop (and I\u0026rsquo;ve had this feeling before):\nIf we cannot predict nonresponse at all, and if we find that nonresponse generally has a weak effect on our survey estimates, what are we doing wrong? What are we not understanding? It feels, in philosophical terms, as if we survey methodologists are perhaps all using the wrong paradigm for studying and understanding the problem. Perhaps we need radically different ideas, and analytical models to study the problem of nonresponse. What these should be is perhaps anyone\u0026rsquo;s guess. And if not anyone\u0026rsquo;s, at least my guess.\n","date":1378738080,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378738080,"objectID":"1c12235cad20cecc1ea2ed5bec1b7e31","permalink":"https://peterlugtig.com/post/nonresponse-workshop-2013/","publishdate":"2013-09-09T16:48:00.002+02:00","relpermalink":"/post/nonresponse-workshop-2013/","section":"post","summary":"One of the greatest challenges in survey research are declining response rates. Around the globe, it appears to become harder and harder to convince people to participate in surveys. As to why response rates are declining, researchers are unsure. A general worsening of the \u0026lsquo;survey climate\u0026rsquo;, due to increased time pressures on people in general, and direct marketing are usually blamed.\nThis year\u0026rsquo;s Nonresponse workshop was held in London last week.","tags":["conference","workshop","nonresponse error","responsive design","survey error"],"title":"Nonresponse Workshop 2013","type":"post"},{"authors":null,"categories":null,"content":"Longitudinal surveys ask the same people the same questions over time. So questionnaires tend to be rather boring for respondents after a while. \u0026ldquo;Are you asking me this again, you asked that last year as well!\u0026rdquo; is what many respondents probably think during an interview. As methodologists who manage panel surveys, we know this process may be rather boring, but in order to document change over time, we just need to ask respondents the same questions over and over.\nSome measures of change over time would become biased if we just repeat questions year-on-year. For example, we know that if we ask respondents twice about their occupation, less than half of all of them have the same occupational codes over time. We know from other statistics (e.g. tax returns), that that is not true. Most people stay in the same occupation over time. Now, you may think, dear reader, that that is probably due to the fact that occupation is rather difficult to measure and code in general, and you are right. Unreliable question will lead to a lot of spurious change over time.\nDependent Interviewing helps to make codes consistent over time and reduce such spurious change. The idea is that, instead of coding occupation independently year-on-year, you ask respondents in year 2 the question \u0026ldquo;last year, you said you were a bankteller, is that still the case?\u0026quot;. There are many different variants to ask this Dependent Interviewing question, and the exact wording is important for the outcomes. Especially, because we do not want respondent to say \u0026ldquo;yes\u0026rdquo; too easily to questions we ask.\n  \u0026ldquo;Last year, you told me you told me you worked as a bankteller, is that still the case?\u0026quot;\nRecently, a paper I wrote on the effects of various forms of Dependent Interviewing came out in Field Methods . It was actually the first paper I wrote for my Ph.D, and I started work on it in 2006. So, it has been quite a journey to get this story on paper and get it published. I am very happy to see it on paper now. We did an experiment, where we tried out different DI-designs in a four-wave panel study, to study effects of data quality of each different DI-design. Specifically, we looked at whether respondents might falsely confirm data from the previous year that we knew contained measurement error. The bottom line of the study is that when Dependent Interviewing is applied to income amount questions over time, it does improve data quality, and we don\u0026rsquo;t need to worry so much about respondents wrongly agreeing to pre-loaded data from the previous year. Read the full paper here. ","date":1375539720,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375539720,"objectID":"393043116c32c8c88e96e84040041a0d","permalink":"https://peterlugtig.com/post/dependent-interviewing-and-risk-of/","publishdate":"2013-08-03T16:22:00.001+02:00","relpermalink":"/post/dependent-interviewing-and-risk-of/","section":"post","summary":"Longitudinal surveys ask the same people the same questions over time. So questionnaires tend to be rather boring for respondents after a while. \u0026ldquo;Are you asking me this again, you asked that last year as well!\u0026rdquo; is what many respondents probably think during an interview. As methodologists who manage panel surveys, we know this process may be rather boring, but in order to document change over time, we just need to ask respondents the same questions over and over.","tags":["measurement error","dependent interviewing","quasi-simplex model","questionnaire design","data quality","panel survey"],"title":"Dependent Interviewing and the risk of correlated measurement errors","type":"post"},{"authors":["Lugtig","P.","and Lensvelt-Mulders","G.J.L.M."],"categories":[],"content":"","date":1374620400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1374620400,"objectID":"066c68be9a3b4186a72ff935da19d24e","permalink":"https://peterlugtig.com/publication/2014_lugtig_evaluating_data_quality_on/","publishdate":"2013-07-24T00:00:00+01:00","relpermalink":"/publication/2014_lugtig_evaluating_data_quality_on/","section":"publication","summary":"Dependent interviewing (DI) uses respondent data from earlier waves in panel surveys to improve the data quality of change estimates. Apart from a positive effect on data quality through reducing overestimations of change, DI could also affect data quality negatively when it leads to satisficing and an overestimation of stability between waves. In this article, we experimentally test two frequently used DI designs under different levels of measurement error. Our data consist of income reports from a four-wave panel survey conducted in the Netherlands. The effects of our experiment on data quality are modeled with a quasi-simplex structure to enable the decomposition of variances into measurement errors and true change. Our main conclusion is that there is some risk of a negative effect on data quality for proactive DI but not for reactive DI.","tags":[],"title":"Evaluating data quality on the measurement of change using dependent interviewing","type":"publication"},{"authors":null,"categories":null,"content":"I am spending time at the Institute for Social and Economic Research in Colchester, UK where I will work on a research project that investigates whether there is a tradeoff between nonresponse and measurement errors in panel surveys.\nSurvey methodologists have long believed that multiple survey errors have a common cause. For example, when a respondent is less motivated, this may result in nonresponse (in a panel study attrition), or in reduced cognitive effort during the interview, which in turn leads to measurement errors. Lower cognitive abilities and language problems might be other examples of common caused that lead to either nonresponse or measurement error. Understanding these common error sources is important to know whether our efforts to reduce 1 survey error source are not offset by an increase in another one. It follows from the idea that good survey design minimize Total Survey Error Studying the trade-off has proven to be very difficult. This is because nonrespondents are by definition not observed. So, we never know how nonrespondents would answer questions, and how much measurement error is included in those answers. We can only observe measurement errors for respondents, but can not compare these to the potential measurement error of nonrespondents.\nHypothetical continuum of timing of survey response\n To overcome this problem, most methodologists have compared \u0026lsquo;early\u0026rsquo; respondents (people who respond very quickly in the fieldwork period) to \u0026lsquo;late\u0026rsquo; respondents (those who only participate after being reminded for example). The idea behind this, is that the probability of response is:\na) a linear continuum from very early response on the one extreme, and nonresponse on the other.\nb) that hypothetically, nonrespondents could be converted into respondents if extreme amounts of efforts are used to do so (Voogt 2005 showed in a small-scale study in the Dutch locality of Zaandam that this is actually possible)\nSo, the idea in summary is that late respondents can serve as a proxy for information about nonrespondents. However, that assumption is not likely to be true in general, if ever.\nIn my project, I will try to overcome this problem, that we never have measurement error estimates for nonrespondents. I use longitudinal data and Structural Equation Modeling techniques to estimate measurement errors for nonrespondents in the British Household Panel Study, compare them to respondents, and link them to potential common causes of both type of errors. See this presentation for more details on this project\n","date":1372931820,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372931820,"objectID":"517901cca031b16b082e73d831b1a9ff","permalink":"https://peterlugtig.com/post/measurement-and-nonresponse-error-in/","publishdate":"2013-07-04T11:57:00.002+02:00","relpermalink":"/post/measurement-and-nonresponse-error-in/","section":"post","summary":"I am spending time at the Institute for Social and Economic Research in Colchester, UK where I will work on a research project that investigates whether there is a tradeoff between nonresponse and measurement errors in panel surveys.\nSurvey methodologists have long believed that multiple survey errors have a common cause. For example, when a respondent is less motivated, this may result in nonresponse (in a panel study attrition), or in reduced cognitive effort during the interview, which in turn leads to measurement errors.","tags":["measurement error","SEM","trade-off between survey errors","attrition","nonresponse error","separating error sources","common causes of survey error","panel survey"],"title":"measurement and nonresponse error in panel surveys","type":"post"},{"authors":null,"categories":null,"content":"The AAPOR conference last week gave an overview of what survey methodologists worry about. There were relatively few people from Europe this year, and I found that the issues methodologists worry about are sometimes different in Europe and the USA. At the upcoming ESRA conference for example there are more than 10 sessions on the topic of mixing survey modes. At AAPOR, mixing modes was definitely not \u0026lsquo;hot\u0026rsquo;.\nWith 8 parallel sessions at most times, I have only seen bits and pieces of all the things that went on. So the list below is just my take on what\u0026rsquo;s innovative and hot in survey research in 2013. RTI composed a summary of all tweets for a different take on what mattered at AAPOR this year\n1. Probability based surveys vs. non-probability surveys. AAPOR published a report on this topic during the conference, written by survey research heavy-weights. This is recommended reading for everyone interested in polls. The conclusion that non-probability polls should not be used if one wants to have a relatively precide estimate for the general population is not surprising. It can not be re-iterated often enough. Other presentations on this topic features John Krosnick showing empirically that only probability-based surveys give consistent estimates. See a summary of the report here 2. The 2012 presidential elections. See a good post by Marc Blumenthal on this topic. Many sessions on likely voter models, shifting demographics in the U.S. and the rise of the cell-phone only generation.\n3. Responsive designs. The idea of responsive (or adaptive) survey designs is that response rates are balanced across important sub-groups of the population. E.g. in a survey on attitudes towards immigrants, it is important to get equal response rates for hispanics, blacks and whites, when you believe that attitudes towards immigrants differ among ethnic sub-groups.\nDuring fieldwork, response rates can be monitored, and when response rates for hispanics stay low, resources can be shifted towards targeting hispanics, by either contacting them more often, or switching them to a more expensive contact mode. If this is succesful, the amount of nonresponse bias in a survey should decrease.\nThe idea of responsive designs has been around for about 15 years. I had until now not seen many successful applications however. A panel session by the U.S. Census bureau did show that response design can work, but it requires survey organisations to redesign their entire fieldwork operations. For more information on this topic, see the excellent blog by James Wagner ","date":1369304280,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1369304280,"objectID":"2a3d04b791df8b019fd9dda29ca5761a","permalink":"https://peterlugtig.com/post/aapor-2013/","publishdate":"2013-05-23T12:18:00.002+02:00","relpermalink":"/post/aapor-2013/","section":"post","summary":"The AAPOR conference last week gave an overview of what survey methodologists worry about. There were relatively few people from Europe this year, and I found that the issues methodologists worry about are sometimes different in Europe and the USA. At the upcoming ESRA conference for example there are more than 10 sessions on the topic of mixing survey modes. At AAPOR, mixing modes was definitely not \u0026lsquo;hot\u0026rsquo;.\nWith 8 parallel sessions at most times, I have only seen bits and pieces of all the things that went on.","tags":["conference","AAPOR","nonresponse error","responsive design","access panels"],"title":"AAPOR 2013","type":"post"},{"authors":null,"categories":null,"content":"I was pointed to an interview with two Harvard professors, one of them my (former) idol Gary King, talking about the need for open access publishing. I\u0026rsquo;m re-posting it here as a reminder to myself, and to anyone from the social sciences (or survey methods), that we should be more open about what we do and write. Too often, papers take years to appear in print-journals, and even then, these articles probably don\u0026rsquo;t make it to those people without subscriptions to all the main publishers.\nOne practical question to anyone reading this: the natural sciences have ArXiv: a system where everyone published work-in-progress. Does anyone know of initiatives in this direction in the social sciences?\n","date":1364803500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364803500,"objectID":"f8d6067f39d98abcc41607c407dd9bbf","permalink":"https://peterlugtig.com/post/open-access-things-we-can-learn-from/","publishdate":"2013-04-01T10:05:00+02:00","relpermalink":"/post/open-access-things-we-can-learn-from/","section":"post","summary":"I was pointed to an interview with two Harvard professors, one of them my (former) idol Gary King, talking about the need for open access publishing. I\u0026rsquo;m re-posting it here as a reminder to myself, and to anyone from the social sciences (or survey methods), that we should be more open about what we do and write. Too often, papers take years to appear in print-journals, and even then, these articles probably don\u0026rsquo;t make it to those people without subscriptions to all the main publishers.","tags":["open access","working paper","publishing"],"title":"Open access: things we can learn from the natural sciences","type":"post"},{"authors":null,"categories":null,"content":"Mixed-mode research is still a hot topic among survey methodologists. At least at about every meeting I attend (some selection bias is likely here). Although we know a lot from experiments in the last decade, there is also a lot we don\u0026rsquo;t know. For example, what designs reduce total survey error most? What is the optimal mix of survey modes when data quality and survey costs are both important? And, how can we compare mixed-mode studies across time, or countries, when the proportions of mode assignments changes over time or vary between countries?\nTogether with some researchers at National Statistical Institutes I am trying to form a European consortium to set up a programme for doing comparative mixed-mode research. One of the goals of this consortium would be to apply for funding at the next wave of EU funding (horizon 2020). We are however still looking for researchers in market research, official statistics and universities. And especially from countries in Northern, Central and Southern Europe. Want to know more? Write me at p.lugtig AT uu.nl\n","date":1362665040,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362665040,"objectID":"83480d0131597d932017ded0035ef231","permalink":"https://peterlugtig.com/post/interested-in-new-mixed-mode-research/","publishdate":"2013-03-07T15:04:00+01:00","relpermalink":"/post/interested-in-new-mixed-mode-research/","section":"post","summary":"Mixed-mode research is still a hot topic among survey methodologists. At least at about every meeting I attend (some selection bias is likely here). Although we know a lot from experiments in the last decade, there is also a lot we don\u0026rsquo;t know. For example, what designs reduce total survey error most? What is the optimal mix of survey modes when data quality and survey costs are both important? And, how can we compare mixed-mode studies across time, or countries, when the proportions of mode assignments changes over time or vary between countries?","tags":["horizon 2020","survey error","mode effect","data quality","mixed mode"],"title":"Interested in new mixed mode research project?","type":"post"},{"authors":null,"categories":null,"content":"  Some colleagues in the United Kingdom have started a half-year initiative to discuss the possibilities of conducting web surveys among the general population. Their website can be found here  One aspect of their discussions focused on whether any web survey among the population should be complemented with another, secondary survey mode. This would for example enable those without Internet access to participate. Obviously, this means mixing survey modes.\nUsing two different survey modes to collect survey data, risks introducing extra survey error. Methodologists (me inclusive) have worked hard on getting a grip on the existence of differences in measurement effects between different modes. In order to study these properly, one should first make sure that the sub samples that are interviewed in different survey modes, do not differ just because of differences in selection effects between the two samples. I have written some earlier posts on this issue, see some of the labels in the word-cloud on the right.\nI have composed a short presentation on ways in which differences in measurement effects in mixed-mode surveys can be studied. The full presentation is here . Comments are very welcome.\nIn going over the literature, two things stood out, that I never realised:\n1. There are few well-conducted studies on measurement effects in mixed-mode surveys. Those that exist show that there often are difference in means, and sometimes in variances of survey statistics. Yet no one (and I\u0026rsquo;d love to be corrected here), has looked at the effect on covariances. That is, do relations between the key variables in a study change, just because of the mode of data collection? There may be an analogy to nonresponse studies, where we often find bias on means and variances, but much smaller biases for covariances. In this picture, this reflects the relation between x1 and y1 in two different survey modes. Is that relation different because of mode effects? Probably not, but we need more research on this.\n  2. What to do about mode effects? We are perhaps not ready for answering this question, looking at how little we know exactly about how measurement differences between modes affect survey statistics. But we should start thinking in general about this question. Can we correct for differences between modes. Should we want to do that? It would create a huge extra burden on survey researchers to study mode differences in all mixed-mode surveys, and designing correction methods for them. Could it be that in five years time, we have concluded that it is probably best to try to keep mode effects as small as possible and not worry about the rest?\n","date":1361608200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1361608200,"objectID":"5f4cafc952fcbfae32a120281d80bc69","permalink":"https://peterlugtig.com/post/mixed-mode-surveys-where-will-be-in-5/","publishdate":"2013-02-23T09:30:00+01:00","relpermalink":"/post/mixed-mode-surveys-where-will-be-in-5/","section":"post","summary":"Some colleagues in the United Kingdom have started a half-year initiative to discuss the possibilities of conducting web surveys among the general population. Their website can be found here  One aspect of their discussions focused on whether any web survey among the population should be complemented with another, secondary survey mode. This would for example enable those without Internet access to participate. Obviously, this means mixing survey modes.","tags":["measurement error","statistical modeling","separating error sources","survey error","mode effect","mixed mode"],"title":"Mixed mode surveys: where will be in 5 years from now?","type":"post"},{"authors":null,"categories":null,"content":"   I recently gave a talk at an internal seminar on planned missingness for a group of developmental psychologists. The idea behind planned missingness is that you can shorten interview time or reduce costs, if you decide as a researcher not to administer all your instruments to everyone in your sample. When you either randomly assign people to receive a particular instrument, or do so by design (i.e. only collect bio-markers in an at-risk group), your missing data will either be Missing Completely At Random (MCAR) or Missing at Random (MAR). Both situations of missing data can easily be \u0026lsquo;solved\u0026rsquo; after the data collection, so you save costs on the one hand, and still obtain a \u0026lsquo;complete\u0026rsquo; dataset for answering your research questions.\n  Click to enlarge\n_ Discrete data collection with fixed intervals_ _Continuous data collection with varying intervals_\nPlanned missingness has been implemented in some cross-sectional surveys. I think it has great potential for panel surveys too, when you randomly assign respondents to become respondent in an entire waves (or not). This can reduce costs or lead to increased statistical power when one decides to invest the saved costs in more longitudinal measurements. If you would stretch this idea, you can end up in a situation of continuous data collection, where the interval between waves is randomized for respondents. A methodological setup like this allows all kinds of new research to be answered. For example the existence and size of test-effects (panel conditioning). Furthermore, models that include time (change, duration, cox-regression, survival models), can be estimated more precisely. And with the advent of Internet surveys not difficult to implement. I don\u0026rsquo;t know any real panel study that ever did this however (please let me know if I\u0026rsquo;m wrong here).\nThe developmental psychologists did not seem too enthusiastic about my ideas last week. Too bad. I would love to collaborate on a study that really does this to show it really works in practice if all is logistically well-organized. Slides can be found here p.s. 04-Feb-13 One of the readers rightly pointed me to the fact that rotating panel surveys use this principle to \u0026lsquo;refresh\u0026rsquo; their sample in every wave. Cohort studies also do this regularly. Even in such panel survey designs, measurements are taken at fixed time points though, and the rotation itself usually revolves around either measuring or dropping entire cohorts at once. I think that even such designs can improve by using the randomness inherent in planned missingness designs to make data collection more efficient and cost effective.\n","date":1359473340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359473340,"objectID":"6a81ce22b4ba0b471708c0dd27d35b91","permalink":"https://peterlugtig.com/post/planned-missingness/","publishdate":"2013-01-29T16:29:00.001+01:00","relpermalink":"/post/planned-missingness/","section":"post","summary":"I recently gave a talk at an internal seminar on planned missingness for a group of developmental psychologists. The idea behind planned missingness is that you can shorten interview time or reduce costs, if you decide as a researcher not to administer all your instruments to everyone in your sample. When you either randomly assign people to receive a particular instrument, or do so by design (i.e. only collect bio-markers in an at-risk group), your missing data will either be Missing Completely At Random (MCAR) or Missing at Random (MAR).","tags":["missing data","panel conditioning","planned missingness","statistical modeling","panel survey"],"title":"Planned Missingness","type":"post"},{"authors":null,"categories":null,"content":"This weekend is the deadline for submitting a presentation proposal to this year\u0026rsquo;s conference of the European Survey Research Association. That\u0026rsquo;s one the two major the conferences for people who love to talk about things like nonresponse bias, total survey error, and mixing survey modes.\nAs in previous years, it looks like the most heated debates will be on mixed-mode surveys. As survey methodologists we have been struggling to combine multiple survey modes (Internet, telephone, face-to-face, mail) in a good way. And we no longer can rely on just one survey mode to do a good survey. Many people don\u0026rsquo;t have Internet, or landline phones, and face-to-face modes are becoming too expensive.\nWhen we start mixing survey modes, we run into all kinds of problems. Different people respond in different survey modes, leading to differences in the variables we\u0026rsquo;re interested in (selection effects). And we also know that people respond differently to the same survey question when asked in two different modes (measurement or \u0026lsquo;mode\u0026rsquo; effect).\nWe have been trying to assess the size of selection and mode effects in mixed-mode surveys for a long time. I have written about this issue earlier, and although we have made progress, I don\u0026rsquo;t think we will ever be able to \u0026lsquo;correct\u0026rsquo; for differences between survey modes. That is because the sizes of selection and mode effects will always differ from survey to survey, depending on the topic of the study, and the population studied.\nSo, I suggest we try something different. We don\u0026rsquo;t we try to make survey modes themselves similar? If you think of combining the Internet, with face-to-face (two very different modes), these could be some ways to make the surveys equivalent.\n- Approach people in the same way. For example, use advance letters in both modes, and then call respondents to either make an appointment (Face-to-face), or ask for an e-mailaddress and do an Internet interview. Stupid it may sound, but mixed-mode surveys or experiments often change the entire protocol, so we have no idea what is caused by what.\n- Use showcards in a face-to-face survey for sensitive questions and let the respondent self-complete them, like they do on the Internet\n- Use a Virtual Reality interviewer on an Internet survey for difficult questions, to help the respondent answering questions.\n- Use an audio recording feature on the Internet, so respondents can give answers in the same way as they do in Face-to-face surveys\n- Use short and simple questions that can easily be asked in any survey mode in more or less the same manner. This implies minimizing the number of response categories to only a few for any question.\nSurely, this approach is not fault free, and I do see lots of practical issues. I do think however that this is a better way to move forward than just trying fix up the mess with statistics after the data collection. These correction methods will always be necessary, but relying on them too much puts too much faith in statistics.\n","date":1357982640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1357982640,"objectID":"e28aa2c86cc5afd89260fb68d6ff2c1e","permalink":"https://peterlugtig.com/post/designing-mixed-mode-surveys/","publishdate":"2013-01-12T10:24:00+01:00","relpermalink":"/post/designing-mixed-mode-surveys/","section":"post","summary":"This weekend is the deadline for submitting a presentation proposal to this year\u0026rsquo;s conference of the European Survey Research Association. That\u0026rsquo;s one the two major the conferences for people who love to talk about things like nonresponse bias, total survey error, and mixing survey modes.\nAs in previous years, it looks like the most heated debates will be on mixed-mode surveys. As survey methodologists we have been struggling to combine multiple survey modes (Internet, telephone, face-to-face, mail) in a good way.","tags":["conference","equivalence","separating error sources","mode effect","questionnaire design","ESRA","mixed mode"],"title":"Designing mixed-mode surveys","type":"post"},{"authors":["Doornwaard","S. M.","van den Eijnden","R.J.J.M.","Lugtig","P.","ter Bogt","T.F.M.","and Overbeek","G."],"categories":[],"content":"","date":1357167600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1357167600,"objectID":"458dda8a3bb65eda09b619ec00361f33","permalink":"https://peterlugtig.com/publication/dutch_2012_doornwaard_ontwikkelingstrajecten/","publishdate":"2013-01-03T00:00:00+01:00","relpermalink":"/publication/dutch_2012_doornwaard_ontwikkelingstrajecten/","section":"publication","summary":"In deze studie onderzochten we of er verschillende ontwikkelingstrajecten bestaan in het gebruik van seksueel expliciet internetmateriaal (seim) van adolescenten en welke factoren voorspellend zijn voor deze trajecten. Een combinatie van latente klasseanalyse met groeicurves en multinominale regressieanalyse werd toegepast op 4-wave longitudinale gegevens van 441 adolescenten. Onder jongens waren vier ontwikkelingstrajecten in seim-gebruik te onderscheiden: ‘Stabiel geen/weinig gebruik’, ‘Sterk toenemend gebruik’, ‘Licht afnemend gebruik’ en ‘Stabiel veel gebruik’. Voor meisjes werd slechts één traject ‘Stabiel geen/weinig gebruik’ gevonden. Jongens in trajecten gekenmerkt door een hogere mate van seim-gebruik bleken bij de aanvang van de studie meer seksueel permissief en seksueel geïnteresseerd, zij communiceerden vaker met hun ouders over seks, konden vaker in privacy internetten en hadden een hogere realiteitsperceptie ten aanzien van seksuele media vergeleken met jongens in het traject ‘Stabiel geen/weinig gebruik’.","tags":[],"title":"In Dutch: Ontwikkelingstrajecten in en voorspellers voor het gebruik van seksueel expliciet internetmateriaal","type":"publication"},{"authors":["Lugtig","P."],"categories":[],"content":"","date":1354316400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1354316400,"objectID":"f434361028fe26c4423521ce54bfc4d5","permalink":"https://peterlugtig.com/publication/dutch_2012_lugtig_luiaards/","publishdate":"2012-12-01T00:00:00+01:00","relpermalink":"/publication/dutch_2012_lugtig_luiaards/","section":"publication","summary":"Uitval is een van de grootste problemen in panelonderzoek. Eerdere studies naar paneluitval kijken meestal naar respondenten die op enig moment nog actief en inactief zijn, en bestuderen de ver-schillen tussen deze respondenten om te bepalen hoe erg paneluitval is. In veel panelstudies is het proces van paneluitval veel subtieler. Respondenten missen soms enkele vragenlijsten, maar doen daarna weer mee. Of ze beginnen onregelmatig en doen later vaker mee. Met behulp van de huidige statistische modellen is het lastig om zulke responspatronen goed te analyseren. Dit artikel laat zien hoe paneluitval in het LISS panel kan worden bestudeerd met een Latente Klasse model. In dit Latente Klasse Model worden respondenten geclassificeerd op basis van hun uitvalproces. Aan de hand van achtergrondgegevens van de respondenten voorspel ik van welke klasse respondenten lid zijn. Trouwe deelnemers in het panel zijn bijvoorbeeld ouder en zorgvuldi-ger dan uitvallers, terwijl onregelmatige respondenten (luiaards), jong en lager opgeleid zijn. Het artikel sluit af met effecten van paneluitval op schattingen van de verkiezingsuitslag en enkele advie-zen aan managers van panels.","tags":[],"title":"In Dutch: Luiaards en trouwe deelnemers. Classificatie van respondenten in een panelstudie","type":"publication"},{"authors":null,"categories":null,"content":"In August, I organised a three-week summerschool with my colleagues in Utrecht on new features in MPLUS 7, the software we use to build Structural Equation Models. Video\u0026rsquo;s of all lectures can be found here. The latest issue of Psychological Methods contains background reading of Bayesian SEM, which is the main new feature of SEM. I find this fascinating stuff, and can think of hundreds of articles that could be written about replications of Maximum Likelihood based approaches.\nI think this is gonna be extremely interesting to survey methodologists as well, because any parametric model (for example models where variances are assumed to have a normal distribution, or factor loadings are assumed to be equal across the sample), can now be estimated as a non-parametric model. This will be huge, I promise.\n","date":1349699160,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349699160,"objectID":"b03770a93a402c3d69ae2db120ce71f5","permalink":"https://peterlugtig.com/post/bayesian-structural-equation-modeling/","publishdate":"2012-10-08T14:26:00.002+02:00","relpermalink":"/post/bayesian-structural-equation-modeling/","section":"post","summary":"In August, I organised a three-week summerschool with my colleagues in Utrecht on new features in MPLUS 7, the software we use to build Structural Equation Models. Video\u0026rsquo;s of all lectures can be found here. The latest issue of Psychological Methods contains background reading of Bayesian SEM, which is the main new feature of SEM. I find this fascinating stuff, and can think of hundreds of articles that could be written about replications of Maximum Likelihood based approaches.","tags":["Mplus","measurement error","SEM","statistical modeling","software","separating error sources","Bayesian"],"title":"Bayesian Structural Equation Modeling","type":"post"},{"authors":null,"categories":null,"content":"All of my research is focused on the methods of assembling and analysis of panel survey data. One of the primary problems of panel survey projects is attrition or drop-out. Over the course of a panel survey, many respondents decide to no longer participate.\nLast july I visited the panel survey methods workshop in Melbourne, at which we had extensive discussions about panel attrition. How to study it, what the consequences are (bias) for survey estimates, and how to prevent it from happening altogether.\nThese questions have a lot in common with the questions that are being discussed at another workshop for survey methodologists: the nonresponse workshop. The only difference is that at the nonresponse workshop we discuss one-off, cross-sectional surveys, and at the panel survey workshop, we dicuss what happens after the first wave of data collection.\nI am in the middle of writing a book chapter (with Annette Scherpenzeel and Marcel Das of Centerdata) on attrition in the LISS Internet panel, and one of the questions that we try to answers is whether nonrespondents in the first wave are actually similar to respondents who drop out at wave 2 or later. Or to be more precise, whether nonrespondents are actually similar to fast attriters, or to other sub-groups of attriters.\nThe graph below shows attrition patterns for the people in the LISS panel for the 50 waves that we analysed. The green line on top represents people who have response propensities close to 1, meaning they always participate. The brown line represents fast attriters, and the pink, dark blue, and purple lines slowers groups that drop out more slowly. You also find new panel entrants (dark grey and red line), and finally, a almost invisible black line that has response propensities of 0, meaning that although these people consented to become a panel member, they never actually participate in the panel.\n  click on the Figure to enlarge\nFor the whole story you\u0026rsquo;ll have to wait for book on \u0026lsquo;Internet panel surveys\u0026rsquo; to come out somewhere in 2013, but I\u0026rsquo;ll focus here on comparing initial nonrespondents to respondents who do consent, but then never participate.\nThese groups turn out to be different. Not just a little different, but hugely different. This was somewhat surprising to me, as many survey methodologists believe that early panel attrition is some kind of continuation of initial nonresponse. It turns out not to be. Fast attriters are very different from initial nonrespondents. My hypothesis for this is that some specific groups of people may ' accidentily\u0026rsquo; say yes to a first survey request, but then try to get out of the survey as fast as they can. I am still not sure what this implies for panel research (comments very welcome): does it mean that the methods that we use to target nonrespondents (persuasion principles of Cialdini et al. 1991) might not work in panel surveys, and that we need to use different methods?\nI think the first few waves of a panel study are extremely important for keeping attrition low in the long run. So, I think we should perhaps prolong some of the efforts that we use in the recruitment phase (advance letters, mixed-mode contact strategy), in the first waves as well, only to resort to a cheaper contact mode later, once panel members have developed a habit of responding to the different waves in a panel.\n","date":1348908540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1348908540,"objectID":"81d28375c0e12c8608f8536c60aaa8d9","permalink":"https://peterlugtig.com/post/is-panel-attrition-same-as-nonresponse/","publishdate":"2012-09-29T10:49:00.004+02:00","relpermalink":"/post/is-panel-attrition-same-as-nonresponse/","section":"post","summary":"All of my research is focused on the methods of assembling and analysis of panel survey data. One of the primary problems of panel survey projects is attrition or drop-out. Over the course of a panel survey, many respondents decide to no longer participate.\nLast july I visited the panel survey methods workshop in Melbourne, at which we had extensive discussions about panel attrition. How to study it, what the consequences are (bias) for survey estimates, and how to prevent it from happening altogether.","tags":["conference","attrition","nonresponse error","data quality","panel survey"],"title":"Is panel attrition the same as nonresponse?","type":"post"},{"authors":null,"categories":null,"content":"There are a lot of reasons why would not want to use acces panels for predicting electoral outcomes . These are well discussed in many places on- and offline. I\u0026rsquo;ll shortly summarize them, before adding some thoughts to why access panels do so badly predicting election outcomes.\n1. Access panels don\u0026rsquo;t draw random samples, but rely on self-selected samples. A slightly better way to get panel respondents is a quota sample, but even these have problems, well discussed here, here and here for example. The bottom line is that access panel respondents are not ' normal\u0026rsquo; people, and so voting preferences of not-normal people are likely to be biased.\n2. Because of these problems, survey managers use weighting. They correct their sample for known biases in the sample. If they know elderly people with low educations are underrepresented in an access panel, they weigh them up. I think this is bad practice. And it has been shown that weighting does not solve the problem,. and can sometimes make biases worse for general surveys. Here are some additional and specific problems, often neglected. In short, weighting only works if the weighting variables can predict the dependent variable to a great extent.\n  Weighting is usually done with socio-demographic variables. From political science research, we know that sociodemographics do a bad job of explaining voting behavior. Explained variances for regression models normally don\u0026rsquo;t exceed 10%.\nSo, let me get down to the main point I would like to make in this post. A point which I have not seen discussed anywhere.\nPanel survey managers have \u0026lsquo;resolved\u0026rsquo; the weakness of their weighting models by including a variable that does predict voring behavior fairly well: past voting behavior. If one knows that past Social Democrat voters are underrepresented, one can weight on that variable. This is all very well, if one has good data of past voting behavior for all panel members. The panels currently do not. Their information is wrong in two ways:\n1. Access panels will never have information for people who did not vote previously. These are mainly young people, or people who normally do not vote in elections. If these new voters vote like everyone else there is no problem, but new voters have very specific voting preferences.\n2. Reversely, access panels can not predict well who is not going to vote in current elections. If non-voters disproportionally voted for one party in the previous elections, this will lead to an overestimation of voters for that party.\nI believe these two problems are larger than most people think. The first problem can predict why the PVV-vote was underestimated in 2006 and 2010. The PVV attracted many new voters in those elections. The second problem explains why the PVV-vote was overestimated in 2012. Many people who voted PVV in the previous elections, stayed home this time.\nSo, panel survey managers who want a bit of free advice how to improve your polls. Try to get a clear view on the new voters, and the people unlikely to vote. That may be hard, especially because non-voters are not so interested in politics, and will therefore not sign up for online access panels voluntarily. But it is certainly not impossible.\n","date":1348322700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1348322700,"objectID":"2576aa32af1127d3f517a7965d7aae82","permalink":"https://peterlugtig.com/post/why-access-panels-cannot-weight/","publishdate":"2012-09-22T16:05:00.002+02:00","relpermalink":"/post/why-access-panels-cannot-weight/","section":"post","summary":"There are a lot of reasons why would not want to use acces panels for predicting electoral outcomes . These are well discussed in many places on- and offline. I\u0026rsquo;ll shortly summarize them, before adding some thoughts to why access panels do so badly predicting election outcomes.\n1. Access panels don\u0026rsquo;t draw random samples, but rely on self-selected samples. A slightly better way to get panel respondents is a quota sample, but even these have problems, well discussed here, here and here for example.","tags":["weighting","opinion poll","access panels","data quality","elections"],"title":"why access panels cannot weight elections polls accurately","type":"post"},{"authors":null,"categories":null,"content":"The night after the election, one can conclude that all pollsters in the Netherlands did a bad job of predicting the election results. All polls were at least off by 20 seats (out of 150), and I expect the newspapers to make headlines of this in the next days. See the table below for the final predictions (before election day), the exit poll and final election results. The last row shows how much each poll was off (in the number of seats\nActually, I think the pollsters did pretty well this time. The only thing all of them mispredicted, was a large number of PVV voters moving to VVD, and a lot of SP voters moving to the PvdA, This movement was visible in the last polls leading up to the elections, but the pollsters either underestimated it, or a lot of people switched for the winner on election date.\nSo, I predicted Synovate would do best, but that did not turn out to be the case. Well, they share first place with Maurice de Hond, but are not clearly better than others. There are lots of blogs, articles and news items about Internet Panels these days. I spent some blogposts on that issue in 2009 myself. Although the largest reason why pollers generally do so badly is that they do not draw random samples, I think there are two more reasons why pollsters do badly. I plan to spend my next two blog posts on these topics, so stay tuned for more on the following issue.\nPollsters use statistical weighting to account for the unrepresentativity of their panel. They do this on sociodemographic characteristics and past voting behavior. I believe it is wrong to weight (in general), and specifically to do so on past voting behavior. I\u0026rsquo;ll show you why in the next days.\nNo. of seats in partliament 2012\n Maurice de Hond (peil.nl)\nIntomart/de stemming\n Synovate\n TNS-NIPO\nExit Poll (synovate)\nFinal results\nVVD (right-liberal)\n36\n35\n37\n35\n41\n41\nPVDA (social democrat)\n36\n34\n36\n34\n40\n38\nSP (socialist)\n20\n22\n21\n21\n15\n15\nPVV (anti-immigrant)\n18\n17\n17\n17\n13\n15\nCDA (christian democrats)\n12\n12\n13\n12\n13\n13\nD\u0026rsquo;66 (center liberals)\n11\n11\n10\n13\n12\n12\nCU (christian union)\n5\n 7\n5\n6\n4\n5\nSGP (reformed christians)\n3\n3\n2\n2\n3\n3\nGroenlinks (green)\n4\n4\n4\n 4\n4\n4\nPVDD (animal rights\n3\n2\n3\n 2\n2\n2\n50plus (elderly)\n2\n3\n 2\n 4\n3\n2\nWrongly predicted\n18\n24\n18\n24\n6\n","date":1347530220,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1347530220,"objectID":"02926fde7fcb2ee5d076eb2025f531e9","permalink":"https://peterlugtig.com/post/dutch-elections-2012-poll-results/","publishdate":"2012-09-13T11:57:00+02:00","relpermalink":"/post/dutch-elections-2012-poll-results/","section":"post","summary":"The night after the election, one can conclude that all pollsters in the Netherlands did a bad job of predicting the election results. All polls were at least off by 20 seats (out of 150), and I expect the newspapers to make headlines of this in the next days. See the table below for the final predictions (before election day), the exit poll and final election results. The last row shows how much each poll was off (in the number of seats","tags":["weighting","TNS NIPO","maurice de hond","opinion poll","access panels","exit poll","Intomart","Synovate","polls"],"title":"Dutch elections 2012 - poll results","type":"post"},{"authors":null,"categories":null,"content":"**Poll volatility **\nBelow, you find the summed changes in parliamentary seats over all parties in consecutive opinion polls for the four main polling firms in the Netherlands in the lead up to the 2012 elections. I will update the table below in the next weeks.\nThis overview follows from my earlier post on Dependent Interviewing. Maurice de Hond (peil.nl) is the only survey pre-loading earlier voter preferences into survey questions. I expect this to lead to less volatility in voter preferences for Maurice de Hond, as compared to the other polling firms.\nUpdate September 12th: With the final polls out on election day, it seems that the polls of Maurice de Hond are indeed most stable over time, and in my previous post I argues this was because of the fact that he uses Dependent Interviewing in his question on \u0026quot; what would you vote if there were elections today\u0026rdquo;. Still, I would have expected a larger effect. Let\u0026rsquo;s see tomorrow which polling firm did best. My bet: Synovate, because they are using the most sound (although still not perfect) methodology of polling people. More on that tomorrow\u0026hellip;\n Maurice de Hond (peil.nl)\nIntomart/de stemming\n Synovate\n TNS-NIPO\n week 23 (03-06)\n4\n-\n 8\n-\n 10-06\n8\n-\n-\n-\n 17-06\n6\n-\n 8*\n-\n 24-06\n4\n-\n-\n 14**\n 01-07\n10\n-\n 12*\n 8\n 08-07\n12\n-\n 12\n 12\n 15-07\n6\n 8\n 10\n 12\n 22-07\n2\n 10\n-\n 6\n 29-07\n4\n-\n 8*\n 6\n 05-08\n2\n-\n-\n 10\n 12-08\n10\n10**\n 8*\n 16\n 19-08\n8\n 8\n12\n 8\n 26-08\n6\n20\n8\n16\n03-09\n22\n20\n12\n14\n10-09\n26\n10\n16\n20\n average change\n8,7\n12,2***\n10,3***\n11,8\n* two-week difference\n** three-week difference\n*** rounded down due to inclusion of multi-week changes\n","date":1345806900,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1345806900,"objectID":"e2fc42614d9f3b69fabcdf32dd6c6ee4","permalink":"https://peterlugtig.com/post/electoral-volatility-due-to-different/","publishdate":"2012-08-24T13:15:00.003+02:00","relpermalink":"/post/electoral-volatility-due-to-different/","section":"post","summary":"**Poll volatility **\nBelow, you find the summed changes in parliamentary seats over all parties in consecutive opinion polls for the four main polling firms in the Netherlands in the lead up to the 2012 elections. I will update the table below in the next weeks.\nThis overview follows from my earlier post on Dependent Interviewing. Maurice de Hond (peil.nl) is the only survey pre-loading earlier voter preferences into survey questions.","tags":["TNS NIPO","maurice de hond","dependent interviewing","opinion poll","Intomart","Synovate","elections"],"title":"Electoral volatility due to different questions?","type":"post"},{"authors":null,"categories":null,"content":"I was re-reading one of the papers I wrote as part of my dissertation on survey data quality in panel surveys. The paper deals with the effects of the introduction of an interviewing technique called Dependent Interviewing in the British Household Panel Survey. I wrote this paper together with Annette Jackle, and if you are interested after reading the next bit, you can download a working paper version of it here. Dependent Interviewing uses data from respondents from earlier interviews in survey questions. Instead of asking respondents every year the question \u0026ldquo;what types of income do you receive\u0026quot;, you can also ask them:\n\u0026ldquo;last year, you told us that you receive income from your private pension plan, the state pension, as well as income from renting out a house. Is this still the same?\u0026quot;\nThere are of course multiple ways in which you can use information like this, and the BHPS actually uses Dependent Interviewing in a slightly more sophisticated way, but the basic idea is in my opinion quite intuitive. Why would you ask the same questions time and time again, when you already know so much about respondents?\nThe paper we wrote documents the effects on data quality, and specifically investigates what the effect of Dependent Interviewing is on measures of household income. In short, the effects are not huge, but it turns out that Dependent Interviewing is especially effective for poorer households. These households depend for a large part on different kinds of government transfers, and these are easily forgotten or underreported. When the effects of Dependent Interviewing are taken into account, the poorer households become a little richer, and so, all in all, poverty is actually a little lower than was previously estimated.\nPerhaps interesting to Dutch readers, one of the main pollers in the Netherlands, Maurice de Hond, is also using Dependent Interviewing in his surveys (on all questions!). I am a member of his panel, and when I complete a survey, I only have to change answers if I want to, and otherwise just confirm my answers from the previous waves.\nI see why Maurice de Hond has chosen to do this. Electoral preferences are very volatile, and panel surveys on voter preferences are perhaps too volatile. But I have serious doubts whether Dependent Interviewing here solves volatility. It rather creates articficial stability. In the first week of july, Maurice de Hond polled an average weekly change of seats of 10. Ipsos Synovate (see my earlier posts on why I trust them most), 12. Actually a small difference. There are many newspapers following and criticising the actual poll results. I\u0026rsquo;ll try to keep you updated on volatility across the polls, meanwhile trying to answer the question whether one should trust stable polls, or volatile polls.\n","date":1345050780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1345050780,"objectID":"d2da8ec3bb60bb88570855c8656d272a","permalink":"https://peterlugtig.com/post/dependent-interviewing-and-longitudinal/","publishdate":"2012-08-15T19:13:00+02:00","relpermalink":"/post/dependent-interviewing-and-longitudinal/","section":"post","summary":"I was re-reading one of the papers I wrote as part of my dissertation on survey data quality in panel surveys. The paper deals with the effects of the introduction of an interviewing technique called Dependent Interviewing in the British Household Panel Survey. I wrote this paper together with Annette Jackle, and if you are interested after reading the next bit, you can download a working paper version of it here.","tags":["income","maurice de hond","dependent interviewing","Annette Jackle","data quality","elections"],"title":"Dependent Interviewing, and stability in opinion polls","type":"post"},{"authors":null,"categories":null,"content":"23-07 I\u0026rsquo;ve changed some things around, integrating my weblog posts with a new personal homepage, where I intend to assemble everything that is now still to be found on diverse pages, as Linked-in, the Utrecht University homepage, and stuff that is just out there on the web. Keep visiting this page, as it will undergo major changes in the next months!\n31-07 Switched the entire homepage to english, and have added a list of downloadable publications.\n25-08 Further changes and news will be listed under the \u0026ldquo;news and agenda\u0026rdquo; page\n","date":1343331600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343331600,"objectID":"f69dab9afa2592c7b37028cbc30e75b4","permalink":"https://peterlugtig.com/post/new-homepage/","publishdate":"2012-07-26T21:40:00.002+02:00","relpermalink":"/post/new-homepage/","section":"post","summary":"23-07 I\u0026rsquo;ve changed some things around, integrating my weblog posts with a new personal homepage, where I intend to assemble everything that is now still to be found on diverse pages, as Linked-in, the Utrecht University homepage, and stuff that is just out there on the web. Keep visiting this page, as it will undergo major changes in the next months!\n31-07 Switched the entire homepage to english, and have added a list of downloadable publications.","tags":null,"title":"new homepage","type":"post"},{"authors":["Schoot","A.G.J. van de","Lugtig","P.","and Hox","J."],"categories":[],"content":"","date":1337036400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1337036400,"objectID":"34f0e1ec449a05947d8611c7c755097e","permalink":"https://peterlugtig.com/publication/2012_schoot_a_checklist_for_testing/","publishdate":"2012-05-15T00:00:00+01:00","relpermalink":"/publication/2012_schoot_a_checklist_for_testing/","section":"publication","summary":"The analysis of measurement invariance of latent constructs is important in research across groups, or across time. By establishing whether factor loadings, intercepts and residual variances are equivalent in a factor model that measures a latent concept, we can assure that comparisons that are made on the latent variable are valid across groups or time. Establishing measurement invariance involves running a set of increasingly constrained structural equation models, and testing whether differences between these models are significant. This paper provides a step-by-step guide to analysing measurement invariance.","tags":[],"title":"A checklist for testing measurement invariance","type":"publication"},{"authors":["Monshouwer","K.","Harakeh","Z.","Lugtig","P.","Huizink","A.","Creemers","H.E.","Reijneveld","S.A.","De Winter","A.F.","van Oort","F.","Ormel","J.","and Vollebergh","W.A.M."],"categories":[],"content":"","date":1331938800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1331938800,"objectID":"68755163b76a8ee2fc9651dc76be4e6b","permalink":"https://peterlugtig.com/publication/2012_monshouwer_prevalence_and_predictors/","publishdate":"2020-02-05T21:21:22+01:00","relpermalink":"/publication/2012_monshouwer_prevalence_and_predictors/","section":"publication","summary":"The present study examined the joint development of substance use and externalizing problems in early and middle adolescence. First, it was tested whether the relevant groups found in previous studies i.e., those with an early onset, a late onset, and no onset or low levels of risk behavior could be identified, while using a developmental model of a single, underlying construct of risk behavior. Second, departing from Moffitt’s taxonomy of antisocial behavior, it was tested if early, but not late, onset risk behavior is predicted by a problematic risk profile in childhood. Data were used from TRAILS, a population based cohort study, starting at age 11 with two follow-ups at mean ages of 13.6 and 16.3 years. Latent transition analyses demonstrated that, both in early and middle adolescence, a single underlying construct of risk behavior, consisting of two classes (labeled as low and high risk behavior), adequately represented the data. Respondents could be clearly classified into four possible transition patterns from early to middle adolescence, with a transition from high to low being almost non-existent (2.5 %), low to low (39.4 %) and low to high (41.8 %) being the most prevalent, and high to high (16.2 %) substantial. As hypothesized, only the high-high group was characterized by a clear adverse predictor profile in late childhood, while the low-high group was not. This study demonstrates that the development of substance use is correlated with externalizing problems and underscores the theory that etiologies of early and later onset risk behavior are different.","tags":[],"title":"Prevalence and predictors of transitions into co-occurring risk behaviour patterns in adolescence: The TRAILS study","type":"publication"},{"authors":null,"categories":null,"content":"In late august of 2011 I attended the Internet Survey Methodology Workshop. There were people from academia, official statistics and market research agencies there. One of the issues discussed there has had me thinking since: the topic of panel conditioning. Some people seem really worried that respondents in panel surveys start behaving or thinking differently because of repeated participation in a survey.\nPanel conditioning is closely linked with the issue of \u0026lsquo;professional\u0026rsquo; respondents. These are respondents who know exactly how survey researchers design surveys, and use this knowledge to get most out of the survey (in terms of reward-schemes) against the least time possible.\nMany market research firms throw out respondents after some time, mostly a couple of years, and then refresh their samples. But is this necessary? If so, after what time do respondents become conditioned? And for what topics is conditioning most problematic?\nSeveral studies from the 1970s focused on voting behavior in election panel studies. They found that respondents who were asked before a general election aboyut their voting behavior were 10-15% more likely to vote than respondents who were only asked about their voting behavior after the election. I wrote about exit-polls earlier; panel conditioning might be one of the reasons why Internet-panels do so badly at predicting election outcomes. Many other studies have focused on panel conditioning: for attitudes, cognitive abilities, knowledge, marital satisfaction and consumer behavior. Use google scholar on \u0026lsquo;practice effect\u0026rsquo;, \u0026lsquo;reactivity\u0026rsquo;, \u0026lsquo;panel conditioning\u0026rsquo;, \u0026lsquo;test-retest effect\u0026rsquo; and you\u0026rsquo;ll see what I mean.\nOverall, the findings suggest that panel conditioning may indeed be problematic, but not in all studies, or for all people. I have some ideas on the circumstances that lead or do not lead to conditioning effects (topic saliency, interval between measurements, frequency of measurement), but none of the studies systematically analyses potential causes for conditioning effects. I am hoping to add some work on this issue in the next years. If anyone know of interesting panel studies that are confronted with panel conditioning effects, let me know\u0026hellip;\n","date":1326373920,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1326373920,"objectID":"437c2df067759fc4fe9c747b147294dd","permalink":"https://peterlugtig.com/post/panel-conditioning/","publishdate":"2012-01-12T14:12:00+01:00","relpermalink":"/post/panel-conditioning/","section":"post","summary":"In late august of 2011 I attended the Internet Survey Methodology Workshop. There were people from academia, official statistics and market research agencies there. One of the issues discussed there has had me thinking since: the topic of panel conditioning. Some people seem really worried that respondents in panel surveys start behaving or thinking differently because of repeated participation in a survey.\nPanel conditioning is closely linked with the issue of \u0026lsquo;professional\u0026rsquo; respondents.","tags":["conference","panel conditioning","market research","opinion poll","workshop","panel survey"],"title":"panel conditioning","type":"post"},{"authors":null,"categories":null,"content":"Gerry Nicolaas (of Natcen) has just written a good review on the nonresponse workshop we both attended this year. See http://natcenblog.blogspot.com/2011/10/challenges-to-current-practice-of.html#comment-form The Nonresponse Workshops are a great place to meet and discuss with survey researchers in a small setting. The next workshop is to be held early september 2012 at Statistics Canada. See www.nonresponse.org\n","date":1319198460,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1319198460,"objectID":"0ec47010f62c429839e48d0ef7b608e0","permalink":"https://peterlugtig.com/post/trouble-of-nonresponse-studies/","publishdate":"2011-10-21T14:01:00.002+02:00","relpermalink":"/post/trouble-of-nonresponse-studies/","section":"post","summary":"Gerry Nicolaas (of Natcen) has just written a good review on the nonresponse workshop we both attended this year. See http://natcenblog.blogspot.com/2011/10/challenges-to-current-practice-of.html#comment-form The Nonresponse Workshops are a great place to meet and discuss with survey researchers in a small setting. The next workshop is to be held early september 2012 at Statistics Canada. See www.nonresponse.org","tags":["conference","nonresponse","workshop","nonresponse error","Gerry Nicolaas"],"title":"The trouble with nonresponse studies","type":"post"},{"authors":null,"categories":null,"content":"I\u0026rsquo;m not dead! In fact, I have been very alive over the past half a year: moving, finishing my Ph.D and starting a new job. With all that settled, I am determined to start where I left off.\nI often get questions about software to do Structural Equation Modeling. There are quite a few packages out there, some more user-friendly or sophisticated than others. Here is an overview of existing packages and my opinion on the pro\u0026rsquo;s and cons of each.\n \u0026lsquo;Old\u0026rsquo; software:\nI was trained to work with LISREL as a student. LISREL still exists, but updates have become sparse over the last decade. It was developed by Karl Joreskog , one of the great pioneers of SEM and Dag Sorbom . Although it hasn\u0026rsquo;t been updated for over 5 years, it is still one of the most widely used software packages. The great thing about LISREL is that it allows flexibility. It can handle categorical data and multilevel-data. The LISREL language has been adopted by other SEM-packages. LISREL requires users to know some matrix algebra, to understand what specific parameters to estimate.\n Mx and EQS were until the end of the 1990s the main competitors to LISREL. Mx has been revamped as an R-package ( openMx ), while EQS is still in use today. I have never worked with EQS myself, but because of the involvement of Peter Bentler in the EQS-project, it has always been cutting-edge when it comes to the handling of categorical data. There seem to be few people using the software, and although being updated now and then, the possibilities in EQS when it comes to mixture and multilevel-models seem limited.\n AMOS is still one of my favorites, although since taken over by the evil empire of SPSS, development has grinded to a standstill. The thing I love about AMOS is its drag-and-drop interface, and is user-friendliness. I use AMOS to teach students the first things about SEM, and it works great. AMOS has no possibility to handle multi-level data or mixture models however, and although it can deal with categorical data, there are other packages that do a better job.\n\u0026lsquo;New\u0026rsquo; software:\nSince 2000 some new software packages have taken over the role of LISREL, Mx and EQS as leading software packages. They are either more user-friendly, are better integrated with standard statistical software, or more sophisticated.\n MPLUS is currently the package to beat. It is an extremely sophisticated programme, with frequent large updates. When it comes to modeling possibilities, there is no other package that comes close to MPLUS. It can handle all types of mixture models, and now includes a Bayesian module that opens a whole new world for statistical modelers. Bengt Muthen is the driving force behind Mplus, contributing greatly to the expansion of SEM models beyond psychometrics and sociometrics. I work with Mplus on a daily basis, and together with some colleagues at Utrecht University, we regularly organize meetings, or teach courses in Mplus. See www.fss.uu.nl/mplus if you want to know more.\nStata ( Glamm ) and Sas ( procalis ) have integrated SEM packages into their main statistical packages. I have never worked with these packages before, but from the literature it seems they are capable of doing the basic SEM analysis (factor models, path models) in a good way. Procalis has a good module for doing Latent Class and Latent transition analysis.\n Latent Gold is another package especially designed for Latent Class analysis and mixture models, although it can handle simpler types of SEM as well. The power of this software package lies in the flexibility of specifying link functions between observed and latent variables. It is currently the only package that can deal with ordinal latent variables and boasts some intelligent algorithms that make the estimation of mixture models way faster than for example Mplus.\nFinally, three packages in R can do SEM. The great benefit of these packages is that they are open source, and allow the user to program functions himself, or to integrate R-scripts with packages prorgrammed by others. OpenMx (mentioned earlier) and Lavaan seem to the two packages that are currently most advanced. I\u0026rsquo;ve heard mixed opinions about the sem package in R, so would not opt for that package\n","date":1319018100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1319018100,"objectID":"be51910111ea3ef7505b5735ec6638a3","permalink":"https://peterlugtig.com/post/sem-software/","publishdate":"2011-10-19T11:55:00.001+02:00","relpermalink":"/post/sem-software/","section":"post","summary":"I\u0026rsquo;m not dead! In fact, I have been very alive over the past half a year: moving, finishing my Ph.D and starting a new job. With all that settled, I am determined to start where I left off.\nI often get questions about software to do Structural Equation Modeling. There are quite a few packages out there, some more user-friendly or sophisticated than others. Here is an overview of existing packages and my opinion on the pro\u0026rsquo;s and cons of each.","tags":["Mplus","Latent Gold","SEM","Lisrel","software","AMOS","review","EQS","R","Mx"],"title":"SEM software","type":"post"},{"authors":["Lugtig","P.","Lensvelt-Mulders","G.J.L.M.","R. Frerichs and Greven","A."],"categories":[],"content":"","date":1314831600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314831600,"objectID":"22f5b18685f8e13bcf9a895907f2b0b1","permalink":"https://peterlugtig.com/publication/2011_lugtig_estimating_nonresponse/","publishdate":"2011-09-01T00:00:00+01:00","relpermalink":"/publication/2011_lugtig_estimating_nonresponse/","section":"publication","summary":"In mixed-mode surveys, it is difficult to separate sample selection differences from mode-effects that can occur when respondents respond in different interview settings. This paper provides a framework for separating mode effects from selection effects by matching very similar respondents from different survey modes using propensity score matching. The answer patterns of the matched respondents are subsequently compared. We show that matching can explain differences in nonresponse and coverage in two Internet samples. When we repeat this procedure for a telephone and Internet sample however, differences persist between the samples after matching. This indicates the occurrence of mode effects in telephone and Internet surveys. Mode effects can be problematic; hence we conclude with a discussion of designs that can be used to explicitly study mode effects.","tags":[],"title":"Estimating nonresponse bias and mode effects in a mixed-mode survey","type":"publication"},{"authors":["Lugtig","P.","and Jäckle","A."],"categories":[],"content":"","date":1314831600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314831600,"objectID":"4e83b446251e606971a92b0670eeeb0c","permalink":"https://peterlugtig.com/publication/2011_lugtig_in_interview_edit_checks/","publishdate":"2011-09-01T00:00:00+01:00","relpermalink":"/publication/2011_lugtig_in_interview_edit_checks/","section":"publication","summary":"Household income is difficult to measure, since it requires collecting information about all potential income sources for each member of a household. We assess the effects of two types of edit check questions on measurement error and survey estimates: within-wave edit checks use responses to questions earlier in the same interview to query apparent inconsistencies in responses; dependent interviewing uses responses from prior interviews to query apparent inconsistencies over time. The findings suggest that traditional interviewing methods underestimate household income in the lower tail of the income distribution, but that neither edit check method has much effect on estimated poverty rates or transition rates in poverty.","tags":[],"title":"In-Interview edit checks: Effects on measurement error in non-labour income and estimates of household income and poverty","type":"publication"},{"authors":["Lugtig","P.","Boeije","H.R.","and Lensvelt-Mulders","G.J.L.M."],"categories":[],"content":"","date":1312498800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1312498800,"objectID":"538681c1589090ff395901343efeca8e","permalink":"https://peterlugtig.com/publication/2012_lugtig_change_what_change/","publishdate":"2011-08-05T00:00:00+01:00","relpermalink":"/publication/2012_lugtig_change_what_change/","section":"publication","summary":"A primary objective of panel studies is to analyze change. The same questionnaire is used to compare data recorded at various times. Panel designs assume that the meaning of the questions and the concept of interest are stable over time. Analyses of measurement invariance often show the contrary. A qualitative part supplementing a panel survey can help us understand this phenomenon. In this study, 261 first-year psychology students completed questionnaires about their study motivation on two occasions; we interviewed some students as well. The survey showed that study motivation is not invariant over time. The qualitative data converged with the quantitative outcomes and explained the lack of invariance by the students’ overall transition during the first study year. We conclude that mixing quantitative and qualitative research methods for panel studies helps us understand change in constructs over time. We can study change at the macrolevel and better understand such change at the microlevel.","tags":[],"title":"Change, what change? Understanding longitudinal measurement invariance using mixed-methods","type":"publication"},{"authors":null,"categories":null,"content":"Sorry for the long silence: have been caught up in work and other things that were always more pressing than writing blog posts. Perhaps it is also because I found it hard to write about statistical modeling. Statistical models are usually complex, and therefore it is difficult to write about them in an accessible way.\nStatistical models are everywhere; their goal is to summarize our world in such a way as to capture the essence, and leave out the irrelevant complexities. Therefore, I see graphs, figures and visualisation tools themselves as models not very differently from statistical models.\nIn the social sciences, I think statistical models are complex in two ways, that make them different from models in physics.\nFirst, our social world is generally more complex and nuanced than laws of physics, and therefore; more complex models are necessary.\nSecond, measurement in the social sciences are more difficult than in the exact sciences and contain more measurement error. Statistical Models in the social sciences should in my view therefore always incorporate some form of measurement errors. One technique that has become dominant in the social sciences, is the technique of Structural Equation Modeling (SEM). Ken Bollen, who is a famous SEM-scientist, explains what makes SEM such a good and attractive technique in the following video.\n","date":1305030840,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1305030840,"objectID":"931271896b4e1e3702045ef73b0c7c70","permalink":"https://peterlugtig.com/post/statistical-modeling-recent-advances/","publishdate":"2011-05-10T14:34:00.002+02:00","relpermalink":"/post/statistical-modeling-recent-advances/","section":"post","summary":"Sorry for the long silence: have been caught up in work and other things that were always more pressing than writing blog posts. Perhaps it is also because I found it hard to write about statistical modeling. Statistical models are usually complex, and therefore it is difficult to write about them in an accessible way.\nStatistical models are everywhere; their goal is to summarize our world in such a way as to capture the essence, and leave out the irrelevant complexities.","tags":["measurement error","SEM","statistical modeling","Ken Bollen"],"title":"Statistical modeling: SEM","type":"post"},{"authors":null,"categories":null,"content":"One of the professors at the department where I work ( Joop Hox ) told me at our first meeting ever that good survey methodologists know their way around in the world of statistics. I think this saying should also go in the reverse order by the way, but I did take his advice seriously, and I am getting more and more interested in statistics, and specifically statistical modeling.\nA good statistical model in my view should be able to answer a specific (complicated) research questions about our social world, in a relatively straightforward way. This implies answering the question of causality (see previous post) is very important in all statistical models, and second, that the statistical model should summarize our social reality in a simple way.\nProving causality can be hard and depends mainly on a good research design. Summarizing our social reality in a not too simplified way is hard, but graphics can do wonders. The video below is very old (well, 5 years), and most of you have perhaps seen it, but it is a good illustration of what I think good researchers should try to achieve (including the Swedish overenthusiastic accent).\nBecause of the advent of Internet and abundance of IT-application, the amount of data that we have available for marketing and research is booming. The great challenge for statisticians (and here come the survey methodologists into play)in the next years is how to handle all this data, make them insightful, and use them to answer questions we weren\u0026rsquo;t able to asnwer before. A great blog post on this topic was posted last year on www.radar.oreilly.com . Highly advised.\nupdate 11-08-2016: update of the link above: http://www.simplilearn.com/resources-to-learn-data-science-online-article\n","date":1302180660,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1302180660,"objectID":"c81ed154ebcaf576a4a0d795fc3b2999","permalink":"https://peterlugtig.com/post/survey-methods-and-statistical-modeling/","publishdate":"2011-04-07T14:51:00.001+02:00","relpermalink":"/post/survey-methods-and-statistical-modeling/","section":"post","summary":"One of the professors at the department where I work ( Joop Hox ) told me at our first meeting ever that good survey methodologists know their way around in the world of statistics. I think this saying should also go in the reverse order by the way, but I did take his advice seriously, and I am getting more and more interested in statistics, and specifically statistical modeling.\nA good statistical model in my view should be able to answer a specific (complicated) research questions about our social world, in a relatively straightforward way.","tags":["statistical modeling","graphics","Hans Rosling","data science"],"title":"survey methods and statistical modeling","type":"post"},{"authors":null,"categories":null,"content":"A short post in between, so I can share two thoughts:\n1. it is now possible to post reactions to my blog posts. Because I\u0026rsquo;m new to blogging, the settings were not very inviting previously. Now, you can react very easily. Please do if you feel like it. I believe in progress by debate.\n2. I am not a specialist in the concept of causality myself, but I love Judea Pearl\u0026rsquo;s blog on the topic of causal relationships, counterfactuals and the role of covariates in the social sciences. He recently posted some great links, new ideas and video\u0026rsquo;s. Go and read it if you have a spare hour.\n  ","date":1301138760,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1301138760,"objectID":"18e77e9300d911c5da702265f4a9184d","permalink":"https://peterlugtig.com/post/causality/","publishdate":"2011-03-26T12:26:00.001+01:00","relpermalink":"/post/causality/","section":"post","summary":"A short post in between, so I can share two thoughts:\n1. it is now possible to post reactions to my blog posts. Because I\u0026rsquo;m new to blogging, the settings were not very inviting previously. Now, you can react very easily. Please do if you feel like it. I believe in progress by debate.\n2. I am not a specialist in the concept of causality myself, but I love Judea Pearl\u0026rsquo;s blog on the topic of causal relationships, counterfactuals and the role of covariates in the social sciences.","tags":["causality","covariates"],"title":"causality","type":"post"},{"authors":null,"categories":null,"content":"Instead of separating out mode effects from nonresponse and noncoverage effects through statistical modeling, it is perhaps better to design our mixed-mode surveys in such a way so that mode effects do not occur. The key principle in preventing the mode effects from occurring, is to make sure that questionnaires are cognitively equivalent to respondents. This means that no matter in which survey mode the respondents participate, they would give the same answer. In my opinion, there are two ways to achieve this.\n1. choose a mix of modes that lead to a cognitively equivalent survey process. The survey process is very different in a questionnaire administered in a telephone vs. an Internet mode. Some mode combinations are can however be combined without great differences between they survey process across the modes:\n- combine face-to-face with telephone modes: the mode of communication is in both modes aural with an interviewer asking and recording answers. The only difference is that the interviewer is physically present in the face-to-face survey, and not in the telephone survey.\n- combine mail and Internet modes. Differences between these modes are minimal. Whereas in the United States it is difficult to sample addresses (but not impossible), in Europe, this combination can easily be implemented. Don Dillman talks about some experiments with this method on the 2009 AAPOR conference (thanks to www.pollster.com).\n2. The second way is to use nonequivalent survey modes (for example the telephone and internet), but design the individual survey questions in such a way that they are still equivalent across modes. This implies that all questions should be simple, short and clear, and that there should be as few answer categories as possible (i.e. yes/no and similar). This means that it would be difficult to ask for attitudes or opinions in such a mixed mode design.\n","date":1300871340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1300871340,"objectID":"d898298a110f9517afb0ce960bb0ac66","permalink":"https://peterlugtig.com/post/mixed-mode-designs-cognitive/","publishdate":"2011-03-23T10:09:00.001+01:00","relpermalink":"/post/mixed-mode-designs-cognitive/","section":"post","summary":"Instead of separating out mode effects from nonresponse and noncoverage effects through statistical modeling, it is perhaps better to design our mixed-mode surveys in such a way so that mode effects do not occur. The key principle in preventing the mode effects from occurring, is to make sure that questionnaires are cognitively equivalent to respondents. This means that no matter in which survey mode the respondents participate, they would give the same answer.","tags":["equivalence","cognitive effects","Don Dillman","mode effect","measurement"],"title":"mixed-mode designs: cognitive equivalence","type":"post"},{"authors":null,"categories":null,"content":"Mixed mode surveys have shown to attract different types of respondents. This may imply that they are succesful. Internet surveys attract the young and telephone surveys the old, so any combination of the two can lead to better population estimates for the variable you\u0026rsquo;re interested in. In other words, mixed-mode surveys can potentially ameliorate the problem that neither telephone, nor Internet surveys are able to cover the entire population.\nThe bad news is that mode-effects (see posts below) coincide with selection effect in mixed-mode surveys. For that reason, it is hard to determine how succesful mixed-mode surveys are, and more importantly, really hard to combine results when there are large differences in the dependent variable across the survey modes.\nI think that matching is one of the few methods to adequately deal with this issue: the idea is straightforward. In any survey among the general population, there will be 1. people who are able and willing to only answer in a specific survey mode (i.e. the Internet or telephone), 2. respondents who would respond in both and 3. respondents who would not participate at all. This means that the composition of the telephone and Internet-samples in a mixed-mode survey will contain people unique to that mode, and people who can also be found in the other mode (see below - the match part).\n With matching, respondents who are similar on a set of covariates are matched from both survey modes, so that pairs of very similar respondents are formed from every survey mode. After matching, any differences that persists between the matched respondents from both samples cannot be due to selection effects on the covariates. Therefore, any differences that remain between the matched respondents after matching should exist only because of a mode effect: whether a question is asked by the interviewer or self-administered, whether it is audial or visual, and whether answers are spoken or written down.\nMatching can be easily done using the package MatchIt in R (amongst others). More information about matching in mixed-mode surveys can be found in a manuscript I wrote with some colleagues.\n","date":1300222620,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1300222620,"objectID":"379b307e72d92f44d55531fc778b2959","permalink":"https://peterlugtig.com/post/matching-to-correct-for-self-selection/","publishdate":"2011-03-15T21:57:00.001+01:00","relpermalink":"/post/matching-to-correct-for-self-selection/","section":"post","summary":"Mixed mode surveys have shown to attract different types of respondents. This may imply that they are succesful. Internet surveys attract the young and telephone surveys the old, so any combination of the two can lead to better population estimates for the variable you\u0026rsquo;re interested in. In other words, mixed-mode surveys can potentially ameliorate the problem that neither telephone, nor Internet surveys are able to cover the entire population.\nThe bad news is that mode-effects (see posts below) coincide with selection effect in mixed-mode surveys.","tags":["nonresponse error","mode effect","matching","mixed mode"],"title":"matching to correct for self-selection bias in mixed-mode surveys","type":"post"},{"authors":null,"categories":null,"content":"Mode effects - the fact that respondents respond differently to a survey question, solely because of the mode of interviewing - are hard to study. This is because mode-effects interact with nonresponse effects. An Internet survey will atract different respondents than a telephone survey. Because of this, any differences that result from this survey, could be either due to differences in the type of respondents, or because of a mode effect.\n  There are three basic methods to study mode effects. The most common way to study mode-effects is:\n1. to experimentally assign respondents to a survey mode. Then, the results from the survey are compared: the response rate, the demographic composition of the samples, and finally differences in the dependent variables. Sometimes, demographic differences between the samples are corrected using a multivariate model, like weighting. For an overview: see the results of this google scholar search.  This type of design is popular, but in my view it has a great drawback: we know Internet samples and telephone surveys do only cover a part of the population. Landline telephone coverage is rapidly declining, while Internet use remains limited to about 80 per cent of the general population in Western countries. There are two alternative approaches, that deal with this issue.\n     2. One can make respondents switch modes during the interview. For example from the telephone to the Internet, or from face-to-face to paper-and-pencil. Although this approach sounds very simple, relatively few studies have been conducted in this manner. See Heerwegh (2009) for a nice example. More experimental studies are defnitely welcome and necessary if we want to understand how problematic mode effects are.\n3. The third way of studying mode effects relies on more sophisticated statistical modeling to separate different sources of survey error. The most relevant errors in mixed-surveys are coverage, nonresponse and response errors (i.e. the mode effect). Separating these could be done using a) validation data b) repeated measurements using the same or different modes or c) matching. I am not aware of any mixed-mode studies that have used validation data to study mode effects, and as the mode effect occurs for attitudinal questions mainly, it is hard to find such data. The other two approaches both offer more practical ways of assessing mode effects. I will discuss both the modeling approach using longitudinal data and matching more extensively in next posts.\n","date":1298915700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298915700,"objectID":"9aefcb02908bb8ee247eb265557dba50","permalink":"https://peterlugtig.com/post/studying-mode-effects/","publishdate":"2011-02-28T18:55:00.004+01:00","relpermalink":"/post/studying-mode-effects/","section":"post","summary":"Mode effects - the fact that respondents respond differently to a survey question, solely because of the mode of interviewing - are hard to study. This is because mode-effects interact with nonresponse effects. An Internet survey will atract different respondents than a telephone survey. Because of this, any differences that result from this survey, could be either due to differences in the type of respondents, or because of a mode effect.","tags":["nonresponse error","separating error sources","mode effect","coverage error"],"title":"studying mode effects","type":"post"},{"authors":null,"categories":null,"content":"One of the most interesting issues in survey research is the mode effect. A mode effect can occur in mixed-mode surveys, where different questionnaire administration methods are combined. The reasons for mixing survey modes are multifold, but usually survey researchers mix modes to limit nonresponse, reach particular hard-to-reach types of respondents, or limit measurement error. It is more common today to mix modes than not mix them, for some good reasons:\n  1. nonresponse to survey requests is ever increasing. In the 1970s it was feasible to achieve a 70% response rate without too much effort in the U.S. and the Netherlands. Nowadays, this is very difficult. In order to limit costs and increase the likelihood of a response, survey organisations use a mix of consecutive modes. For example, it starts by mailing a cheap questionnaire by mail, perhaps with an URL included in the mail. Nonrespondents are then followed up by more expensive modes: they are phoned, and/or later visited at home to make sure response rates go up.\n2. there are few survey modes that are able to reach everyone. In the 1990s, almost everyone had a landline phone, now only 65% does so. Internet penetration is at about 85%, but does not seem to get higher. In order to reach everyone, we have to mix modes. On top of that, certain types of respondents may have mode preferences. Young people are commonly believed to like web-surveys (I\u0026rsquo;m not too sure of that), while older people like phone or face-to-face surveys.\n  3. for some questions, we know it is better to ask them in particular modes. Sensitive behaviors and attitudes, like drug use, committing fraud, or attitudes towards relationships, are better measured when the survey is anonymous (i.e. when no interviewer is present). For questions that are difficult and require explanation the opposite is true: interviewers are necessary for exmple to get a detailed view of someone\u0026rsquo;s income.\nMixing survey modes seems to be a good idea from all these angles. One problematic feature however is that people react differently when they answer a question on the web or on the phone. This is because it makes a difference whether a questions is read out to you (phone), or whether you can read the question yourself. Also, it matters whether an interviewer is present or not, and whether you have to tell your answer or whether you can write it down. These differences between survey modes lead to all kinds of differences in the data: the mode effect. Although differences between survey modes are well documented, the problem is that mode effects and other effects are confounded: the different modes attract different people. People on the phone might be less likely to give a negative answer due to the interviewer being present, but it could also be that phone surveys attract older people, who are also less likely to answer negatively. The fact that measurement errors and non-measurement errors interact in mixed-mode surveys makes it very difficult to estimate how problematic mode effects are in practice, and whether we should be worried about them. In my next post I will outline some ways how mode-effects could in my view be studied and better understood\n","date":1298274300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298274300,"objectID":"18fac8aa71d6fb4596c8a37ba202fc4f","permalink":"https://peterlugtig.com/post/mode-effects/","publishdate":"2011-02-21T08:45:00.002+01:00","relpermalink":"/post/mode-effects/","section":"post","summary":"One of the most interesting issues in survey research is the mode effect. A mode effect can occur in mixed-mode surveys, where different questionnaire administration methods are combined. The reasons for mixing survey modes are multifold, but usually survey researchers mix modes to limit nonresponse, reach particular hard-to-reach types of respondents, or limit measurement error. It is more common today to mix modes than not mix them, for some good reasons:","tags":["measurement error","nonresponse error","mode effect","Internet survey"],"title":"mode effects","type":"post"},{"authors":["De Ridder","D.T.D","de Boer","B.","Lugtig","P.","Bakker","A.","and van Hooft","E.A.J."],"categories":[],"content":"","date":1297465200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297465200,"objectID":"b2ac5c08a298356e0d41b56124aad4c1","permalink":"https://peterlugtig.com/publication/2011_de_ridder_not_doing_bad_things/","publishdate":"2011-02-12T00:00:00+01:00","relpermalink":"/publication/2011_de_ridder_not_doing_bad_things/","section":"publication","summary":"The present study investigated whether a conceptual distinction between two components of self-control (inhibitory and initiatory self-control) is empirically valid. To that purpose, a series of confirmative factor analyses were employed in two samples (total N = 577), providing support for a distinction between inhibitory and initiatory self-control. In addition, the predictive validity of the two components of self-control was examined by regression analyses with (un)desired health/academic behavior as dependent variables, showing that inhibitory self-control was a superior predictor of undesired behavior and initiatory self-control a better predictor of desired behavior.","tags":[],"title":"Not doing bad things is not equivalent to doing the right thing: Distinguishing between inhibitory and initiatory self-control","type":"publication"},{"authors":null,"categories":null,"content":"Before people believe I\u0026rsquo;m old-fashioned, I do think that Internet-surveys, even panel surveys are the future of survey research. John Krosnick makes some good points in a video shot by the people from www.pollster.com ","date":1297332780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297332780,"objectID":"94fca2968808a017ddfc26688e800ffd","permalink":"https://peterlugtig.com/post/how-to-use-internet-panels-for-polling/","publishdate":"2011-02-10T11:13:00+01:00","relpermalink":"/post/how-to-use-internet-panels-for-polling/","section":"post","summary":"Before people believe I\u0026rsquo;m old-fashioned, I do think that Internet-surveys, even panel surveys are the future of survey research. John Krosnick makes some good points in a video shot by the people from www.pollster.com ","tags":["John Krosnick","AAPOR","opinion poll","access panels","data quality"],"title":"how to use Internet panels for polling","type":"post"},{"authors":null,"categories":null,"content":"1. Is it clear who ordered and financed the poll?\n2. Is there a report documenting the poll\u0026rsquo;s procedures?\n3. Is the target population clearly described?\n4. is the questionnaire available and has it been tested?\n5. what were the sampling procedures?\n* the sample should be drawn for the target population. If it only contains for example people with Internet access, be careful\n6. What is the number of respondents?\n7. Is the response percentage sufficient?\n* it is difficult to say what percentage is sufficient. Higher response percentages do not automatically lead to better data quality. 10 or 20 % is however too low.\n8. Have the data been weighted?\n9. Are the margins of error being reported?\nFor more info, check the website of Jelke Bethlehem (in Dutch), or download the checklist here , with an explanation (in Dutch)\n","date":1297330680,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297330680,"objectID":"51e20d7ce544bb7ffddd260e4d65eb9b","permalink":"https://peterlugtig.com/post/checklist-for-quality-of-opinion-polls/","publishdate":"2011-02-10T10:38:00+01:00","relpermalink":"/post/checklist-for-quality-of-opinion-polls/","section":"post","summary":"1. Is it clear who ordered and financed the poll?\n2. Is there a report documenting the poll\u0026rsquo;s procedures?\n3. Is the target population clearly described?\n4. is the questionnaire available and has it been tested?\n5. what were the sampling procedures?\n* the sample should be drawn for the target population. If it only contains for example people with Internet access, be careful\n6. What is the number of respondents?","tags":["journalists","NPSO","impact","checklist","data quality","Jelke Bethlehem"],"title":"checklist for quality of opinion polls","type":"post"},{"authors":null,"categories":null,"content":"Many opinion pollers do badly when it comes to predicting elections. This is mainly because they let their respondents self-select them into their polls. So what, who cares? The polls make for some good entertainment and easily fill the talk-shows on television. If everyone knows they cannot be trusted, why care?\nWe should care. In the Dutch electoral system - with poportional respresentation - every vote counts. If only a small percentage of voters lets their vote depend on the polls of the election result, this can result in shifts of several seats in parliament. It is unclear how many voters decide how to vote based on the opinion polls, but it is a fact that there are many voters who consider voting for two or more parties, and many who do vote strategically. The Dutch Parliamentary Election Study (DPES) in 2006 found that 18% of voters indicated that they let their vote be influenced by the election polls. This amounts to a total of 27 parliamentary seats: almost the number of seats of the largest party in the current parliament .\nAs long as voters choose strategically in different ways this may not matter. If someone votes strategically to make sure a new government has the the greens in it, but someone else votes strategically for labour to make sure his or her favourite candidate becomes prime mininster, the net effect of strategical voting might be zero or very small. There is evidence however, that this is not the case. People like to vote for winners. This is called the bandwagon effect . Whenever labour does well in the (biased) opinion polls, more voters will consider voting for them. This may in the end lead to the fact political parties (and pollers) have a lot of interest to do well in polls. In fact, it may be tempting to publish fraudulent polls. This seems to be increasingly common in the United States, where they call them \u0026ldquo;push polls\u0026rdquo; . Publish fraudulent polls on purpose to make public opinion shift in your favor.\nSo, what to do about it? First, I think it would be fair not to publish any opinion polls some time before election day, as is done in France for example (albeit only for two days). Second, journalists and newsreaders should be very critical towards opinion polls, and only publish them when some basic quality criteria have been assessed and met. The Dutch Organisation on Survey Research has taken the initiative to develop a checklist for journalists. I will put it online soon.\n","date":1297329060,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297329060,"objectID":"ae1125b8dd5b43b56c0fe236e47133e2","permalink":"https://peterlugtig.com/post/influence-of-polls-on-voting-behavior/","publishdate":"2011-02-10T10:11:00+01:00","relpermalink":"/post/influence-of-polls-on-voting-behavior/","section":"post","summary":"Many opinion pollers do badly when it comes to predicting elections. This is mainly because they let their respondents self-select them into their polls. So what, who cares? The polls make for some good entertainment and easily fill the talk-shows on television. If everyone knows they cannot be trusted, why care?\nWe should care. In the Dutch electoral system - with poportional respresentation - every vote counts. If only a small percentage of voters lets their vote depend on the polls of the election result, this can result in shifts of several seats in parliament.","tags":["NPSO","bandwagon effect","exit poll","data quality","elections","polls","push polls"],"title":"the influence of polls on voting behavior","type":"post"},{"authors":null,"categories":null,"content":"There are several ways to do an exit poll, but they all come down to asking people what they voted, right after they went into the voting booth. The first succesfull modern exit poll was conducted in 1967 to predict the governor\u0026rsquo;s election of Kentucky .\nOne of the difficulties in exit polling, is that some people might not want to say whom they vote for, especially if this person is politically controversial. This might be one of the reasons why Geert Wilders, and the PVV in general always underperform in Dutch exit polls. The second difficulty is selecting a number of polling stations. Good exit polls do this either randomly, or (even better) choose stratified sampling. Stratified sampling is particularly important when voting behavior has a strong regional component. For example, a random selection of polling stations in the Netherlands, might exclude by chance any localities in the \u0026lsquo;bible belt\u0026rsquo; , where people often vote for the SGP leading to a under-represntation of voters for the SGP. Stratifying on past voting behavior in polling stations can increases statistical power , making sure we need fewer polling stations to achieve the same margin of error.\nIn the past, exit polls were conducted like this. Slowly, market research firms have first switched to telephone surveys, and later Internet surveys to do their exit poll. Both TNS NIPO and peil.nl relied on their panel to predict the election results. This once again shows how people who voluntarily join access panels can not be used to produce good statistics for the general population.\nWisely, the Dutch news stations (ANP, NOS, RTL) chose to do a proper, old-school exit poll in 2010. See this post for details (in Dutch).\nSo what, one might ask? Why worry about the crappy polls? We can just ignore them, and then focus on the polls that do a good job? Alas, people are heavily influenced by polls in the media in the period leading up to elections. More on this, and strategic voting, next time\n","date":1295863500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1295863500,"objectID":"bdb873a4741ca8f2a45f149cb6bacc14","permalink":"https://peterlugtig.com/post/how-to-do-exit-poll/","publishdate":"2011-01-24T11:05:00.001+01:00","relpermalink":"/post/how-to-do-exit-poll/","section":"post","summary":"There are several ways to do an exit poll, but they all come down to asking people what they voted, right after they went into the voting booth. The first succesfull modern exit poll was conducted in 1967 to predict the governor\u0026rsquo;s election of Kentucky .\nOne of the difficulties in exit polling, is that some people might not want to say whom they vote for, especially if this person is politically controversial.","tags":["sampling","access panels","exit poll","elections"],"title":"how to do an exit-poll","type":"post"},{"authors":null,"categories":null,"content":"Opinion pollers do a lousy job of predicting elections. For a good read, see for example the prediction of the New Hampshere primary in 2008, when all polls predicted Obama to win, but it was Clinton who won (albeit by a slim margin).\nIn the Dutch context, there are three main polling firms, that each do equally well (or badly). Out of a hundred and fifty parliamentary seats, peil.nl mispredicted 20, while TNS-NIPO and Synovate shared the honor of only missing the target by 16 seats in the 2010 parliamentary election. These polls were conducted the day before the election, and some of the pollers said that people might have changed their vote at the last minute. That may very well be, but even the exit poll on the night of the election was wrong. Peil.nl was 17 seats off and TNS NIPO 15 . Only Synovate did a lot better, and only missed the true result by 3 seats. I will discuss why this is in a next post, but it is just a matter of speed and low costs versus quality.\nAnd we have known for a long, long time how to do exit polls. Although there was public outcry in the UK, when the exit poll predicted the liberal democrats not to win the elections , it was spot on. If we know how to do it, then why don\u0026rsquo;t we?\n","date":1295282700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1295282700,"objectID":"5120045297c49f5530e477ab8d216122","permalink":"https://peterlugtig.com/post/predicting-elections/","publishdate":"2011-01-17T17:45:00.001+01:00","relpermalink":"/post/predicting-elections/","section":"post","summary":"Opinion pollers do a lousy job of predicting elections. For a good read, see for example the prediction of the New Hampshere primary in 2008, when all polls predicted Obama to win, but it was Clinton who won (albeit by a slim margin).\nIn the Dutch context, there are three main polling firms, that each do equally well (or badly). Out of a hundred and fifty parliamentary seats, peil.nl mispredicted 20, while TNS-NIPO and Synovate shared the honor of only missing the target by 16 seats in the 2010 parliamentary election.","tags":["opinion poll","exit poll","data quality","elections"],"title":"predicting elections","type":"post"},{"authors":null,"categories":null,"content":"Dear all,\nWith a new year come new year\u0026rsquo;s resolutions. I have been working as a survey methodologist for about the last 5 years. I teach and I do research. Teaching gives instant rewards, or at least instant feedback. I like that. Doing research is however a different matter. It is a slow and sometimes agonizing process of muddling through (for me).\nStudies remain in review forever, sometimes don\u0026rsquo;t make it at all into a publication, while some of my ideas or views just never make onto paper at all. I hope this blog fills that gap.\nI will write in English, but might occasionally do so in Dutch if I feel like it. As far as content goes, I\u0026rsquo;m not sure where all of this will lead. I might post very academic-like things very frequently, but could also publish every once in a while.\nAs a survey methodologist my view is that data matter. Policy makers, and academics use data too often without really knowing how the data were gathered, and whether they are trustworthy. Over the past five years it is my experience that data quality is often low, leading to badly informed or even wrong decisions. Data quality is far more important that fancy statistical models or cool graphs. Hopefully you will enjoy my adventures in the jungle of improving survey data quality.\nYour singalong survey methodologist,\nPeter\n","date":1294676040,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1294676040,"objectID":"46bf885c2eb0b818bbe1881cc8fec0ff","permalink":"https://peterlugtig.com/post/first-past-post/","publishdate":"2011-01-10T17:14:00+01:00","relpermalink":"/post/first-past-post/","section":"post","summary":"Dear all,\nWith a new year come new year\u0026rsquo;s resolutions. I have been working as a survey methodologist for about the last 5 years. I teach and I do research. Teaching gives instant rewards, or at least instant feedback. I like that. Doing research is however a different matter. It is a slow and sometimes agonizing process of muddling through (for me).\nStudies remain in review forever, sometimes don\u0026rsquo;t make it at all into a publication, while some of my ideas or views just never make onto paper at all.","tags":["introduction","data quality"],"title":"first past the post","type":"post"},{"authors":["Lensvelt-Mulders","G.J.L.M.","Lugtig","P.","and Hubregtse","M."],"categories":[],"content":"","date":1249081200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1249081200,"objectID":"2275cba56da73015a9cf75c43a599aca","permalink":"https://peterlugtig.com/publication/2009_lensvelt_mulders_separating_selection_bias/","publishdate":"2009-08-01T00:00:00+01:00","relpermalink":"/publication/2009_lensvelt_mulders_separating_selection_bias/","section":"publication","summary":"","tags":[],"title":"Separating selection bias and non-coverage in internet panels using propensity matching","type":"publication"},{"authors":["Lensvelt-Mulders","G.J.L.M.","Hox","J.J.","and Lugtig","P."],"categories":[],"content":"","date":1235775600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1235775600,"objectID":"93a9e8157b89b3b8a62e12c44b3afadd","permalink":"https://peterlugtig.com/publication/2008_lensvelt_assembling_an_access_panel/","publishdate":"2009-02-28T00:00:00+01:00","relpermalink":"/publication/2008_lensvelt_assembling_an_access_panel/","section":"publication","summary":"Internet-based household panels are becoming increasingly popular as an instrument to obtain wide-ranging knowledge about the general population. Since the Internet penetration in the general population is large (83% in the Netherlands) and still growing, such panels are often treated as a random sample of the population, and the results of panel studies are commonly generalized to the whole population. In this chapter, we describe the setting up of an Internet panel and the effects of choosing the Internet as the only source of data collection. A random sample of 10,000 individuals was drawn from the general population and invited to join a panel. From the non-re-sponders a second sample of 2000 was drawn and asked to complete a short question-naire including the demographic variables and 9 questions from the first panel survey on health-care reforms. Results indicate that the panel members differ markedly from non-members on almost all demographic variables, and on the knowledge questions. The application of a logistic regression weighting technique resulted in more skewed data after weighting than before. We conclude that if an Internet panel is not a rep-resentative sample of the population, then no weighting procedure will correct for the selection bias.","tags":[],"title":"Assembling an access panel: a study of initial nonresponse and self-selection bias","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8e7bc052bdfc6746ea2bb6595e8093eb","permalink":"https://peterlugtig.com/home/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://peterlugtig.com/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"Hello!","tags":null,"title":"About me","type":"widget_page"}]