<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>market research | Peter Lugtig</title>
    <link>https://peterlugtig.github.io/tags/market-research/</link>
      <atom:link href="https://peterlugtig.github.io/tags/market-research/index.xml" rel="self" type="application/rss+xml" />
    <description>market research</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 - 2020</copyright><lastBuildDate>Thu, 27 Apr 2017 19:52:00 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>market research</title>
      <link>https://peterlugtig.github.io/tags/market-research/</link>
    </image>
    
    <item>
      <title>Mobile-only web survey respondents</title>
      <link>https://peterlugtig.github.io/post/mobile-only-web-survey-respondents/</link>
      <pubDate>Thu, 27 Apr 2017 19:52:00 +0200</pubDate>
      <guid>https://peterlugtig.github.io/post/mobile-only-web-survey-respondents/</guid>
      <description>&lt;p&gt;My breaks between posts are getting longer and longer. Sorry my dear readers. Today, I am writing about research done over a year ago that I did with 
&lt;a href=&#34;https://www.uu.nl/staff/VToepoel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vera Toepoel&lt;/a&gt;
 and 
&lt;a href=&#34;https://www.linkedin.com/in/alerk-amin-908394/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alerk Amin.&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Our study was about a group of respondents we can no longer ignore: Mobile-only web survey respondents. These are people, who do no longer use a laptop or desktop PC and use their smartphone for most or any of their Internet browsing, but instead use a smartphone. If we as survey methodologists want these people to answer our surveys, we &lt;em&gt;have to&lt;/em&gt; design our surveys for smartphones as well.&lt;/p&gt;
&lt;p&gt;Who are these mobile-only web survey respondents? This population may of course differ across countries. We used data from the American Life Panel, run by RAND, to investigate what this group looked like in the United States, using data from 2014 (so the situation today may be a bit different). The full paper can be found 
&lt;a href=&#34;https://surveypractice.scholasticahq.com/article/2803-mobile-only-web-survey-respondents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;We find that of all people participating in 7 surveys conducted in the panel, 7% is mobile-only in practice. This is not a huge proportion, but it may matter a lot if these 7% of respondents are very different from other types of respondents. We find that they are.&lt;/p&gt;
&lt;p&gt;In order to study how different these respondents are, we define 5 groups based on the device the use for responding to surveys:&lt;br&gt;
1. Respondents who always use a PC for completing surveys. This the largest group (68%) and therefore serves as the reference group)&lt;br&gt;
2. Respondents who always use a tablet (5%)&lt;br&gt;
3. Respondents who always use a smartphone ( 7% - our group of interest)&lt;br&gt;
4. Respondents who mix tablets and Pcs (7%)&lt;br&gt;
5. Respondents who mix phones and Pcs (10%)&lt;br&gt;
A further 1% uses all devices, but we ignore these respondents here.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://2.bp.blogspot.com/-tsKhJYMzMnQ/WQIezJ94h6I/AAAAAAAAC6c/DqazrgtOwMkPZjqYfnvo2By_Rhay2tPFwCLcB/s1600/plot%2Bmarginal%2Beffcets.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://2.bp.blogspot.com/-tsKhJYMzMnQ/WQIezJ94h6I/AAAAAAAAC6c/DqazrgtOwMkPZjqYfnvo2By_Rhay2tPFwCLcB/s400/plot%2Bmarginal%2Beffcets.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Click Figure to enlarge. The effects shown are always in comparison to the reference group, which is the ‘always PC’ group.&lt;/p&gt;
&lt;p&gt;The 5 groups serve as our dependent variable in a multinomial logit regression. The average marginal effects shown in the Figure above respresent the change in the likelihood of being in the &amp;lsquo;always PC&amp;rsquo; group as compared to one of the other groups. The negative age coefficient of -.03 for the always phone group means that with every decade respondents get younger (a negative effect), they have a .03 higher probability to be be in the always phone group as referred to the always Pc group. These effects seem small, but they are not. An imaginary respondent aged 60 has a predicted probability of 92 percent of being in the always PC group as opposed to the always phone group, but this probability is about 80 percent for someone aged 20, controlling for the effects of other covariates.&lt;/p&gt;
&lt;p&gt;Our take-away? Apart from age, &amp;lsquo;Always phone’ respondents are also less likely to have a higher education (Bachelor degree or higher), are more likely to be married, and more likely to be of Hispanic or African American ethnicity. These characteristics coincide with some of the most important characteristics of hard-to-recruit respondents. While designing your surveys for smartphones will not get these hard-to-recruit respondents into your panel, you can easily lose them by not designing your surveys for smartphones.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>panel conditioning</title>
      <link>https://peterlugtig.github.io/post/panel-conditioning/</link>
      <pubDate>Thu, 12 Jan 2012 14:12:00 +0100</pubDate>
      <guid>https://peterlugtig.github.io/post/panel-conditioning/</guid>
      <description>&lt;p&gt;In late august of 2011 I attended the Internet Survey Methodology Workshop. There were people from academia, official statistics and market research agencies there. One of the issues discussed there has had me thinking since: the topic of panel conditioning. Some people seem really worried that respondents in panel surveys start behaving or thinking differently because of repeated participation in a survey.&lt;/p&gt;
&lt;p&gt;Panel conditioning is closely linked with the issue of  &amp;lsquo;professional&amp;rsquo; respondents. These are respondents who know exactly how survey researchers design surveys, and use this knowledge to get most out of the survey (in terms of reward-schemes) against the least time possible.&lt;/p&gt;
&lt;p&gt;Many market research firms throw out respondents after some time, mostly a couple of years, and then refresh their samples. But is this necessary? If so, after what time do respondents become conditioned? And for what topics is conditioning most problematic?&lt;/p&gt;
&lt;p&gt;Several studies from the 1970s focused on voting behavior in election panel studies. They found that respondents who were asked before a general election aboyut their voting behavior were 10-15% more likely to vote than respondents who were only asked about their voting behavior after the election. I wrote about exit-polls earlier; panel conditioning might be one of the reasons why Internet-panels do so badly at predicting election outcomes. Many other studies have focused on panel conditioning: for attitudes, cognitive abilities, knowledge, marital satisfaction and consumer behavior. Use google scholar on &amp;lsquo;practice effect&amp;rsquo;, &amp;lsquo;reactivity&amp;rsquo;, &amp;lsquo;panel conditioning&amp;rsquo;, &amp;lsquo;test-retest effect&amp;rsquo; and you&amp;rsquo;ll see what I mean.&lt;/p&gt;
&lt;p&gt;Overall, the findings suggest that panel conditioning may indeed be problematic, but not in all studies, or for all people. I have some ideas on the circumstances that lead or do not lead to conditioning effects (topic saliency, interval between measurements, frequency of measurement), but none of the studies systematically analyses potential causes for conditioning effects. I am hoping to add some work on this issue in the next years. If anyone know of interesting panel studies that are confronted with panel conditioning effects, let me know&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
