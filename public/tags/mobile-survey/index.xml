<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mobile survey | Peter Lugtig</title>
    <link>https://thomvolker.github.io/tags/mobile-survey/</link>
      <atom:link href="https://thomvolker.github.io/tags/mobile-survey/index.xml" rel="self" type="application/rss+xml" />
    <description>mobile survey</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 - 2020</copyright><lastBuildDate>Thu, 27 Apr 2017 19:52:00 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>mobile survey</title>
      <link>https://thomvolker.github.io/tags/mobile-survey/</link>
    </image>
    
    <item>
      <title>Mobile-only web survey respondents</title>
      <link>https://thomvolker.github.io/post/mobile-only-web-survey-respondents/</link>
      <pubDate>Thu, 27 Apr 2017 19:52:00 +0200</pubDate>
      <guid>https://thomvolker.github.io/post/mobile-only-web-survey-respondents/</guid>
      <description>&lt;p&gt;My breaks between posts are getting longer and longer. Sorry my dear readers. Today, I am writing about research done over a year ago that I did with 
&lt;a href=&#34;https://www.uu.nl/staff/VToepoel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vera Toepoel&lt;/a&gt;
 and 
&lt;a href=&#34;https://www.linkedin.com/in/alerk-amin-908394/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alerk Amin.&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Our study was about a group of respondents we can no longer ignore: Mobile-only web survey respondents. These are people, who do no longer use a laptop or desktop PC and use their smartphone for most or any of their Internet browsing, but instead use a smartphone. If we as survey methodologists want these people to answer our surveys, we &lt;em&gt;have to&lt;/em&gt; design our surveys for smartphones as well.&lt;/p&gt;
&lt;p&gt;Who are these mobile-only web survey respondents? This population may of course differ across countries. We used data from the American Life Panel, run by RAND, to investigate what this group looked like in the United States, using data from 2014 (so the situation today may be a bit different). The full paper can be found 
&lt;a href=&#34;https://surveypractice.scholasticahq.com/article/2803-mobile-only-web-survey-respondents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;We find that of all people participating in 7 surveys conducted in the panel, 7% is mobile-only in practice. This is not a huge proportion, but it may matter a lot if these 7% of respondents are very different from other types of respondents. We find that they are.&lt;/p&gt;
&lt;p&gt;In order to study how different these respondents are, we define 5 groups based on the device the use for responding to surveys:&lt;br&gt;
1. Respondents who always use a PC for completing surveys. This the largest group (68%) and therefore serves as the reference group)&lt;br&gt;
2. Respondents who always use a tablet (5%)&lt;br&gt;
3. Respondents who always use a smartphone ( 7% - our group of interest)&lt;br&gt;
4. Respondents who mix tablets and Pcs (7%)&lt;br&gt;
5. Respondents who mix phones and Pcs (10%)&lt;br&gt;
A further 1% uses all devices, but we ignore these respondents here.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://2.bp.blogspot.com/-tsKhJYMzMnQ/WQIezJ94h6I/AAAAAAAAC6c/DqazrgtOwMkPZjqYfnvo2By_Rhay2tPFwCLcB/s1600/plot%2Bmarginal%2Beffcets.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://2.bp.blogspot.com/-tsKhJYMzMnQ/WQIezJ94h6I/AAAAAAAAC6c/DqazrgtOwMkPZjqYfnvo2By_Rhay2tPFwCLcB/s400/plot%2Bmarginal%2Beffcets.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Click Figure to enlarge. The effects shown are always in comparison to the reference group, which is the ‘always PC’ group.&lt;/p&gt;
&lt;p&gt;The 5 groups serve as our dependent variable in a multinomial logit regression. The average marginal effects shown in the Figure above respresent the change in the likelihood of being in the &amp;lsquo;always PC&amp;rsquo; group as compared to one of the other groups. The negative age coefficient of -.03 for the always phone group means that with every decade respondents get younger (a negative effect), they have a .03 higher probability to be be in the always phone group as referred to the always Pc group. These effects seem small, but they are not. An imaginary respondent aged 60 has a predicted probability of 92 percent of being in the always PC group as opposed to the always phone group, but this probability is about 80 percent for someone aged 20, controlling for the effects of other covariates.&lt;/p&gt;
&lt;p&gt;Our take-away? Apart from age, &amp;lsquo;Always phone’ respondents are also less likely to have a higher education (Bachelor degree or higher), are more likely to be married, and more likely to be of Hispanic or African American ethnicity. These characteristics coincide with some of the most important characteristics of hard-to-recruit respondents. While designing your surveys for smartphones will not get these hard-to-recruit respondents into your panel, you can easily lose them by not designing your surveys for smartphones.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Satisficing in mobile web surveys. Device-effect or selection effect?</title>
      <link>https://thomvolker.github.io/post/blog-post/</link>
      <pubDate>Mon, 08 Dec 2014 20:47:00 +0100</pubDate>
      <guid>https://thomvolker.github.io/post/blog-post/</guid>
      <description>&lt;p&gt;Last week, I wrote about the fact 
&lt;a href=&#34;http://www.peterlugtig.com/2014/12/what-devices-do-respondents-use-over.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;that respondents in panel surveys are now using tablets and smartphones to complete web surveys&lt;/a&gt;
. We found that in the LISS panel, respondents who use tablets and smartphones are much more likely to switch devices over time and not participate in some months.&lt;br&gt;
The question we actually wanted to answer was a different one: do respondents who complete surveys on their smartphone or mobile give worse answers?&lt;/p&gt;
&lt;p&gt;To do this, we used 6 months of data from the LISS panel, and in each month, coded the User Agent String. We then coded types of satisficing behavior that occur in surveys: the percentage of item missings, whether respondents complete (non-mandatory) open questions, how long their answers were, whether respondents straightline, whether they go for the first answers in a check-all-that-apply questions, and how many answers they click in a check-all-that apply question. We also looked at interview duration, and how much respondents liked the survey.&lt;/p&gt;
&lt;p&gt;We found that respondents on a smartphone seem to do much worse. They take longer to complete the survey, are more negative about the survey, have more item missings, and have a much higher tendency to pick the first answer. On the other questions, differences were small, sometimes in favor of the smartphone user.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://3.bp.blogspot.com/-ugtwA4jujIY/VIYBnhikpVI/AAAAAAAACs4/y_99X9lD1Aw/s1600/Slide1.jpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://3.bp.blogspot.com/-ugtwA4jujIY/VIYBnhikpVI/AAAAAAAACs4/y_99X9lD1Aw/s1600/Slide1.jpg&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Click to enlarge: indicators of satisficing per device in LISS survey&lt;/p&gt;
&lt;p&gt;Is this effect due to the fact that the smartphone and tablet are not made to complete surveys, and is satisficing higher because of a device-effect? Or is it a person effect, and are worse respondents more inclined to do a survey on a tablet or smartphone?&lt;/p&gt;
&lt;p&gt;In order to answer this final question, we looked at device-transitions that respondents take within the LISS panel. In the 6 months of the LISS, respondents can make 5 transitions from using 1 device in the one month, to another (or the same) device in the next. For 7 out of 9 transitions (we have too few observations to analyze the tablet -&amp;gt; phone and phone -&amp;gt; tablet transitions), we can then look at the difference in measurement error that is associated with a change in device.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://3.bp.blogspot.com/-xyw5vo1H-28/VIYFOBkuBpI/AAAAAAAACtM/knp91jodOE4/s1600/plotbars3.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://3.bp.blogspot.com/-xyw5vo1H-28/VIYFOBkuBpI/AAAAAAAACtM/knp91jodOE4/s1600/plotbars3.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Click to enlarge. Changes in data quality (positive is better) associated with change in device.&lt;/p&gt;
&lt;p&gt;The red bars indicate that there is no significant change in measurement error associated with a device change. Our conclusion is that device changes do not lead to more measurement error, with 2 exceptions:&lt;br&gt;
1. A transition from tablet -&amp;gt; PC or phone -&amp;gt; PC in two consecutive months, leads to a better evaluation of the questionnaire. This implies that the user experience of completing web surveys on a mobile device should be improved.&lt;br&gt;
2. We find that people check more answers in a check-all-that-apply question when they move from a tablet -&amp;gt; PC, or phone -&amp;gt; PC&lt;/p&gt;
&lt;p&gt;So, in short. Satisficing seems to be more problematic when surveys are completed on tablets and phones. But this can almost fully be explained by a selection effect. Those respondents who are worse completing surveys, choose to complete surveys more on tablets and smartphones.&lt;/p&gt;
&lt;p&gt;The full paper can be found 
&lt;a href=&#34;https://www.dropbox.com/s/ew6rtantczkpi7y/Lugtig%20and%20Toepoel%20%28prepublication%29.pdf?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Which devices do respondents use over the course of a panel study?</title>
      <link>https://thomvolker.github.io/post/what-devices-do-respondents-use-over/</link>
      <pubDate>Tue, 02 Dec 2014 15:44:00 +0100</pubDate>
      <guid>https://thomvolker.github.io/post/what-devices-do-respondents-use-over/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;http://www.uu.nl/staff/VToepoel&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vera Toepoel&lt;/a&gt;
 and I have been writing a few articles over the last two years about how survey respondents are taking up tablet computers and smartphones. We were interested in studying whether people in a probability-based web panel (
&lt;a href=&#34;http://www.lissdata.nl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the LISS panel&lt;/a&gt;
) use different devices over time, and whether siwtches in devices for completing surveys are associated with more or less measurement error.&lt;/p&gt;
&lt;p&gt;In order to answer this question, we have coded the User Agent Strings of the devices used by more than 6.000 respondents over a six month period. (see the publication tab for a syntax on how to do this using R).&lt;/p&gt;
&lt;p&gt;We find, as others have done, that in every wave about 10% of respondents either use a tablet or smartphone. What is new in our analyses is that we focus on the question whether respondents persistently use the same device.&lt;/p&gt;
&lt;p&gt;The table below shows that PC users largely stick to their PC in all waves. For example, we see that 77.4% of PC-respondents in April, again use a PC in May. Only 1.5% of April’s PC respondents switch to either a tablet or smartphone to complete a questionnaire in May.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table.&lt;/strong&gt; Devices used between April and September 2013 by LISS panel respondents.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://1.bp.blogspot.com/-GBK0uZ9jCuQ/VH3RelGgypI/AAAAAAAACsg/lKOeVcgPHb0/s1600/lugtig%2Band%2Btoepoel%2Btable%2B1.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://1.bp.blogspot.com/-GBK0uZ9jCuQ/VH3RelGgypI/AAAAAAAACsg/lKOeVcgPHb0/s1600/lugtig%2Band%2Btoepoel%2Btable%2B1.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;N = 6,226. Click to enlarge&lt;/p&gt;
&lt;p&gt;The proportion of respondents switching a PC for either a tablet or smartphone is similarly low in the other months, and is never more than 5%. This stability in device use for PCs is, however, not found for tablets and smartphones. Once people are using a smartphone in particular, they are not very likely to use a smartphone in the next waves of LISS. Only 29 per cent of smartphone users in July 2013, again uses a smartphone in August for example. The consistency of tablet usage increases over the course of the panel; 24% of respondent is a consistent tablet user in April-May, but this increases to 64% in July-August.&lt;/p&gt;
&lt;p&gt;Finally, it is worth to note that the use of either a smartphone or a tablet is more likely to lead to non-participation in the next wave of the survey. This may however be a sample selection effect. More loyal panel members may favor the PC to complete the questionnaires.&lt;/p&gt;
&lt;p&gt;More in a next post on the differences between respondents answer behavior over time, when they switch devices. Do respondents become worse when they answer a survey on a smartphone or tablet?&lt;/p&gt;
&lt;p&gt;You can download the full paper 
&lt;a href=&#34;https://www.dropbox.com/s/ew6rtantczkpi7y/Lugtig%20and%20Toepoel%20%28prepublication%29.pdf?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Can you push web survey respondents to complete questionnaires on their mobile phones?</title>
      <link>https://thomvolker.github.io/post/can-you-push-web-survey-respondents-to/</link>
      <pubDate>Wed, 13 Aug 2014 19:06:00 +0200</pubDate>
      <guid>https://thomvolker.github.io/post/can-you-push-web-survey-respondents-to/</guid>
      <description>&lt;p&gt;I am back from some great holidays, and am revisiting some of the research I did over the last 2 years. Back then, I would have not expected that I would become so interested in doing survey research on mobile phones. I do think that a little change of research topic does one good.&lt;/p&gt;
&lt;p&gt;I have written two papers with Vera Toepoel on how to do surveys on mobile phones. The first question we had was whether people were actually likely to do a survey on a mobile phone. Last year, Marketresponse, a probability-based web panel in the Netherlands, had changed their survey software so that questionnaires would be dynamically adapted to mobile phone screen settings, and navigation methods. They then informed their respondents about it, and encouraged them to try a short survey on shopping behavior on their smartphone (if respondents had one).&lt;/p&gt;
&lt;p&gt;We found that of those respondents who owned a smartphone, 59% chose to use it when encouraged and were positively surprised by this finding. Even with quite little encouragement, survey respondents are willing to try completing the survey on their mobile phone. Also, we found little reason to be worried about side-effects of encouraging mobile survey response.&lt;/p&gt;
&lt;p&gt;- We found little differences in terms of demographics between those who did the survey on a mobile phone, or a desktop (including tablets).&lt;br&gt;
- We found no differences in terms of response behavior.&lt;br&gt;
- We found no difference in how mobile and desktop respondents evaluated the questionnaire.&lt;br&gt;
- We found no difference in the time it took them to complete the survey (see the figure below). In fact, the timings were so similar, we could scarcely believe the differences were so small.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://1.bp.blogspot.com/-09-2vnxn6mo/U-uZs9lpXGI/AAAAAAAACr0/1X1MWVccCtA/s1600/time%2Bto%2Bcomlete%2Bweb%2Bsurvey.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://1.bp.blogspot.com/-09-2vnxn6mo/U-uZs9lpXGI/AAAAAAAACr0/1X1MWVccCtA/s1600/time%2Bto%2Bcomlete%2Bweb%2Bsurvey.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;The full paper can be found 
&lt;a href=&#34;http://ssc.sagepub.com/content/early/2014/04/02/0894439313510482.abstract&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
. There are a few potential caveats in our study: we use a sample of experienced survey respondents and did not use experimental assignments, so self-selection into device could be selective beyond the variables we studied. So far however, it really seems that web surveys on a mobile phone are not very different for respondents than traditional web surveys.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AAPOR 2014</title>
      <link>https://thomvolker.github.io/post/aapor-2014/</link>
      <pubDate>Mon, 26 May 2014 17:05:00 +0200</pubDate>
      <guid>https://thomvolker.github.io/post/aapor-2014/</guid>
      <description>&lt;p&gt;Big data and new technologies to do survey research. These were in my view the two themes of the 
&lt;a href=&#34;http://www.aapor.org/AAPOR_Annual_Conference.htm#.U4NUUi-prs0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2014 AAPOR conference&lt;/a&gt;
. The conference organisation tried to push the theme ‘Measurement and the role of pubic opinion in a democracy’, but I don&#39;t think the theme was really reflected in the talks at the conference. Or perhaps I have missed those talks, the conference was huge as always (&amp;gt; 1000 participants).&lt;/p&gt;
&lt;p&gt;The profession of survey research is surely changing. Mick Couper last year argued that the 
&lt;a href=&#34;https://ojs.ub.uni-konstanz.de/srm/article/view/5751&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‘sky wasn’t falling’&lt;/a&gt;
 on survey research, but it is evolving. Big data may potentially replace parts of survey research, especially if we don&#39;t adapt to new technologies (mobile), and learn to use some of the data that are now found everywhere. Big data and survey research in fact have the same basic goal. To extract meaningful information out of datasets (big data) or people (survey research), and use that to inform policy making.&lt;/p&gt;
&lt;p&gt;Big data can certainly be useful for policy-making. Out of the 10 or so presentations that I have seen at AAPOR, most were however just talking about potential possibilities over using big data to inform policy makers.&lt;br&gt;
What was in my opinion missing at AAPOR were good case studies that showed how big data can replace survey research and provide valid inferences. I have seen many good earlier examples when it comes to predictions at the level of an individual using big data. When Amazon tries to recommend me books that relate to a book I have previously bought, I find these useful and accurate predictions of what I really like. In politics, voter registration records data can help politicians target likely voters for their party, as the 
&lt;a href=&#34;http://www.technologyreview.com/featuredstory/509026/how-obamas-team-used-big-data-to-rally-voters/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2012 Obama campaign showed&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;But when it comes to aggregating big data to the level of the population, big data is often in trouble (the Obama election campaign is an outlier here, as they collect data on the &lt;em&gt;whole&lt;/em&gt; population). Survey research has relied on the principle of random sampling from the population to draw inferences, but for big data, coverage and nonresponse errors are often unknown and unestimatible for the convenience samples that big data ususally are. 
&lt;a href=&#34;https://blogs.rti.org/surveypost/2014/05/08/aapor-preview-big-data-in-public-opinion-and-survey-research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paul Biemer made this point in an excellent talk&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;Most of the other big data presentations at AAPOR to me were either in the category ‘bar talk’ - anecdotes without a scientific empirical strategy - or just talked about the potential of big data. And don’t get me wrong: I do think that big data are very useful, especially if they cover a late proportion of the population (e.g. voter records), or if the goals is prediction at the level of an individual.&lt;/p&gt;
&lt;p&gt;The other conference theme seemed to be mobile surveys. With Vera Toepoel, I gave a presentation on this topic, which may be the topic of a next blogpost. Here, I think survey researchers are much better equipped to deal with the challenge mobile devices pose. I saw many excellent presentations on questionnaire design for mobile surveys, and selection bias.&lt;/p&gt;
&lt;p&gt;Finally, this is just my conference take-away. Some other bloggers (
&lt;a href=&#34;http://freerangeresearch.com/2014/05/20/reporting-on-the-aapor-69th-national-conference-in-anaheim-aapor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
 
&lt;a href=&#34;http://lovestats.wordpress.com/tag/aapor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
) seem to have a slightly different view on the conference. Probably this is due to the fact I have only seen 1 out of the 8 presentations given at any time. So be sure to check their posts out if you want to know more about the conference.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
