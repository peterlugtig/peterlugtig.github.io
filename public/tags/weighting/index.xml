<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>weighting | Peter Lugtig</title>
    <link>/tags/weighting/</link>
      <atom:link href="/tags/weighting/index.xml" rel="self" type="application/rss+xml" />
    <description>weighting</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019 - 2020</copyright><lastBuildDate>Mon, 14 Oct 2013 10:41:00 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>weighting</title>
      <link>/tags/weighting/</link>
    </image>
    
    <item>
      <title>Imagine we have great covariates for correcting for unit nonresponse...</title>
      <link>/post/imagine-we-have-great-covariates-for/</link>
      <pubDate>Mon, 14 Oct 2013 10:41:00 +0200</pubDate>
      <guid>/post/imagine-we-have-great-covariates-for/</guid>
      <description>&lt;p&gt;I am continuing on the recent article and commentaries on weighting to correct for unit nonresponse by Michael Brick, as published in the recent issue of the Journal of Official Statistics (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
).&lt;/p&gt;
&lt;p&gt;The article by no means is all about whether one should impute or weight. I am just picking out one issue that got me thinking. Michael Brick rightly says that in order to correct succesfully for unit nonresponse using covariates, we want the covariates to do two things:&lt;/p&gt;
&lt;p&gt;1. They should explain missingness.&lt;br&gt;
2. They should highly correlate with our variable of interest.&lt;/p&gt;
&lt;p&gt;In other words, these are the two assumptions for a  Missing At Random process of missing data.&lt;/p&gt;
&lt;p&gt;The variables (covariates) we currently use for nonresponse adjustments do neither. Gender, age, ethnicity, region, (and if we&#39;re lucky) education, household composition and house characterics do not explain missingness, nor our variable of interest. Would it ever be conceivable to obtain covariates that do this? What are the candidates?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. covariates (X) that explain missingness (R):&lt;/strong&gt;&lt;br&gt;
Paradata are currently our best bet. Those may be interviewer observations or call data during fieldwork (note the absence of sample level paradata for self-administered surveys - here lies a task for us). Paradata don&#39;t explain missingness very well at the moment, but I think everyone in survey research agrees we can try to collect more.&lt;br&gt;
Another set of candidates are variables that we obtain by enriching sampling frames. We can use marketing data, social networks, or census data to get more information on our sampling units.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. covariates (X) that explain our variable of interest (Y)&lt;/strong&gt;:&lt;br&gt;
Even if we find covariates that explain missingness, we also want those covariates to be highly correlated to our variable of interest. It is very unlikely that a fixed set of for example paradata variables can ever achieve that. Enriched frame data may be more promising, but is unlikely that this will generally work. I think it is a huge problem that our nonresponse adjustment variables (X) are not related to Y, and one that is not likely to ever be resolved for cross-sectional surveys.&lt;/p&gt;
&lt;p&gt;But. In longitudinal surveys, this is an entirely different matter. Because we usually ask the same variables over time, we can use variables from earlier occasions to predict values that are missing at later waves. So, there, we have great covariates that explain our variable of interest. We can use those as long as MAR holds. If change in the dependent variable is associated with attrition, MAR does not hold. Strangely, I know very few studies that study whether attrition is related to change in the dependent variable. Usually, attrition studies focus on covariates measured before attrition, to then explain attrition. They do not focus on change in the dependent variable.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://2.bp.blogspot.com/-NhM3-D53n-g/UlutJ3JdvgI/AAAAAAAACnY/vmiOUDyFvdk/s1600/missing&amp;#43;data&amp;#43;mechanisms.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://2.bp.blogspot.com/-NhM3-D53n-g/UlutJ3JdvgI/AAAAAAAACnY/vmiOUDyFvdk/s400/missing+data+mechanisms.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Covariate adjustment for nonresponse in cross-sectional and longitudinal surveys&lt;/p&gt;
&lt;p&gt;(follow-up 28 October 2013): When adjustment variables are strongly linked to dependent variables, but not to nonresponse, variances tend to be increased (See Little and Vartivarian). So, in longitudinal surveys, the weak link between X and R should really be of medium strength as well, if adjustment is to be successful.&lt;/p&gt;
&lt;p&gt;I once thought that because we have so much more information in longitudinal surveys, we could use the lessons that we learn from attrition analyses to improve nonresponse adjustments in cross-sectional surveys. In a 
&lt;a href=&#34;http://www.peterlugtig.com/2012/09/is-panel-attrition-same-as-nonresponse.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;forthcoming book chapter&lt;/a&gt;
, I found that the correlates of attrition are however very different from the correlates of nonresponse in wave 1. So in my view, the best we can do in cross-sectional surveys is to focus on explaining missingness, and then hope for the best for the prediction of our variables of interest.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>To weight or to impute for unit nonresponse?</title>
      <link>/post/to-weight-or-to-impute-for-unit/</link>
      <pubDate>Sun, 06 Oct 2013 21:49:00 +0200</pubDate>
      <guid>/post/to-weight-or-to-impute-for-unit/</guid>
      <description>&lt;p&gt;This week, I have been reading the most recent issue of the 
&lt;a href=&#34;http://www.jos.nu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Journal of Official Statistics&lt;/a&gt;
, a journal that has been open access since the 1980s.  In this issue is a 
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293329&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;critical review article of weighting procedures&lt;/a&gt;
 authored by Michael Brick with commentaries by Olena Kaminska (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293355&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
), Philipp Kott (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293359&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
), Roderick Little (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293363&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
), Geert Loosveldt (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293367&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
), and a rejoinder (
&lt;a href=&#34;http://www.jos.nu/Articles/abstract.asp?article=293371&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
).&lt;/p&gt;
&lt;p&gt;I found this article a great read, and to be full of ideas related to unit nonresponse. The article reviews approaches to weighting: either to the sample or the population, by poststratification and with different statistical techniques. But it discusses much more, and I recommend reading it.&lt;/p&gt;
&lt;p&gt;One of the issues that is discussed in the article, but much more extensively in a commentary by Roderick Little, is the question whether we should use weighting or imputations to adjust for unit nonresponse in surveys. Over the years, I have switched allegiances to favouring weighting or imputations in certain missing data situations many times, and I am still not always certain on what is best to do. Weighting is generally favoured for cross-sectional surveys, because we understand how it works. Imputations are generally favoured when we have strong correlates for missingness and our variable(s) of interest, such as in longitudinal surveys. Here are some plusses and minuses for both weighting and imputations.&lt;/p&gt;
&lt;p&gt;Weighting is design based. Based on information that is available for the population or whole sample (including nonrespondents), respondent data are weighted in such a way that the survey data reflect the sample/population again.&lt;/p&gt;
&lt;p&gt;+ The statistical properties of all design-based weighting procedures are well-known.&lt;br&gt;
+ Weighting works with complex sampling designs (at least theoretically).&lt;br&gt;
+ We need relatively little information on nonrespondents to be able to use weighting procedures. There is however a big BUT&amp;hellip;&lt;br&gt;
- Weighting models mainly use socio-demographic data, because that is the kind of information we can add to our sampling frame. These variables are never highly correlated with our variable of interest, nor missingness due to nonresponse, so weighting is not very effective. That is, weighting theoretically works nicely, but in practice, it doesn&#39;t ameliorate the missing data problem we have because of unit nonresponse much.&lt;/p&gt;
&lt;p&gt;Imputations are model based. Based on available information for respondents and nonrespondents, a prediction model is built for a variable which has missing information. The model can take an infinite number of shapes, depending on whether imputation is stochastic, how variables are related within the model, and what variables are being used. Based on this model, one or multiple values are imputed for every missing value on every variable for every case. The crucial difference is that weighting uses the same variables for correcting the entire dataset, whereas imputation models differ for every variable that is to be imputed.&lt;/p&gt;
&lt;p&gt;+ Imputation models are flexible. This means that the imputation model can be optimized in such a way that it strongly predicts both the dependent variable to be imputed, and the missingness process.&lt;/p&gt;
&lt;p&gt;- In the case of unit nonresponse, we often have limited data on nonrespondents. So, although a model-based approach may have advantages over design-based aproaches in terms of its ability to predict our variable(s) of interest, this depends on the quality of the covariates we use.&lt;/p&gt;
&lt;p&gt;This then brings me, and the authors of the various papers in JoS back to the basic problem: 
&lt;a href=&#34;http://www.peterlugtig.com/2013/09/nonresponse-workshop-2013.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;we don&#39;t understand the process on nonresponse in surveys&lt;/a&gt;
. Next time, more on imputations and weighting for longitudinal surveys. And more on design vs. model based approaches in survey research.&lt;/p&gt;
&lt;p&gt;p.s. This all assumes simple random sampling. If complex sampling designs are used, weighting is until now I think the best way to start dealing with nonresponse. I am unaware of imputation methods that can deal with complex sampling (other than straightforward multilevel structures).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>why access panels cannot weight elections polls accurately</title>
      <link>/post/why-access-panels-cannot-weight/</link>
      <pubDate>Sat, 22 Sep 2012 16:05:00 +0200</pubDate>
      <guid>/post/why-access-panels-cannot-weight/</guid>
      <description>&lt;p&gt;There are a lot of reasons why would not want to use acces panels for predicting electoral outcomes . These are well discussed in many places on- and offline. I&#39;ll shortly summarize them, before adding some thoughts to why access panels do so badly predicting election outcomes.&lt;/p&gt;
&lt;p&gt;1. Access panels don&#39;t draw random samples, but rely on self-selected samples. A slightly better way to get panel respondents is a quota sample, but even these have problems, well discussed here, here and here for example. The bottom line is that access panel respondents are not &#39; normal&amp;rsquo; people, and so voting preferences of not-normal people are likely to be biased.&lt;/p&gt;
&lt;p&gt;2. Because of these problems, survey managers use weighting. They correct their sample for known biases in the sample. If they know elderly people with low educations are underrepresented in an access panel, they weigh them up. I think this is bad practice. And it has been shown that weighting does not solve the problem,. and can sometimes make biases worse for general surveys. Here are some additional and specific problems, often neglected. In short, weighting only works if the weighting variables can predict the dependent variable to a great extent.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://1.bp.blogspot.com/-vjBRTegZb3Q/UF3EyedoEQI/AAAAAAAACe8/lc7kLoJxNis/s1600/Unbalanced_scales-too-far-right.png&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://1.bp.blogspot.com/-vjBRTegZb3Q/UF3EyedoEQI/AAAAAAAACe8/lc7kLoJxNis/s200/Unbalanced_scales-too-far-right.png&#34; alt=&#34;&#34;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Weighting is usually done with socio-demographic variables. From political science research, we know that sociodemographics do a bad job of explaining voting behavior. Explained variances for regression models normally don&#39;t exceed 10%.&lt;br&gt;
So, let me get down to the main point I would like to make in this post. A point which I have not seen discussed anywhere.&lt;/p&gt;
&lt;p&gt;Panel survey managers have &amp;lsquo;resolved&amp;rsquo; the weakness of their weighting models by including a variable that does predict voring behavior fairly well: past voting behavior. If one knows that past Social Democrat voters are underrepresented, one can weight on that variable. This is all very well, if one has good data of past voting behavior for all panel members. The panels currently do not. Their information is wrong in two ways:&lt;/p&gt;
&lt;p&gt;1. Access panels will never have information for people &lt;strong&gt;who did not vote previously&lt;/strong&gt;. These are mainly young people, or people who normally do not vote in elections. If these new voters vote like everyone else there is no problem, but new voters have very specific voting preferences.&lt;/p&gt;
&lt;p&gt;2.  Reversely, access panels can not predict well &lt;strong&gt;who is not going to vote in current elections&lt;/strong&gt;. If non-voters disproportionally voted for one party in the previous elections, this will lead to an overestimation of voters for that party.&lt;/p&gt;
&lt;p&gt;I believe these two problems are larger than most people think. The first problem can predict why the PVV-vote was underestimated in 2006 and 2010. The PVV attracted many new voters in those elections. The second problem explains why the PVV-vote was overestimated in 2012.  Many people who voted PVV in the previous elections, stayed home this time.&lt;/p&gt;
&lt;p&gt;So, panel survey managers who want a bit of free advice how to improve your polls. Try to get a clear view on the new voters, and the people unlikely to vote. That may be hard, especially because non-voters are not so interested in politics, and will therefore not sign up for online access panels voluntarily. But it is certainly not impossible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dutch elections 2012 - poll results</title>
      <link>/post/dutch-elections-2012-poll-results/</link>
      <pubDate>Thu, 13 Sep 2012 11:57:00 +0200</pubDate>
      <guid>/post/dutch-elections-2012-poll-results/</guid>
      <description>&lt;p&gt;The night after the election, one can conclude that all pollsters in the Netherlands did a bad job of predicting the election results. All polls were at least off by 20 seats (out of 150), and I expect the newspapers to make headlines of this in the next days. See the table below for the final predictions (before election day), the exit poll and final election results. The last row shows how much each poll was off (in the number of seats&lt;/p&gt;
&lt;p&gt;Actually, I think the pollsters did pretty well this time. The only thing all of them mispredicted, was a large number of PVV voters moving to VVD, and a lot of SP voters moving to the PvdA, This movement was visible in the last polls leading up to the elections, but the pollsters either underestimated it, or a lot of people switched for the winner on election date.&lt;/p&gt;
&lt;p&gt;So, I predicted Synovate would do best, but that did not turn out to be the case. Well, they share first place with Maurice de Hond, but are not clearly better than others. There are lots of blogs, articles and news items about Internet Panels these days. I spent some blogposts on that issue in 2009 myself. Although the largest reason why pollers generally do so badly is that they do not draw random samples, I think there are two more reasons why pollsters do badly. I plan to spend my next two blog posts on these topics, so stay tuned for more on the following issue.&lt;/p&gt;
&lt;p&gt;Pollsters use statistical weighting to account for the unrepresentativity of their panel. They do this on sociodemographic characteristics and past voting behavior. I believe it is wrong to weight (in general), and specifically to do so on past voting behavior. I&#39;ll show you why in the next days.&lt;/p&gt;
&lt;p&gt;No. of seats in partliament 2012&lt;/p&gt;
&lt;p&gt; Maurice de Hond (peil.nl)&lt;/p&gt;
&lt;p&gt;Intomart/de stemming&lt;/p&gt;
&lt;p&gt; Synovate&lt;/p&gt;
&lt;p&gt; TNS-NIPO&lt;/p&gt;
&lt;p&gt;Exit Poll (synovate)&lt;/p&gt;
&lt;p&gt;Final results&lt;/p&gt;
&lt;p&gt;VVD (right-liberal)&lt;/p&gt;
&lt;p&gt;36&lt;/p&gt;
&lt;p&gt;35&lt;/p&gt;
&lt;p&gt;37&lt;/p&gt;
&lt;p&gt;35&lt;/p&gt;
&lt;p&gt;41&lt;/p&gt;
&lt;p&gt;41&lt;/p&gt;
&lt;p&gt;PVDA (social democrat)&lt;/p&gt;
&lt;p&gt;36&lt;/p&gt;
&lt;p&gt;34&lt;/p&gt;
&lt;p&gt;36&lt;/p&gt;
&lt;p&gt;34&lt;/p&gt;
&lt;p&gt;40&lt;/p&gt;
&lt;p&gt;38&lt;/p&gt;
&lt;p&gt;SP (socialist)&lt;/p&gt;
&lt;p&gt;20&lt;/p&gt;
&lt;p&gt;22&lt;/p&gt;
&lt;p&gt;21&lt;/p&gt;
&lt;p&gt;21&lt;/p&gt;
&lt;p&gt;15&lt;/p&gt;
&lt;p&gt;15&lt;/p&gt;
&lt;p&gt;PVV (anti-immigrant)&lt;/p&gt;
&lt;p&gt;18&lt;/p&gt;
&lt;p&gt;17&lt;/p&gt;
&lt;p&gt;17&lt;/p&gt;
&lt;p&gt;17&lt;/p&gt;
&lt;p&gt;13&lt;/p&gt;
&lt;p&gt;15&lt;/p&gt;
&lt;p&gt;CDA (christian democrats)&lt;/p&gt;
&lt;p&gt;12&lt;/p&gt;
&lt;p&gt;12&lt;/p&gt;
&lt;p&gt;13&lt;/p&gt;
&lt;p&gt;12&lt;/p&gt;
&lt;p&gt;13&lt;/p&gt;
&lt;p&gt;13&lt;/p&gt;
&lt;p&gt;D&#39;66 (center liberals)&lt;/p&gt;
&lt;p&gt;11&lt;/p&gt;
&lt;p&gt;11&lt;/p&gt;
&lt;p&gt;10&lt;/p&gt;
&lt;p&gt;13&lt;/p&gt;
&lt;p&gt;12&lt;/p&gt;
&lt;p&gt;12&lt;/p&gt;
&lt;p&gt;CU (christian union)&lt;/p&gt;
&lt;p&gt;5&lt;/p&gt;
&lt;p&gt; 7&lt;/p&gt;
&lt;p&gt;5&lt;/p&gt;
&lt;p&gt;6&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt;5&lt;/p&gt;
&lt;p&gt;SGP (reformed christians)&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;Groenlinks (green)&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt; 4&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt;4&lt;/p&gt;
&lt;p&gt;PVDD (animal rights&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt; 2&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;50plus (elderly)&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt; 2&lt;/p&gt;
&lt;p&gt; 4&lt;/p&gt;
&lt;p&gt;3&lt;/p&gt;
&lt;p&gt;2&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wrongly predicted&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;24&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;24&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
